---
author: ZhgChgLi
categories:
- KKday Tech Blog
date: 2024-08-13T08:10:37.015+0000
description: iOSé–‹ç™ºè€…å‘ã‘ã«Vision frameworkã®æ©Ÿèƒ½ã‚’æŒ¯ã‚Šè¿”ã‚Šã€iOS 18ã§è¿½åŠ ã•ã‚ŒãŸSwift APIã‚’å®Ÿéš›ã«è©¦ã—ã¦åŠ¹ç‡çš„ãªç”»åƒèªè­˜ã‚’å®Ÿç¾ã™ã‚‹æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚
image:
  path: /assets/755509180ca8/1*NqN-_MAE4tt11n6MnUQWxQ.jpeg
last_modified_at: 2024-08-14T12:07:49.774+0000
render_with_liquid: false
tags:
- iOSã‚¢ãƒ—ãƒªé–‹ç™º
- Visionãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- Appleã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹
- AI
- æ©Ÿæ¢°å­¦ç¿’
- japanese
- ai-translation
title: iOS Vision frameworkï½œWWDC 24ã§Swiftå¼·åŒ–ã‚’è§£èª¬â€”Vision frameworkæœ€æ–°æ©Ÿèƒ½ã‚’å¾¹åº•ãƒ¬ãƒ“ãƒ¥ãƒ¼
---

### iOS Vision framework x WWDC 24 Vision frameworkã®Swiftå¼·åŒ–ã‚’ç™ºè¦‹ã‚»ãƒƒã‚·ãƒ§ãƒ³

Vision framework æ©Ÿèƒ½ãƒ¬ãƒ“ãƒ¥ãƒ¼ & iOS 18 æ–°Swift API è©¦ç”¨

![Photo by [BoliviaInteligente](https://unsplash.com/@boliviainteligente?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash){:target="_blank"}](/assets/755509180ca8/1*NqN-_MAE4tt11n6MnUQWxQ.jpeg)

Photo by [BoliviaInteligente](https://unsplash.com/@boliviainteligente?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash){:target="_blank"}

#### ãƒ†ãƒ¼ãƒ

![Vision Proã¨ã®é–¢ä¿‚ã¯ãƒ›ãƒƒãƒˆãƒ‰ãƒƒã‚°ã¨çŠ¬ã®é–¢ä¿‚ã¨åŒã˜ã§ã€å…¨ãé–¢ä¿‚ã‚ã‚Šã¾ã›ã‚“ã€‚](/assets/755509180ca8/1*ebqm2jzCK1GSrDDY0XtrUA.png)

Vision Proã¨ã®é–¢ä¿‚ã¯ã€ãƒ›ãƒƒãƒˆãƒ‰ãƒƒã‚°ã¨çŠ¬ã®é–¢ä¿‚ã¨åŒã˜ã§ã€å…¨ãé–¢ä¿‚ã‚ã‚Šã¾ã›ã‚“ã€‚

### Vision framework

Vision framework ã¯ã€AppleãŒçµ±åˆã—ãŸæ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹ç”»åƒèªè­˜ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€é–‹ç™ºè€…ãŒä¸€èˆ¬çš„ãªç”»åƒèªè­˜æ©Ÿèƒ½ã‚’ç°¡å˜ã‹ã¤è¿…é€Ÿã«å®Ÿè£…ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚Vision framework ã¯ iOS 11.0+ï¼ˆ2017å¹´ï¼iPhone 8ï¼‰ã§åˆã‚ã¦ãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã€ãã®å¾Œã‚‚ç¶™ç¶šçš„ã«æ”¹è‰¯ã•ã‚Œã€Swift Concurrencyã¨ã®çµ±åˆãŒé€²ã¿ã€å®Ÿè¡Œæ€§èƒ½ãŒå‘ä¸Šã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€iOS 18.0 ã‹ã‚‰ã¯æ–°ã—ã„ Swift Vision framework API ãŒæä¾›ã•ã‚Œã€Swift Concurrency ã®åŠ¹æœã‚’æœ€å¤§é™ã«ç™ºæ®ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚

**Vision framework ã®ç‰¹å¾´**

- å†…è”µã•ã‚ŒãŸå¤šæ•°ã®ç”»åƒèªè­˜ãŠã‚ˆã³å‹•çš„è¿½è·¡ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆiOS 18ã¾ã§ã«åˆè¨ˆ31ç¨®é¡ï¼‰

- On-Device ã¯å˜ã«ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã®ãƒãƒƒãƒ—ã§å‡¦ç†ã‚’è¡Œã„ã€èªè­˜ãƒ—ãƒ­ã‚»ã‚¹ã¯ã‚¯ãƒ©ã‚¦ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã«ä¾å­˜ã›ãšã€é«˜é€Ÿã‹ã¤å®‰å…¨ã§ã™

- APIã¯ç°¡å˜ã§ä½¿ã„ã‚„ã™ã„

- Apple å…¨ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã¯ iOS 11.0+ã€iPadOS 11.0+ã€Mac Catalyst 13.0+ã€macOS 10.13+ã€tvOS 11.0+ã€visionOS 1.0+ ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚

- æ•°å¹´é–“ï¼ˆ2017å¹´ï½ç¾åœ¨ï¼‰ãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã€ç¶™ç¶šçš„ã«æ›´æ–°ã•ã‚Œã¦ã„ã¾ã™

- Swiftè¨€èªã®ç‰¹æ€§ã‚’çµ±åˆã—ã¦è¨ˆç®—æ€§èƒ½ã‚’å‘ä¸Š

> ***6å¹´å‰ã«å°‘ã—è§¦ã£ãŸã“ã¨ãŒã‚ã‚Šã¾ã™ï¼š [Vision å…¥é–€ â€” ã‚¢ãƒ—ãƒªã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã«è‡ªå‹•ã§é¡”ã‚’èªè­˜ã—ã¦ãƒˆãƒªãƒŸãƒ³ã‚° (Swift)](../9a9aa892f9a9/)***

> *ä»Šå›ã¯[WWDC 24 Discover Swift enhancements in the Vision framework Session](https://developer.apple.com/videos/play/wwdc2024/10163/){:target="_blank"}ã¨åˆã‚ã›ã¦ã€æ–°ã—ã„Swiftã®ç‰¹å¾´ã‚’å–ã‚Šå…¥ã‚ŒãªãŒã‚‰æ”¹ã‚ã¦å¾©ç¿’ã—ã¾ã™ã€‚*

#### CoreML

Appleã«ã¯ã‚‚ã†ä¸€ã¤ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹[CoreML](https://developer.apple.com/documentation/coreml){:target="_blank"}ã‚‚ã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã¯On-Deviceãƒãƒƒãƒ—ã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸæ©Ÿæ¢°å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ãŒã€è‡ªåˆ†ã§èªè­˜ã—ãŸã„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒ—ãƒªã«çµ„ã¿è¾¼ã‚“ã§ç›´æ¥ä½¿ã†ã“ã¨ãŒã§ãã¾ã™ã€‚èˆˆå‘³ãŒã‚ã‚‹æ–¹ã¯ãœã²è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚ï¼ˆä¾‹ï¼š[ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¨˜äº‹åˆ†é¡](../793bf2cdda0f/) ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®[è¿·æƒ‘ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ¤œå‡º](https://apps.apple.com/tw/app/%E7%86%8A%E7%8C%AB%E5%90%83%E7%9F%AD%E4%BF%A1-%E5%9E%83%E5%9C%BE%E7%9F%AD%E4%BF%A1%E8%BF%87%E6%BB%A4/id1319191852){:target="_blank"}ãªã©ï¼‰

#### p.s.

[**Vision**](https://developer.apple.com/documentation/vision/){:target="_blank"} **v.s. [VisionKit](https://developer.apple.com/documentation/visionkit){:target="_blank"} ï¼š**

> [***Vision***](https://developer.apple.com/documentation/vision/){:target="*blank"} _ï¼šä¸»ã«é¡”èªè­˜ã€ãƒãƒ¼ã‚³ãƒ¼ãƒ‰æ¤œå‡ºã€ãƒ†ã‚­ã‚¹ãƒˆèªè­˜ãªã©ã®ç”»åƒè§£æã‚¿ã‚¹ã‚¯ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚é™æ­¢ç”»åƒã‚„å‹•ç”»å†…ã®è¦–è¦šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å‡¦ç†ãƒ»è§£æã™ã‚‹å¼·åŠ›ãªAPIã‚’æä¾›ã—ã¾ã™ã€‚_

> [***VisionKit***](https://developer.apple.com/documentation/visionkit){:target="*blank"} _ï¼šãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ã‚­ãƒ£ãƒ³ã«é–¢é€£ã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’å‡¦ç†ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚é«˜å“è³ªãªPDFã‚„ç”»åƒã‚’ç”Ÿæˆã™ã‚‹ã‚¹ã‚­ãƒ£ãƒŠãƒ¼ãƒ“ãƒ¥ãƒ¼ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ã‚’æä¾›ã—ã¾ã™ã€‚*

Vision framework ã¯ M1 æ©Ÿç¨®ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ã§ã¯å‹•ä½œã›ãšã€å®Ÿæ©Ÿã§ã®ã¿ãƒ†ã‚¹ãƒˆå¯èƒ½ã§ã™ã€‚ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ç’°å¢ƒã§å®Ÿè¡Œã™ã‚‹ã¨ `Could not create Espresso context` ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã™ã€‚å…¬å¼ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ã®è­°è«–ã‚’ç¢ºèªã—ã¾ã—ãŸãŒã€è§£æ±ºç­–ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ [å…¬å¼ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ã®è­°è«–ã¯ã“ã¡ã‚‰](https://forums.developer.apple.com/forums/thread/675806){:target="_blank"} ã€‚

> *æ‰‹å…ƒã«å®Ÿéš›ã®iOS 18ãƒ‡ãƒã‚¤ã‚¹ãŒãªã„ãŸã‚ã€ã“ã®è¨˜äº‹ã®ã™ã¹ã¦ã®å®Ÿè¡Œçµæœã¯æ—§ï¼ˆiOS 18ä»¥å‰ï¼‰ã®æ›¸ãæ–¹ã«ã‚ˆã‚‹ã‚‚ã®ã§ã™ï¼›**æ–°ã—ã„æ›¸ãæ–¹ã§ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸå ´åˆã¯ã‚³ãƒ¡ãƒ³ãƒˆã§ã”æŒ‡æ‘˜ãã ã•ã„**ã€‚*

### WWDC 2024 â€” Visionãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®Swiftå¼·åŒ–ã‚’ç™ºè¦‹ã™ã‚‹

![[Visionãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®Swiftå¼·åŒ–ã‚’ç™ºè¦‹](https://developer.apple.com/videos/play/wwdc2024/10163/?time=45){:target="_blank"}](/assets/755509180ca8/1*8N5GtY1uqxP-4iAAAticOA.png)

[Visionãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®Swiftå¼·åŒ–ã‚’ç™ºè¦‹ã™ã‚‹](https://developer.apple.com/videos/play/wwdc2024/10163/?time=45){:target="_blank"}

> *æœ¬è¨˜äº‹ã¯ WWDC 24 â€” [Discover Swift enhancements in the Vision framework](https://developer.apple.com/videos/play/wwdc2024/10163/?time=45){:target="_blank"} ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å…±æœ‰ãƒ¡ãƒ¢ã¨ã€è‡ªèº«ã®å®Ÿé¨“çµæœã®ã¾ã¨ã‚ã§ã™ã€‚*

### ã¯ã˜ã‚ã« â€” Visionãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ç‰¹å¾´

#### é¡”èªè­˜ã€è¼ªéƒ­æ¤œå‡º

![](/assets/755509180ca8/1*RNGfE_EeaQhiKAPdJeFYQw.png)

![](/assets/755509180ca8/1*iMdzeLm2aWjATVV6_Kvrjg.png)

#### ç”»åƒå†…ãƒ†ã‚­ã‚¹ãƒˆèªè­˜

iOS 18 ã¾ã§ã«ã€18è¨€èªã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚

![](/assets/755509180ca8/1*kU_OYn5w368h-ahDYU4lDw.png)

```swift
// ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹è¨€èªä¸€è¦§
if #available(iOS 18.0, *) {
  print(RecognizeTextRequest().supportedRecognitionLanguages.map { "\($0.languageCode!)-\(($0.region?.identifier ?? $0.script?.identifier)!)" })
} else {
  print(try! VNRecognizeTextRequest().supportedRecognitionLanguages())
}

// å®Ÿéš›ã«ä½¿ç”¨å¯èƒ½ãªèªè­˜è¨€èªã¯ã“ã¡ã‚‰ãŒåŸºæº–ã§ã™ã€‚
// å®Ÿæ©Ÿãƒ†ã‚¹ãƒˆã§iOS 18ã®å‡ºåŠ›çµæœï¼š
// ["en-US", "fr-FR", "it-IT", "de-DE", "es-ES", "pt-BR", "zh-Hans", "zh-Hant", "yue-Hans", "yue-Hant", "ko-KR", "ja-JP", "ru-RU", "uk-UA", "th-TH", "vi-VT", "ar-SA", "ars-SA"]
// WWDCã§è¨€åŠã•ã‚ŒãŸSwedishè¨€èªã¯è¦‹å½“ãŸã‚Šã¾ã›ã‚“ã€‚ã¾ã ãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã¦ã„ãªã„ã‹ã€ãƒ‡ãƒã‚¤ã‚¹ã®åœ°åŸŸãƒ»è¨€èªè¨­å®šã«é–¢é€£ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
```

#### å‹•çš„ãªå‹•ä½œã‚­ãƒ£ãƒ—ãƒãƒ£

![](/assets/755509180ca8/1*6TfyCcszdD1NdId0bdM16Q.gif)

![](/assets/755509180ca8/1*8y_XXdH36uKpfP0p6BCJQA.gif)

- äººã‚„ç‰©ä½“ã®å‹•çš„ãªè¿½è·¡ãŒå¯èƒ½ã§ã™

- ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã‚­ãƒ£ãƒ—ãƒãƒ£ã§ç©ºä¸­ç½²åæ©Ÿèƒ½ã‚’å®Ÿç¾ã™ã‚‹

#### Visionã®æ–°æ©Ÿèƒ½ (iOS 18)â€” ç”»åƒè©•ä¾¡æ©Ÿèƒ½ï¼ˆå“è³ªã€ç‰¹å¾´ç‚¹ï¼‰

- å…¥åŠ›ç”»åƒã«ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã€å„ªã‚ŒãŸå†™çœŸã‚’é¸ã³ã‚„ã™ãã—ã¾ã™

- ã‚¹ã‚³ã‚¢ã®è¨ˆç®—æ–¹æ³•ã¯è¤‡æ•°ã®è¦ç´ ã‚’å«ã¿ã€ç”»è³ªã ã‘ã§ãªãã€å…‰ã®çŠ¶æ…‹ã€è§’åº¦ã€æ’®å½±å¯¾è±¡ã€**è¨˜æ†¶ã«æ®‹ã‚‹ãƒã‚¤ãƒ³ãƒˆãŒã‚ã‚‹ã‹ã©ã†ã‹**ã‚‚è€ƒæ…®ã•ã‚Œã¾ã™ã€‚

![](/assets/755509180ca8/1*XwjeaHcB6arxJhIR7cFsWg.png)

![](/assets/755509180ca8/1*YdhZlZBlTaIZd4nLxhBtaQ.png)

![](/assets/755509180ca8/1*IhMDFdk6DWwTv1qIG0Gi0Q.png)

WWDCã§ã¯åŒã˜ç”»è³ªã§ã€ä¸Šè¨˜ã®3æšã®ç”»åƒã‚’ä½¿ã£ã¦èª¬æ˜ã—ã¾ã—ãŸã€‚

- é«˜è©•ä¾¡ã®ç”»åƒï¼šæ§‹å›³ã€å…‰ã€è¨˜æ†¶ã«æ®‹ã‚‹ãƒã‚¤ãƒ³ãƒˆ

- ä½è©•ä¾¡ã®ç”»åƒï¼šä¸»é¡ŒãŒãªãã€æ‰‹è»½ã«æ’®ã£ãŸã‚Šä¸æ³¨æ„ã§æ’®ã£ãŸã‚ˆã†ãªã‚‚ã®

- ç´ æã®ç”»åƒï¼šæŠ€è¡“çš„ã«ã¯ã‚ˆãæ’®ã‚Œã¦ã„ã‚‹ãŒã€å°è±¡ã«æ®‹ã‚‰ãšã€ç´ æãƒ©ã‚¤ãƒ–ãƒ©ãƒªç”¨ã®ç”»åƒã®ã‚ˆã†ãªã‚‚ã®

**iOS â‰¥ 18 æ–°API: [CalculateImageAestheticsScoresRequest](https://developer.apple.com/documentation/vision/calculateimageaestheticsscoresrequest){:target="_blank"}**

```swift
let request = CalculateImageAestheticsScoresRequest()
let result = try await request.perform(on: URL(string: "https://zhgchg.li/assets/cb65fd5ab770/1*yL3vI1ADzwlovctW5WQgJw.jpeg")!)

// å†™çœŸã®ã‚¹ã‚³ã‚¢
print(result.overallScore)

// ç´ æç”»åƒã¨åˆ¤å®šã•ã‚ŒãŸã‹ã©ã†ã‹
print(result.isUtility)
```

#### Visionã®æ–°æ©Ÿèƒ½ï¼ˆiOS 18ï¼‰â€” ä½“ï¼‹ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ãƒãƒ¼ã‚ºã®åŒæ™‚æ¤œå‡º

![](/assets/755509180ca8/1*A9320aRV-jdccgiXrmSrJw.png)

ã“ã‚Œã¾ã§ã¯äººä½“ã®ãƒãƒ¼ã‚ºã¨æ‰‹ã®ãƒãƒ¼ã‚ºã‚’å€‹åˆ¥ã«æ¤œå‡ºã™ã‚‹ã—ã‹ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸãŒã€ä»Šå›ã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã§é–‹ç™ºè€…ã¯èº«ä½“ã®ãƒãƒ¼ã‚ºã¨æ‰‹ã®ãƒãƒ¼ã‚ºã‚’åŒæ™‚ã«æ¤œå‡ºã—ã€åŒã˜ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¨çµæœã¨ã—ã¦çµ±åˆã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚ˆã‚Šå¤šãã®å¿œç”¨æ©Ÿèƒ½ã®é–‹ç™ºãŒå®¹æ˜“ã«ãªã‚Šã¾ã™ã€‚

**iOS â‰¥ 18 æ–°API: [DetectHumanBodyPoseRequest](https://developer.apple.com/documentation/vision/detecthumanbodyposerequest){:target="_blank"}**

```swift
var request = DetectHumanBodyPoseRequest()
// æ‰‹ã®ãƒãƒ¼ã‚ºã‚‚åŒæ™‚ã«æ¤œå‡ºã™ã‚‹
request.detectsHands = true

guard let bodyPose = try await request.perform(on: image).first else { return }

// ä½“ã®ãƒãƒ¼ã‚ºã®é–¢ç¯€
let bodyJoints = bodyPose.allJoints()
// å·¦æ‰‹ã®ãƒãƒ¼ã‚ºã®é–¢ç¯€
let leftHandJoints = bodyPose.leftHand.allJoints()
// å³æ‰‹ã®ãƒãƒ¼ã‚ºã®é–¢ç¯€
let rightHandJoints = bodyPose.rightHand.allJoints()
```

### æ–°ã—ã„ Vision API

Apple ã¯ä»Šå›ã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã§ã€æ–°ã—ã„ Swift Vision API ã‚’é–‹ç™ºè€…å‘ã‘ã«æä¾›ã—ã¾ã—ãŸã€‚åŸºæœ¬çš„ãªå¾“æ¥ã®æ©Ÿèƒ½ã‚µãƒãƒ¼ãƒˆã«åŠ ãˆã€ä¸»ã« Swift 6 / Swift Concurrency ã®ç‰¹æ€§ã‚’å¼·åŒ–ã—ã€ã‚ˆã‚Šé«˜æ€§èƒ½ã§ã‚ˆã‚Š Swift ã‚‰ã—ã„ API æ“ä½œæ–¹æ³•ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚

### Visionã®ä½¿ã„å§‹ã‚æ–¹

![](/assets/755509180ca8/1*mv9g5jmqrS6YScxoGYJemQ.png)

![](/assets/755509180ca8/1*iidNN7nKHoskh_tcjfuHKQ.png)

ã“ã“ã§è¬›æ¼”è€…ã¯å†ã³Vision frameworkã®åŸºæœ¬çš„ãªä½¿ã„æ–¹ã‚’ç´¹ä»‹ã—ã¾ã—ãŸã€‚Appleã¯ã™ã§ã«[31ç¨®é¡](https://developer.apple.com/documentation/vision/visionrequest){:target="_blank"}ï¼ˆiOS 18æ™‚ç‚¹ï¼‰ã®ä¸€èˆ¬çš„ãªç”»åƒèªè­˜ãƒªã‚¯ã‚¨ã‚¹ãƒˆã€ŒRequestã€ã¨å¯¾å¿œã™ã‚‹ã€ŒObservationã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ãƒ©ãƒƒãƒ—ã—ã¦ã„ã¾ã™ã€‚

1. **Request:** DetectFaceRectanglesRequest é¡”é ˜åŸŸæ¤œå‡ºãƒªã‚¯ã‚¨ã‚¹ãƒˆ  
   **Result:** FaceObservation  
   ä»¥å‰ã®è¨˜äº‹ã€Œ [Vision åˆæ¢ â€” APP ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ è‡ªå‹•é¡”æ¤œå‡ºãƒˆãƒªãƒŸãƒ³ã‚° (Swift)](../9a9aa892f9a9/) ã€ã§ã“ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä½¿ã£ã¦ã„ã¾ã™ã€‚

2. **Request:** RecognizeTextRequest æ–‡å­—èªè­˜ãƒªã‚¯ã‚¨ã‚¹ãƒˆ  
   **Result:** RecognizedTextObservation

3. **Request:** GenerateObjectnessBasedSaliencyImageRequest ä¸»ä½“ç‰©ä½“èªè­˜ãƒªã‚¯ã‚¨ã‚¹ãƒˆ  
   **Result:** SaliencyImageObservation

### å…¨éƒ¨ 31 ç¨®ãƒªã‚¯ã‚¨ã‚¹ãƒˆ Requestï¼š

[VisionRequest](https://developer.apple.com/documentation/vision/visionrequest){:target="_blank"} ã€‚

\\| Request ç”¨é€”                                 \\| Observation èª¬æ˜                                                  \\|
\\|-----------------------------------------------\\|------------------------------------------------------------------\\|
\\| CalculateImageAestheticsScoresRequest<br/>ç”»åƒã®ç¾çš„ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã¾ã™ã€‚                                 \\| AestheticsObservation<br/>æ§‹å›³ã‚„è‰²å½©ãªã©ã®è¦ç´ ã‚’å«ã‚€ç”»åƒã®ç¾çš„è©•ä¾¡ã‚¹ã‚³ã‚¢ã‚’è¿”ã—ã¾ã™ã€‚                           \\|
\\| ClassifyImageRequest<br/>ç”»åƒå†…å®¹ã‚’åˆ†é¡ã—ã¾ã™ã€‚                                      \\| ClassificationObservation<br/>ç”»åƒå†…ã®ç‰©ä½“ã‚„ã‚·ãƒ¼ãƒ³ã®åˆ†é¡ãƒ©ãƒ™ãƒ«ã¨ä¿¡é ¼åº¦ã‚’è¿”ã—ã¾ã™ã€‚                           \\|
\\| CoreMLRequest<br/>Core MLãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ç”»åƒã‚’è§£æã—ã¾ã™ã€‚                          \\| CoreMLFeatureValueObservation<br/>Core MLãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›çµæœã«åŸºã¥ãè¦³å¯Ÿçµæœã‚’ç”Ÿæˆã—ã¾ã™ã€‚                            \\|
\\| DetectAnimalBodyPoseRequest<br/>ç”»åƒå†…ã®å‹•ç‰©ã®å§¿å‹¢ã‚’æ¤œå‡ºã—ã¾ã™ã€‚                               \\| RecognizedPointsObservation<br/>å‹•ç‰©ã®éª¨æ ¼ç‚¹ã¨ãã®ä½ç½®ã‚’è¿”ã—ã¾ã™ã€‚                                         \\|
\\| DetectBarcodesRequest<br/>ç”»åƒå†…ã®ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã‚’æ¤œå‡ºã—ã¾ã™ã€‚                                   \\| BarcodeObservation<br/>ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã®ãƒ‡ãƒ¼ã‚¿ã¨ç¨®é¡ï¼ˆQRã‚³ãƒ¼ãƒ‰ãªã©ï¼‰ã‚’è¿”ã—ã¾ã™ã€‚                                 \\|
\\| DetectContoursRequest<br/>ç”»åƒå†…ã®è¼ªéƒ­ã‚’æ¤œå‡ºã—ã¾ã™ã€‚                                   \\| ContoursObservation<br/>ç”»åƒã§æ¤œå‡ºã•ã‚ŒãŸè¼ªéƒ­ç·šã‚’è¿”ã—ã¾ã™ã€‚                                         \\|
\\| DetectDocumentSegmentationRequest<br/>ç”»åƒå†…ã®æ–‡æ›¸ã‚’æ¤œå‡ºãƒ»åˆ†å‰²ã—ã¾ã™ã€‚                             \\| RectangleObservation<br/>æ–‡æ›¸ã®å¢ƒç•Œã®çŸ©å½¢ä½ç½®ã‚’è¿”ã—ã¾ã™ã€‚                                         \\|
\\| DetectFaceCaptureQualityRequest<br/>é¡”ã®ã‚­ãƒ£ãƒ—ãƒãƒ£å“è³ªã‚’è©•ä¾¡ã—ã¾ã™ã€‚                                   \\| FaceObservation<br/>é¡”ç”»åƒã®å“è³ªè©•ä¾¡ã‚¹ã‚³ã‚¢ã‚’è¿”ã—ã¾ã™ã€‚                                       \\|
\\| DetectFaceLandmarksRequest<br/>é¡”ã®ç‰¹å¾´ç‚¹ã‚’æ¤œå‡ºã—ã¾ã™ã€‚                                     \\| FaceObservation<br/>ç›®ã‚„é¼»ãªã©ã®é¡”ã®ç‰¹å¾´ç‚¹ã®è©³ç´°ãªä½ç½®ã‚’è¿”ã—ã¾ã™ã€‚                       \\|
\\| DetectFaceRectanglesRequest<br/>ç”»åƒå†…ã®é¡”ã‚’æ¤œå‡ºã—ã¾ã™ã€‚                                   \\| FaceObservation<br/>é¡”ã®å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹ã®ä½ç½®ã‚’è¿”ã—ã¾ã™ã€‚                                             \\|
\\| DetectHorizonRequest<br/>ç”»åƒå†…ã®åœ°å¹³ç·šã‚’æ¤œå‡ºã—ã¾ã™ã€‚                                 \\| HorizonObservation<br/>åœ°å¹³ç·šã®è§’åº¦ã¨ä½ç½®ã‚’è¿”ã—ã¾ã™ã€‚                                           \\|
\\| DetectHumanBodyPose3DRequest<br/>ç”»åƒå†…ã®3Däººä½“å§¿å‹¢ã‚’æ¤œå‡ºã—ã¾ã™ã€‚                           \\| RecognizedPointsObservation<br/>3Däººä½“ã®éª¨æ ¼ç‚¹ã¨ç©ºé–“åº§æ¨™ã‚’è¿”ã—ã¾ã™ã€‚                                    \\|
\\| DetectHumanBodyPoseRequest<br/>ç”»åƒå†…ã®äººä½“å§¿å‹¢ã‚’æ¤œå‡ºã—ã¾ã™ã€‚                               \\| RecognizedPointsObservation<br/>äººä½“ã®éª¨æ ¼ç‚¹ã¨ãã®åº§æ¨™ã‚’è¿”ã—ã¾ã™ã€‚                                           \\|
\\| DetectHumanHandPoseRequest<br/>ç”»åƒå†…ã®æ‰‹ã®å§¿å‹¢ã‚’æ¤œå‡ºã—ã¾ã™ã€‚                               \\| RecognizedPointsObservation<br/>æ‰‹ã®éª¨æ ¼ç‚¹ã¨ãã®ä½ç½®ã‚’è¿”ã—ã¾ã™ã€‚                                           \\|
\\| DetectHumanRectanglesRequest<br/>ç”»åƒå†…ã®äººä½“ã‚’æ¤œå‡ºã—ã¾ã™ã€‚                                   \\| HumanObservation<br/>äººä½“ã®å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹ã®ä½ç½®ã‚’è¿”ã—ã¾ã™ã€‚                                             \\|
\\| DetectRectanglesRequest<br/>ç”»åƒå†…ã®çŸ©å½¢ã‚’æ¤œå‡ºã—ã¾ã™ã€‚                                   \\| RectangleObservation<br/>çŸ©å½¢ã®4ã¤ã®é ‚ç‚¹åº§æ¨™ã‚’è¿”ã—ã¾ã™ã€‚                                           \\|
\\| DetectTextRectanglesRequest<br/>ç”»åƒå†…ã®ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸã‚’æ¤œå‡ºã—ã¾ã™ã€‚                               \\| TextObservation<br/>ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸã®ä½ç½®ã¨å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹ã‚’è¿”ã—ã¾ã™ã€‚                                       \\|
\\| DetectTrajectoriesRequest<br/>ç‰©ä½“ã®å‹•ãã®è»Œè·¡ã‚’æ¤œå‡ºãƒ»è§£æã—ã¾ã™ã€‚                             \\| TrajectoryObservation<br/>å‹•ãã®è»Œè·¡ç‚¹ã¨æ™‚é–“ç³»åˆ—ã‚’è¿”ã—ã¾ã™ã€‚                                       \\|
\\| GenerateAttentionBasedSaliencyImageRequest<br/>æ³¨æ„ã«åŸºã¥ãé¡•è‘—æ€§ç”»åƒã‚’ç”Ÿæˆã—ã¾ã™ã€‚                         \\| SaliencyImageObservation<br/>ç”»åƒå†…ã§æœ€ã‚‚æ³¨ç›®ã•ã‚Œã‚‹é ˜åŸŸã®é¡•è‘—æ€§ãƒãƒƒãƒ—ã‚’è¿”ã—ã¾ã™ã€‚                             \\|
\\| GenerateForegroundInstanceMaskRequest<br/>å‰æ™¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒã‚¹ã‚¯ç”»åƒã‚’ç”Ÿæˆã—ã¾ã™ã€‚                               \\| InstanceMaskObservation<br/>å‰æ™¯ç‰©ä½“ã®ãƒã‚¹ã‚¯ã‚’è¿”ã—ã¾ã™ã€‚                                               \\|
\\| GenerateImageFeaturePrintRequest<br/>æ¯”è¼ƒç”¨ã®ç”»åƒç‰¹å¾´ãƒ—ãƒªãƒ³ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚                         \\| FeaturePrintObservation<br/>é¡ä¼¼åº¦æ¯”è¼ƒã«ä½¿ã†ç”»åƒã®ç‰¹å¾´ãƒ—ãƒªãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã—ã¾ã™ã€‚                           \\|
\\| GenerateObjectnessBasedSaliencyImageRequest<br/>ç‰©ä½“ã®é¡•è‘—æ€§ã«åŸºã¥ãç”»åƒã‚’ç”Ÿæˆã—ã¾ã™ã€‚                           \\| SaliencyImageObservation<br/>ç‰©ä½“ã®é¡•è‘—æ€§é ˜åŸŸã®é¡•è‘—æ€§ãƒãƒƒãƒ—ã‚’è¿”ã—ã¾ã™ã€‚                                   \\|
\\| GeneratePersonInstanceMaskRequest<br/>äººç‰©ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒã‚¹ã‚¯ç”»åƒã‚’ç”Ÿæˆã—ã¾ã™ã€‚                               \\| InstanceMaskObservation<br/>äººç‰©ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ãƒã‚¹ã‚¯ã‚’è¿”ã—ã¾ã™ã€‚                                               \\|
\\| GeneratePersonSegmentationRequest<br/>äººç‰©ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”»åƒã‚’ç”Ÿæˆã—ã¾ã™ã€‚                                   \\| SegmentationObservation<br/>äººç‰©ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³äºŒå€¤ç”»åƒã‚’è¿”ã—ã¾ã™ã€‚                                             \\|
\\| RecognizeAnimalsRequest<br/>ç”»åƒå†…ã®å‹•ç‰©ã‚’æ¤œå‡ºãƒ»è­˜åˆ¥ã—ã¾ã™ã€‚                             \\| RecognizedObjectObservation<br/>å‹•ç‰©ã®ç¨®é¡ã¨ä¿¡é ¼åº¦ã‚’è¿”ã—ã¾ã™ã€‚                                           \\|
\\| RecognizeTextRequest<br/>ç”»åƒå†…ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¤œå‡ºãƒ»èªè­˜ã—ã¾ã™ã€‚                             \\| RecognizedTextObservation<br/>æ¤œå‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã¨ãã®é ˜åŸŸä½ç½®ã‚’è¿”ã—ã¾ã™ã€‚                                 \\|
\\| TrackHomographicImageRegistrationRequest<br/>åŒæ¬¡ç”»åƒç™»éŒ²ã‚’è¿½è·¡ã—ã¾ã™ã€‚                             \\| ImageAlignmentObservation<br/>ç”»åƒé–“ã®åŒæ¬¡å¤‰æ›è¡Œåˆ—ã‚’è¿”ã—ã€ç”»åƒç™»éŒ²ã«ä½¿ç”¨ã—ã¾ã™ã€‚                           \\|
\\| TrackObjectRequest<br/>ç”»åƒå†…ã®ç‰©ä½“ã‚’è¿½è·¡ã—ã¾ã™ã€‚                                   \\| DetectedObjectObservation<br/>ç‰©ä½“ã®ç”»åƒå†…ä½ç½®ã¨é€Ÿåº¦æƒ…å ±ã‚’è¿”ã—ã¾ã™ã€‚                                 \\|
\\| TrackOpticalFlowRequest<br/>ç”»åƒå†…ã®ã‚ªãƒ—ãƒ†ã‚£ã‚«ãƒ«ãƒ•ãƒ­ãƒ¼ã‚’è¿½è·¡ã—ã¾ã™ã€‚                                   \\| OpticalFlowObservation<br/>ãƒ”ã‚¯ã‚»ãƒ«ã®ç§»å‹•ã‚’è¡¨ã™ã‚ªãƒ—ãƒ†ã‚£ã‚«ãƒ«ãƒ•ãƒ­ãƒ¼ã®ãƒ™ã‚¯ãƒˆãƒ«å ´ã‚’è¿”ã—ã¾ã™ã€‚                             \\|
\\| TrackRectangleRequest<br/>ç”»åƒå†…ã®çŸ©å½¢ã‚’è¿½è·¡ã—ã¾ã™ã€‚                                   \\| RectangleObservation<br/>çŸ©å½¢ã®ä½ç½®ã€å¤§ãã•ã€å›è»¢è§’åº¦ã‚’è¿”ã—ã¾ã™ã€‚                           \\|
\\| TrackTranslationalImageRegistrationRequest<br/>å¹³è¡Œç§»å‹•ç”»åƒç™»éŒ²ã‚’è¿½è·¡ã—ã¾ã™ã€‚                             \\| ImageAlignmentObservation<br/>ç”»åƒé–“ã®å¹³è¡Œç§»å‹•å¤‰æ›è¡Œåˆ—ã‚’è¿”ã—ã€ç”»åƒç™»éŒ²ã«ä½¿ç”¨ã—ã¾ã™ã€‚                           \\|

- VNã‚’å‰ã«ä»˜ã‘ã‚‹ã®ã¯æ—§APIã®æ›¸ãæ–¹ã§ã™ï¼ˆiOS 18ä»¥å‰ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼‰

è¬›æ¼”è€…ã¯ã„ãã¤ã‹ã®ã‚ˆãä½¿ã‚ã‚Œã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«ã¤ã„ã¦è¨€åŠã—ã¾ã—ãŸã€‚ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

#### ClassifyImageRequest

å…¥åŠ›ç”»åƒã‚’èªè­˜ã—ã€ãƒ©ãƒ™ãƒ«åˆ†é¡ã¨ä¿¡é ¼åº¦ã‚’å–å¾—ã—ã¾ã™ã€‚

![](/assets/755509180ca8/1*8NSQEjxGejujKLbXcILmxQ.jpeg)

![[éŠè¨˜] 2024 ä¹å·å†è¨ª 9æ—¥é–“è‡ªç”±æ—…è¡Œã€é‡œå±±çµŒç”±â†’åšå¤šã‚¯ãƒ«ãƒ¼ã‚ºå…¥å›½](/assets/755509180ca8/1*f1rNoOIQbE33M9F9NmoTXg.png)

[æ—…è¡Œè¨˜] 2024å¹´ ä¹å·å†è¨ª 9æ—¥é–“ã®è‡ªç”±æ—…è¡Œã€é‡œå±±çµŒç”±â†’åšå¤šã‚¯ãƒ«ãƒ¼ã‚ºå…¥å›½

```swift
if #available(iOS 18.0, *) {
    // Swiftã®æ–°æ©Ÿèƒ½ã‚’ä½¿ã£ãŸæ–°ã—ã„API
    let request = ClassifyImageRequest()
    Task {
        do {
            let observations = try await request.perform(on: URL(string: "https://zhgchg.li/assets/cb65fd5ab770/1*yL3vI1ADzwlovctW5WQgJw.jpeg")!)
            observations.forEach {
                observation in
                print("\(observation.identifier): \(observation.confidence)")
            }
        }
        catch {
            print("ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: \(error)")
        }
    }
} else {
    // ä»¥å‰ã®æ›¸ãæ–¹
    let completionHandler: VNRequestCompletionHandler = {
        request, error in
        guard error == nil else {
            print("ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: \(String(describing: error))")
            return
        }
        guard let observations = request.results as? [VNClassificationObservation] else {
            return
        }
        observations.forEach {
            observation in
            print("\(observation.identifier): \(observation.confidence)")
        }
    }

    let request = VNClassifyImageRequest(completionHandler: completionHandler)
    DispatchQueue.global().async {
        let handler = VNImageRequestHandler(url: URL(string: "https://zhgchg.li/assets/cb65fd5ab770/1*3_jdrLurFuUfNdW4BJaRww.jpeg")!, options: [:])
        do {
            try handler.perform([request])
        }
        catch {
            print("ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: \(error)")
        }
    }
}
```

**åˆ†æçµæœï¼š**

```r
 â€¢ outdoorï¼ˆå±‹å¤–ï¼‰: 0.75392926
 â€¢ skyï¼ˆç©ºï¼‰: 0.75392926
 â€¢ blue_skyï¼ˆé’ç©ºï¼‰: 0.7519531
 â€¢ machineï¼ˆæ©Ÿæ¢°ï¼‰: 0.6958008
 â€¢ cloudyï¼ˆæ›‡ã‚Šï¼‰: 0.26538086
 â€¢ structureï¼ˆæ§‹é€ ç‰©ï¼‰: 0.15728651
 â€¢ signï¼ˆæ¨™è­˜ï¼‰: 0.14224191
 â€¢ fenceï¼ˆãƒ•ã‚§ãƒ³ã‚¹ï¼‰: 0.118652344
 â€¢ bannerï¼ˆãƒãƒŠãƒ¼ï¼‰: 0.0793457
 â€¢ materialï¼ˆç´ æï¼‰: 0.075975396
 â€¢ plantï¼ˆæ¤ç‰©ï¼‰: 0.054406323
 â€¢ foliageï¼ˆè‘‰ï¼‰: 0.05029297
 â€¢ lightï¼ˆå…‰ï¼‰: 0.048126098
 â€¢ lamppostï¼ˆè¡—ç¯ï¼‰: 0.048095703
 â€¢ billboardsï¼ˆçœ‹æ¿ï¼‰: 0.040039062
 â€¢ artï¼ˆã‚¢ãƒ¼ãƒˆï¼‰: 0.03977703
 â€¢ branchï¼ˆæï¼‰: 0.03930664
 â€¢ decorationï¼ˆè£…é£¾ï¼‰: 0.036868922
 â€¢ flagï¼ˆæ——ï¼‰: 0.036865234
....ç•¥
```

#### RecognizeTextRequest

ç”»åƒå†…ã®æ–‡å­—ã‚’èªè­˜ã™ã‚‹ã€‚ï¼ˆåˆ¥åï¼šç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¸ï¼‰

![[[éŠè¨˜] 2023 æ±äº¬ 5 æ—¥è‡ªç”±è¡Œ](../9da2c51fa4f2/)](/assets/755509180ca8/1*XL40lLT774PfO60rCIfnxA.jpeg)

[[æ—…è¡Œè¨˜] 2023å¹´ æ±äº¬ 5æ—¥é–“è‡ªç”±æ—…è¡Œ](../9da2c51fa4f2/)

```swift
if #available(iOS 18.0, *) {
    // Swiftã®æ–°æ©Ÿèƒ½ã‚’ä½¿ã£ãŸæ–°ã—ã„API
    var request = RecognizeTextRequest()
    request.recognitionLevel = .accurate
    request.recognitionLanguages = [.init(identifier: "ja-JP"), .init(identifier: "en-US")] // è¨€èªã‚³ãƒ¼ãƒ‰ã‚’æŒ‡å®šã€ä¾‹ï¼šç¹ä½“å­—ä¸­å›½èª
    Task {
        do {
            let observations = try await request.perform(on: URL(string: "https://zhgchg.li/assets/9da2c51fa4f2/1*fBbNbDepYioQ-3-0XUkF6Q.jpeg")!)
            observations.forEach {
                observation in
                let topCandidate = observation.topCandidates(1).first
                print(topCandidate?.string ?? "ãƒ†ã‚­ã‚¹ãƒˆãŒèªè­˜ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            }
        }
        catch {
            print("ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: \(error)")
        }
    }
} else {
    // æ—§APIã®æ›¸ãæ–¹
    let completionHandler: VNRequestCompletionHandler = {
        request, error in
        guard error == nil else {
            print("ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: \(String(describing: error))")
            return
        }
        guard let observations = request.results as? [VNRecognizedTextObservation] else {
            return
        }
        observations.forEach {
            observation in
            let topCandidate = observation.topCandidates(1).first
            print(topCandidate?.string ?? "ãƒ†ã‚­ã‚¹ãƒˆãŒèªè­˜ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        }
    }

    let request = VNRecognizeTextRequest(completionHandler: completionHandler)
    request.recognitionLevel = .accurate
    request.recognitionLanguages = ["ja-JP", "en-US"] // è¨€èªã‚³ãƒ¼ãƒ‰ã‚’æŒ‡å®šã€ä¾‹ï¼šç¹ä½“å­—ä¸­å›½èª
    DispatchQueue.global().async {
        let handler = VNImageRequestHandler(url: URL(string: "https://zhgchg.li/assets/9da2c51fa4f2/1*fBbNbDepYioQ-3-0XUkF6Q.jpeg")!, options: [:])
        do {
            try handler.perform([request])
        }
        catch {
            print("ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: \(error)")
        }
    }
}
```

**åˆ†æçµæœï¼š**

```makefile
LE LABO é’å±±åº—
TEL:03-6419-7167
ï¼ŠãŠè²·ã„ä¸Šã’ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™*
No: 21347
æ—¥ä»˜ï¼š2023/06/10 14.14.57
æ‹…å½“ï¼š
1690370
ãƒ¬ã‚¸ï¼š008A 1
å•†å“å
ç¨è¾¼ä¸Šä»£æ•°é‡ç¨è¾¼åˆè¨ˆ
ã‚«ã‚¤ã‚¢ãƒƒã‚¯ 10 EDP FB 15ML
J1P7010000S
16,800
16,800
ã‚¢ãƒŠã‚¶ãƒ¼ 13 EDP FB 15ML
J1PJ010000S
10,700
10,700
ãƒªãƒƒãƒ—ãƒ‘ãƒ¼ãƒ  15ML
JOWC010000S
2,000
1
åˆè¨ˆé‡‘é¡
ï¼ˆå†…ç¨é¡ï¼‰
CARD
2,000
3ç‚¹å¾¡è²·ä¸Šã’
29,500
0
29,500
29,500
```

#### DetectBarcodesRequest

ç”»åƒå†…ã®ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã‚„QRã‚³ãƒ¼ãƒ‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œå‡ºã™ã‚‹ã€‚

![](/assets/755509180ca8/1*Z72y9rIwIKQCmnnuwsq0uQ.png)

![ã‚¿ã‚¤ç¾åœ°ã®äººãŒãŠã™ã™ã‚ã™ã‚‹ã‚¬ãƒãƒ§ã‚¦å°ã‚¯ãƒ¼ãƒ«ãƒãƒ¼ãƒ ](/assets/755509180ca8/1*s3V1UQRIqto-iG1e30PK7Q.jpeg)

ã‚¿ã‚¤ã®åœ°å…ƒæ°‘ãŒãŠã™ã™ã‚ã™ã‚‹ã‚¬ãƒãƒ§ã‚¦ãƒãƒ¼ãƒ 

```swift
let filePath = Bundle.main.path(forResource: "IMG_6777", ofType: "png")! // ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆç”»åƒ
let fileURL = URL(filePath: filePath)
if #available(iOS 18.0, *) {
    // Swiftã®æ–°æ©Ÿèƒ½ã‚’ä½¿ã£ãŸæ–°ã—ã„API
    let request = DetectBarcodesRequest()
    Task {
        do {
            let observations = try await request.perform(on: fileURL)
            observations.forEach {
                observation in
                print("Payload: \(observation.payloadString ?? "ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ãªã—")")
                print("Symbology: \(observation.symbology)")
            }
        }
        catch {
            print("ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: \(error)")
        }
    }
} else {
    // æ—§æ–¹å¼
    let completionHandler: VNRequestCompletionHandler = {
        request, error in
        guard error == nil else {
            print("ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: \(String(describing: error))")
            return
        }
        guard let observations = request.results as? [VNBarcodeObservation] else {
            return
        }
        observations.forEach {
            observation in
            print("Payload: \(observation.payloadStringValue ?? "ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ãªã—")")
            print("Symbology: \(observation.symbology.rawValue)")
        }
    }

    let request = VNDetectBarcodesRequest(completionHandler: completionHandler)
    DispatchQueue.global().async {
        let handler = VNImageRequestHandler(url: fileURL, options: [:])
        do {
            try handler.perform([request])
        }
        catch {
            print("ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: \(error)")
        }
    }
}
```

**åˆ†æçµæœï¼š**

```makefile
Payload: 8859126000911
Symbology: VNBarcodeSymbologyEAN13
Payload: https://lin.ee/hGynbVM
Symbology: VNBarcodeSymbologyQR
Payload: http://www.hongthaipanich.com/
Symbology: VNBarcodeSymbologyQR
Payload: https://www.facebook.com/qr?id=100063856061714
Symbology: VNBarcodeSymbologyQR
```

#### RecognizeAnimalsRequest

ç”»åƒå†…ã®å‹•ç‰©ã¨ä¿¡é ¼åº¦ã‚’èªè­˜ã™ã‚‹ã€‚

![](/assets/755509180ca8/1*5zF3gA3WB1Q0-_cgt6mTCw.png)

![[meme Source](https://www.redbubble.com/i/canvas-print/Funny-AI-Woman-yelling-at-a-cat-meme-design-Machine-learning-by-omolog/43039298.5Y5V7){:target="_blank"}](/assets/755509180ca8/1*KZ7mdE8fobP-_oj7tJf_Ww.jpeg)

[meme Source](https://www.redbubble.com/i/canvas-print/Funny-AI-Woman-yelling-at-a-cat-meme-design-Machine-learning-by-omolog/43039298.5Y5V7){:target="_blank"}

```swift
let filePath = Bundle.main.path(forResource: "IMG_5026", ofType: "png")! // ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆç”»åƒ
let fileURL = URL(filePath: filePath)
if #available(iOS 18.0, *) {
    // Swiftã®æ–°æ©Ÿèƒ½ã‚’ä½¿ã£ãŸæ–°ã—ã„API
    let request = RecognizeAnimalsRequest()
    Task {
        do {
            let observations = try await request.perform(on: fileURL)
            observations.forEach {
                observation in
                let labels = observation.labels
                labels.forEach {
                    label in
                    print("æ¤œå‡ºã•ã‚ŒãŸå‹•ç‰©: \(label.identifier)ã€ä¿¡é ¼åº¦: \(label.confidence)")
                }
            }
        }
        catch {
            print("ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: \(error)")
        }
    }
} else {
    // æ—§APIã®æ›¸ãæ–¹
    let completionHandler: VNRequestCompletionHandler = {
        request, error in
        guard error == nil else {
            print("ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: \(String(describing: error))")
            return
        }
        guard let observations = request.results as? [VNRecognizedObjectObservation] else {
            return
        }
        observations.forEach {
            observation in
            let labels = observation.labels
            labels.forEach {
                label in
                print("æ¤œå‡ºã•ã‚ŒãŸå‹•ç‰©: \(label.identifier)ã€ä¿¡é ¼åº¦: \(label.confidence)")
            }
        }
    }

    let request = VNRecognizeAnimalsRequest(completionHandler: completionHandler)
    DispatchQueue.global().async {
        let handler = VNImageRequestHandler(url: fileURL, options: [:])
        do {
            try handler.perform([request])
        }
        catch {
            print("ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: \(error)")
        }
    }
}
```

åˆ†æçµæœï¼š

```csharp
Detected animal: Cat with confidence: 0.77245045
```

#### ãã®ä»–ï¼š

- ç”»åƒå†…ã®äººä½“ã‚’æ¤œå‡ºã™ã‚‹ï¼šDetectHumanRectanglesRequest

- äººã‚„å‹•ç‰©ã®ãƒãƒ¼ã‚ºæ¤œå‡ºï¼ˆ3Dã¾ãŸã¯2Då¯¾å¿œï¼‰ï¼šDetectAnimalBodyPoseRequestã€DetectHumanBodyPose3DRequestã€DetectHumanBodyPoseRequestã€DetectHumanHandPoseRequest

- ç‰©ä½“ã®å‹•ãã®è»Œè·¡ã‚’æ¤œå‡ºãŠã‚ˆã³è¿½è·¡ã™ã‚‹ï¼ˆå‹•ç”»ã‚„ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã®ç•°ãªã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ã§ï¼‰ï¼šDetectTrajectoriesRequestã€TrackObjectRequestã€TrackRectangleRequest

#### **iOS â‰¥ 18 ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã®ãƒã‚¤ãƒ©ã‚¤ãƒˆï¼š**

```rust
VN*Request -> *Request ï¼ˆä¾‹ï¼šVNDetectBarcodesRequest -> DetectBarcodesRequestï¼‰
VN*Observation -> *Observation ï¼ˆä¾‹ï¼šVNRecognizedObjectObservation -> RecognizedObjectObservationï¼‰
VNRequestCompletionHandler -> async/await
VNImageRequestHandler.perform([VN*Request]) -> *Request.perform()
```

### WWDCã®ä¾‹

WWDCå…¬å¼å‹•ç”»ã§ã¯ã€ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒãƒ¼ã‚±ãƒƒãƒˆã®å•†å“ã‚¹ã‚­ãƒ£ãƒŠãƒ¼ã‚’ä¾‹ã«æŒ™ã’ã¦ã„ã¾ã™ã€‚

#### ã¾ãšã»ã¨ã‚“ã©ã®å•†å“ã«ã¯ã‚¹ã‚­ãƒ£ãƒ³å¯èƒ½ãªãƒãƒ¼ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã™

![](/assets/755509180ca8/1*YT_Uf8eEi36Iv7zcOrmP4A.png)

![](/assets/755509180ca8/1*J9uIwRKubLoJoC7i096AdQ.png)

![](/assets/755509180ca8/1*gKg-NfHYqy7uBqe5hxzBSw.png)

`observation.boundingBox` ã‹ã‚‰ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã®ä½ç½®ã‚’å–å¾—ã§ãã¾ã™ãŒã€ä¸€èˆ¬çš„ãª UIView åº§æ¨™ç³»ã¨ã¯ç•°ãªã‚Šã€`BoundingBox` ã®ç›¸å¯¾ä½ç½®ã®èµ·ç‚¹ã¯å·¦ä¸‹ã§ã€å€¤ã®ç¯„å›²ã¯0ã€œ1ã®é–“ã§ã™ã€‚

```swift
let filePath = Bundle.main.path(forResource: "IMG_6785", ofType: "png")! // ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆç”»åƒ
let fileURL = URL(filePath: filePath)
if #available(iOS 18.0, *) {
    // Swiftã®æ–°æ©Ÿèƒ½ã‚’ä½¿ã£ãŸæ–°ã—ã„API
    var request = DetectBarcodesRequest()
    request.symbologies = [.ean13] // EAN13ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã®ã¿ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã™ã‚‹å ´åˆã¯ç›´æ¥æŒ‡å®šã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Š
    Task {
        do {
            let observations = try await request.perform(on: fileURL)
            if let observation = observations.first {
                DispatchQueue.main.async {
                    self.infoLabel.text = observation.payloadString
                    // ãƒãƒ¼ã‚¯ç”¨ã®è‰²ãƒ¬ã‚¤ãƒ¤ãƒ¼
                    let colorLayer = CALayer()
                    // iOS >=18 æ–°ã—ã„åº§æ¨™å¤‰æ›API toImageCoordinates
                    // æœªæ¤œè¨¼ã§ã€å®Ÿéš›ã«ã¯ContentMode = AspectFitã®ã‚ªãƒ•ã‚»ãƒƒãƒˆè¨ˆç®—ãŒå¿…è¦ã‹ã‚‚:
                    colorLayer.frame = observation.boundingBox.toImageCoordinates(self.baseImageView.frame.size, origin: .upperLeft)
                    colorLayer.backgroundColor = UIColor.red.withAlphaComponent(0.5).cgColor
                    self.baseImageView.layer.addSublayer(colorLayer)
                }
                print("BoundingBox: \(observation.boundingBox.cgRect)")
                print("Payload: \(observation.payloadString ?? "No payload")")
                print("Symbology: \(observation.symbology)")
            }
        }
        catch {
            print("Request failed: \(error)")
        }
    }
} else {
    // æ—§APIã®æ›¸ãæ–¹
    let completionHandler: VNRequestCompletionHandler = {
        request, error in
        guard error == nil else {
            print("Request failed: \(String(describing: error))")
            return
        }
        guard let observations = request.results as? [VNBarcodeObservation] else {
            return
        }
        if let observation = observations.first {
            DispatchQueue.main.async {
                self.infoLabel.text = observation.payloadStringValue
                // ãƒãƒ¼ã‚¯ç”¨ã®è‰²ãƒ¬ã‚¤ãƒ¤ãƒ¼
                let colorLayer = CALayer()
                colorLayer.frame = self.convertBoundingBox(observation.boundingBox, to: self.baseImageView)
                colorLayer.backgroundColor = UIColor.red.withAlphaComponent(0.5).cgColor
                self.baseImageView.layer.addSublayer(colorLayer)
            }
            print("BoundingBox: \(observation.boundingBox)")
            print("Payload: \(observation.payloadStringValue ?? "No payload")")
            print("Symbology: \(observation.symbology.rawValue)")
        }
    }

    let request = VNDetectBarcodesRequest(completionHandler: completionHandler)
    request.symbologies = [.ean13] // EAN13ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã®ã¿ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã™ã‚‹å ´åˆã¯ç›´æ¥æŒ‡å®šã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Š
    DispatchQueue.global().async {
        let handler = VNImageRequestHandler(url: fileURL, options: [:])
        do {
            try handler.perform([request])
        }
        catch {
            print("Request failed: \(error)")
        }
    }
}
```

**iOS â‰¥ 18 ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã®ãƒã‚¤ãƒ©ã‚¤ãƒˆï¼š**

```less
// iOS >=18 æ–°ã—ã„åº§æ¨™å¤‰æ›API toImageCoordinates
observation.boundingBox.toImageCoordinates(CGSize, origin: .upperLeft)
// https://developer.apple.com/documentation/vision/normalizedpoint/toimagecoordinates(from:imagesize:origin:)
```

**ãƒ˜ãƒ«ãƒ‘ãƒ¼:**

```swift
// ChatGPT 4oã«ã‚ˆã£ã¦ç”Ÿæˆ
// ç”»åƒãŒImageViewã§ContentMode = AspectFitã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ãŸã‚
// Fitã«ã‚ˆã£ã¦ã§ãã‚‹ä¸Šä¸‹ã®ç©ºç™½ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’è¨ˆç®—ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
func convertBoundingBox(_ boundingBox: CGRect, to view: UIImageView) -> CGRect {
    guard let image = view.image else {
        return .zero
    }

    let imageSize = image.size
    let viewSize = view.bounds.size
    let imageRatio = imageSize.width / imageSize.height
    let viewRatio = viewSize.width / viewSize.height
    var scaleFactor: CGFloat
    var offsetX: CGFloat = 0
    var offsetY: CGFloat = 0
    if imageRatio > viewRatio {
        // ç”»åƒã¯å¹…æ–¹å‘ã«ãƒ•ã‚£ãƒƒãƒˆã—ã¦ã„ã‚‹
        scaleFactor = viewSize.width / imageSize.width
        offsetY = (viewSize.height - imageSize.height * scaleFactor) / 2
    }

    else {
        // ç”»åƒã¯é«˜ã•æ–¹å‘ã«ãƒ•ã‚£ãƒƒãƒˆã—ã¦ã„ã‚‹
        scaleFactor = viewSize.height / imageSize.height
        offsetX = (viewSize.width - imageSize.width * scaleFactor) / 2
    }

    let x = boundingBox.minX * imageSize.width * scaleFactor + offsetX
    let y = (1 - boundingBox.maxY) * imageSize.height * scaleFactor + offsetY
    let width = boundingBox.width * imageSize.width * scaleFactor
    let height = boundingBox.height * imageSize.height * scaleFactor
    return CGRect(x: x, y: y, width: width, height: height)
}
```

**å‡ºåŠ›çµæœ**

```makefile
BoundingBox: (0.5295758928571429, 0.21408638121589782, 0.0943080357142857, 0.21254415360708087)
Payload: 4710018183805
Symbology: VNBarcodeSymbologyEAN13
```

#### ä¸€éƒ¨ã®å•†å“ã«ã¯ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ãŒãªãã€ä¾‹ãˆã°ãƒãƒ©å£²ã‚Šã®æœç‰©ã«ã¯å•†å“ãƒ©ãƒ™ãƒ«ã®ã¿ãŒã‚ã‚Šã¾ã™

![](/assets/755509180ca8/1*jeZhLtg9j11kgOAvKZmevg.jpeg)

![](/assets/755509180ca8/1*YNokMMUewMA2kzjoGmMJPw.png)

ãã®ãŸã‚ã€ç§ãŸã¡ã®ã‚¹ã‚­ãƒ£ãƒŠãƒ¼ã‚‚ãƒ†ã‚­ã‚¹ãƒˆãƒ©ãƒ™ãƒ«ã®ã‚¹ã‚­ãƒ£ãƒ³ã«å¯¾å¿œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```swift
let filePath = Bundle.main.path(forResource: "apple", ofType: "jpg")! // ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆç”»åƒ
let fileURL = URL(filePath: filePath)
if #available(iOS 18.0, *) {
    // Swiftã®æ–°æ©Ÿèƒ½ã‚’ä½¿ã£ãŸæ–°ã—ã„API
    var barcodesRequest = DetectBarcodesRequest()
    barcodesRequest.symbologies = [.ean13] // EAN13ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã®ã¿ã‚¹ã‚­ãƒ£ãƒ³ã™ã‚‹å ´åˆã¯æŒ‡å®šã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Š
    var textRequest = RecognizeTextRequest()
    textRequest.recognitionLanguages = [.init(identifier: "zh-Hnat"), .init(identifier: "en-US")]
    Task {
        do {
            let handler = ImageRequestHandler(fileURL)
            // ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ‘ãƒƒã‚¯æ§‹æ–‡ã§å…¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å®Œäº†ã‚’å¾…ã¤å¿…è¦ãŒã‚ã‚‹
            // let (barcodesObservation, textObservation, ...) = try await handler.perform(barcodesRequest, textRequest, ...)
            let (barcodesObservation, textObservation) = try await handler.perform(barcodesRequest, textRequest)
            if let observation = barcodesObservation.first {
                DispatchQueue.main.async {
                    self.infoLabel.text = observation.payloadString
                    // ãƒãƒ¼ã‚¯ç”¨ã®è‰²ãƒ¬ã‚¤ãƒ¤ãƒ¼
                    let colorLayer = CALayer()
                    // iOS >=18 æ–°ã—ã„åº§æ¨™å¤‰æ›API toImageCoordinates
                    // æœªæ¤œè¨¼ã§ã€å®Ÿéš›ã«ã¯ContentMode = AspectFitã®ã‚ªãƒ•ã‚»ãƒƒãƒˆè¨ˆç®—ãŒå¿…è¦ãªå¯èƒ½æ€§ã‚ã‚Š
                    colorLayer.frame = observation.boundingBox.toImageCoordinates(self.baseImageView.frame.size, origin: .upperLeft)
                    colorLayer.backgroundColor = UIColor.red.withAlphaComponent(0.5).cgColor
                    self.baseImageView.layer.addSublayer(colorLayer)
                }
                print("BoundingBox: \(observation.boundingBox.cgRect)")
                print("Payload: \(observation.payloadString ?? "ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ãªã—")")
                print("Symbology: \(observation.symbology)")
            }
            textObservation.forEach {
                observation in
                let topCandidate = observation.topCandidates(1).first
                print(topCandidate?.string ?? "ãƒ†ã‚­ã‚¹ãƒˆèªè­˜ãªã—")
            }
        }
        catch {
            print("ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: \(error)")
        }
    }
} else {
    // ä»¥å‰ã®æ›¸ãæ–¹
    let barcodesCompletionHandler: VNRequestCompletionHandler = {
        request, error in
        guard error == nil else {
            print("ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: \(String(describing: error))")
            return
        }
        guard let observations = request.results as? [VNBarcodeObservation] else {
            return
        }
        if let observation = observations.first {
            DispatchQueue.main.async {
                self.infoLabel.text = observation.payloadStringValue
                // ãƒãƒ¼ã‚¯ç”¨ã®è‰²ãƒ¬ã‚¤ãƒ¤ãƒ¼
                let colorLayer = CALayer()
                colorLayer.frame = self.convertBoundingBox(observation.boundingBox, to: self.baseImageView)
                colorLayer.backgroundColor = UIColor.red.withAlphaComponent(0.5).cgColor
                self.baseImageView.layer.addSublayer(colorLayer)
            }
            print("BoundingBox: \(observation.boundingBox)")
            print("Payload: \(observation.payloadStringValue ?? "ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ãªã—")")
            print("Symbology: \(observation.symbology.rawValue)")
        }
    }

    let textCompletionHandler: VNRequestCompletionHandler = {
        request, error in
        guard error == nil else {
            print("ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: \(String(describing: error))")
            return
        }
        guard let observations = request.results as? [VNRecognizedTextObservation] else {
            return
        }
        observations.forEach {
            observation in
            let topCandidate = observation.topCandidates(1).first
            print(topCandidate?.string ?? "ãƒ†ã‚­ã‚¹ãƒˆèªè­˜ãªã—")
        }
    }

    let barcodesRequest = VNDetectBarcodesRequest(completionHandler: barcodesCompletionHandler)
    barcodesRequest.symbologies = [.ean13] // EAN13ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã®ã¿ã‚¹ã‚­ãƒ£ãƒ³ã™ã‚‹å ´åˆã¯æŒ‡å®šã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Š
    let textRequest = VNRecognizeTextRequest(completionHandler: textCompletionHandler)
    textRequest.recognitionLevel = .accurate
    textRequest.recognitionLanguages = ["en-US"]
    DispatchQueue.global().async {
        let handler = VNImageRequestHandler(url: fileURL, options: [:])
        do {
            try handler.perform([barcodesRequest, textRequest])
        }
        catch {
            print("ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: \(error)")
        }
    }
}
```

**å‡ºåŠ›çµæœï¼š**

```
94128s
ã‚ªãƒ¼ã‚¬ãƒ‹ãƒƒã‚¯
ãƒ”ãƒ³ã‚¯ãƒ¬ãƒ‡ã‚£Â®
UShç”£
```

**iOS â‰¥ 18 ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã®ãƒã‚¤ãƒ©ã‚¤ãƒˆï¼š**

```swift
let handler = ImageRequestHandler(fileURL)
// ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ‘ãƒƒã‚¯æ§‹æ–‡ã§ã€ã™ã¹ã¦ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒå®Œäº†ã™ã‚‹ã®ã‚’å¾…ã£ã¦ã‹ã‚‰çµæœã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
// let (barcodesObservation, textObservation, ...) = try await handler.perform(barcodesRequest, textRequest, ...)
let (barcodesObservation, textObservation) = try await handler.perform(barcodesRequest, textRequest)
```

#### iOS â‰¥ 18 [performAll( )](<https://developer.apple.com/documentation/vision/imagerequesthandler/performall(_:>)?changes=latest_minor){:target="_blank"} ãƒ¡ã‚½ãƒƒãƒ‰

![](/assets/755509180ca8/1*z0364eYD4F4On194EgQ1kQ.png)

å‰ã® `perform(barcodesRequest, textRequest)` ã¯ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã‚¹ã‚­ãƒ£ãƒ³ã¨ãƒ†ã‚­ã‚¹ãƒˆã‚¹ã‚­ãƒ£ãƒ³ã®å‡¦ç†ã§ã€ä¸¡æ–¹ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒå®Œäº†ã™ã‚‹ã¾ã§æ¬¡ã®å‡¦ç†ã«é€²ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚iOS 18ã‹ã‚‰ã¯æ–°ã—ã„ `performAll()` ãƒ¡ã‚½ãƒƒãƒ‰ãŒæä¾›ã•ã‚Œã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ–¹å¼ãŒã‚¹ãƒˆãƒªãƒ¼ãƒ ã«å¤‰ã‚ã‚Šã€ã„ãšã‚Œã‹ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆçµæœã‚’å—ã‘å–ã£ãŸã‚‰ã™ãã«å¯¾å¿œå‡¦ç†ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚

```swift
if #available(iOS 18.0, *) {
    // Swiftã®æ–°æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ãŸæ–°ã—ã„API
    var barcodesRequest = DetectBarcodesRequest()
    barcodesRequest.symbologies = [.ean13] // EAN13ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã®ã¿ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã™ã‚‹å ´åˆã¯æŒ‡å®šã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Š
    var textRequest = RecognizeTextRequest()
    textRequest.recognitionLanguages = [.init(identifier: "zh-Hnat"), .init(identifier: "en-US")]
    Task {
        let handler = ImageRequestHandler(fileURL)
        let observation = handler.performAll([barcodesRequest, textRequest] as [any VisionRequest])
        for try await result in observation {
            switch result {
                case .detectBarcodes(_, let barcodesObservation):
                if let observation = barcodesObservation.first {
                    DispatchQueue.main.async {
                        self.infoLabel.text = observation.payloadString
                        // è‰²ä»˜ããƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒãƒ¼ã‚¯
                        let colorLayer = CALayer()
                        // iOS >=18 æ–°ã—ã„åº§æ¨™å¤‰æ›API toImageCoordinates
                        // æœªæ¤œè¨¼ã€å®Ÿéš›ã«ã¯ContentMode = AspectFitã®ã‚ªãƒ•ã‚»ãƒƒãƒˆè¨ˆç®—ãŒå¿…è¦ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“:
                        colorLayer.frame = observation.boundingBox.toImageCoordinates(self.baseImageView.frame.size, origin: .upperLeft)
                        colorLayer.backgroundColor = UIColor.red.withAlphaComponent(0.5).cgColor
                        self.baseImageView.layer.addSublayer(colorLayer)
                    }
                    print("BoundingBox: \(observation.boundingBox.cgRect)")
                    print("Payload: \(observation.payloadString ?? "No payload")")
                    print("Symbology: \(observation.symbology)")
                }
                case .recognizeText(_, let textObservation):
                textObservation.forEach {
                    observation in
                    let topCandidate = observation.topCandidates(1).first
                    print(topCandidate?.string ?? "èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãªã—")
                }
                default:
                print("èªè­˜ã•ã‚Œãªã„çµæœ: \(result)")
            }
        }
    }
}
```

### Swift Concurrencyã§æœ€é©åŒ–ã™ã‚‹

![](/assets/755509180ca8/1*LgxxMOVS6is3n6EqPWqA6Q.png)

![](/assets/755509180ca8/1*80CFJpkb-gjy3bJs4jAC2A.png)

ã‚ã‚‹ç”»åƒã‚¦ã‚©ãƒ¼ãƒ«ãƒªã‚¹ãƒˆãŒã‚ã‚Šã€å„ç”»åƒã‹ã‚‰è‡ªå‹•çš„ã«å¯¾è±¡ç‰©ã‚’ãƒˆãƒªãƒŸãƒ³ã‚°ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã¨ã—ã¾ã™ã€‚ã“ã®å ´åˆã€Swift Concurrencyã‚’æ´»ç”¨ã—ã¦èª­ã¿è¾¼ã¿åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

#### **å…ƒã®æ›¸ãæ–¹**

```swift
func generateThumbnail(url: URL) async throws -> UIImage {
  let request = GenerateAttentionBasedSaliencyImageRequest()
  let saliencyObservation = try await request.perform(on: url)
  return cropImage(url, to: saliencyObservation.salientObjects)
}
    
func generateAllThumbnails() async throws {
  for image in images {
    image.thumbnail = try await generateThumbnail(url: image.url)
  }
}
```

ä¸€åº¦ã«ä¸€ã¤ã ã‘å®Ÿè¡Œã™ã‚‹ãŸã‚ã€åŠ¹ç‡ã¨æ€§èƒ½ãŒé…ã„ã€‚

#### **æœ€é©åŒ– (1) â€” TaskGroup** åŒæ™‚å®Ÿè¡Œ

```swift

func generateAllThumbnails() async throws {
  try await withThrowingDiscardingTaskGroup { taskGroup in
    for image in images {
      image.thumbnail = try await generateThumbnail(url: image.url)
     }
  }
}
```

å„ã‚¿ã‚¹ã‚¯ã‚’TaskGroupã®ä¸¦è¡Œå‡¦ç†ã«è¿½åŠ ã—ã¾ã™ã€‚

> ***å•é¡Œï¼šç”»åƒèªè­˜ã‚„ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆæ“ä½œã¯éå¸¸ã«ãƒ¡ãƒ¢ãƒªã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¶ˆè²»ã—ã¾ã™ã€‚ç„¡åˆ¶é™ã«ä¸¦è¡Œã‚¿ã‚¹ã‚¯ã‚’å¢—ã‚„ã™ã¨ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å‹•ä½œãŒé‡ããªã£ãŸã‚Šã€OOMã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã®åŸå› ã¨ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚***

#### æœ€é©åŒ– (2) â€” TaskGroup Concurrency + ä¸¦è¡Œæ•°ã®åˆ¶é™

```swift
func generateAllThumbnails() async throws {
    try await withThrowingDiscardingTaskGroup {
        taskGroup in
        // æœ€å¤§åŒæ™‚å®Ÿè¡Œæ•°ã¯5ã‚’è¶…ãˆãªã„
        let maxImageTasks = min(5, images.count)
        // ã¾ãš5ã¤ã®ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ
        for index in 0..<maxImageTasks {
            taskGroup.addTask {
                image[index].thumbnail = try await generateThumbnail(url: image[index].url)
            }
        }
        var nextIndex = maxImageTasks
        for try await _ in taskGroup {
            // taskGroupå†…ã®ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã—ãŸæ™‚...
            // ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒçµ‚ç«¯ã‹ç¢ºèª
            if nextIndex < images.count {
                let image = images[nextIndex]
                // ã‚¿ã‚¹ã‚¯ã‚’é †æ¬¡è¿½åŠ ï¼ˆæœ€å¤§5ã¤ã‚’ç¶­æŒï¼‰
                taskGroup.addTask {
                    image.thumbnail = try await generateThumbnail(url: image.url)
                }
                nextIndex += 1
            }
        }
    }
}
```

### æ—¢å­˜ã®Visionã‚¢ãƒ—ãƒªã‚’æ›´æ–°ã™ã‚‹

![](/assets/755509180ca8/1*0OhzcxQ7OpSujeyvt9918Q.png)

![](/assets/755509180ca8/1*MH4Xa0RB2DZQ1Fl9-kItSw.png)

1. Visionã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ã‚¨ãƒ³ã‚¸ãƒ³æ­è¼‰ãƒ‡ãƒã‚¤ã‚¹ã§ä¸€éƒ¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¯¾ã™ã‚‹CPUã¨GPUã®ã‚µãƒãƒ¼ãƒˆã‚’å»ƒæ­¢ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ‡ãƒã‚¤ã‚¹ã§ã¯ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ã‚¨ãƒ³ã‚¸ãƒ³ãŒæœ€ã‚‚é«˜æ€§èƒ½ãªé¸æŠè‚¢ã§ã™ã€‚  
   `supportedComputeDevices()` APIã§ç¢ºèªã§ãã¾ã™ã€‚

2. ã™ã¹ã¦ã®VNãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤  
   `VNXXRequest` , `VNXXXObservation` â†’ `Request` , `Observation`

3. async/awaitã‚’ä½¿ã£ã¦å…ƒã®VNRequestCompletionHandlerã‚’ç½®ãæ›ãˆã¾ã™ã€‚

4. ç›´æ¥`*Request.perform()`ã‚’ä½¿ç”¨ã—ã€å¾“æ¥ã®`VNImageRequestHandler.perform([VN*Request])`ã‚’ç½®ãæ›ãˆã¾ã™ã€‚

### ã¾ã¨ã‚

- Swiftè¨€èªã®ç‰¹æ€§ã«åˆã‚ã›ã¦æ–°ãŸã«è¨­è¨ˆã•ã‚ŒãŸAPI

- æ–°æ©Ÿèƒ½ã‚„ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã™ã¹ã¦Swiftå°‚ç”¨ã§ã€iOS 18ä»¥é™ã§åˆ©ç”¨å¯èƒ½ã§ã™

- æ–°ã—ã„ç”»åƒç¾å­¦è©•ä¾¡æ©Ÿèƒ½ã€èº«ä½“ï¼‹æ‰‹ã®ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼è¿½è·¡

### ã‚ã‚ŠãŒã¨ã†ï¼

![](/assets/755509180ca8/1*BK_5eH1i4-drOUOGnuQRSg.png)

### KKday å‹Ÿé›†ã®ãŠçŸ¥ã‚‰ã›

![](/assets/755509180ca8/1*kjcldhvCP1cM-QqDfRFaYg.png)

ğŸ‘‰ğŸ‘‰ğŸ‘‰ä»Šå›ã®å‹‰å¼·ä¼šã®å…±æœ‰ã¯KKdayã‚¢ãƒ—ãƒªãƒãƒ¼ãƒ ã®é€±æ¬¡æŠ€è¡“å…±æœ‰æ´»å‹•ã«ç”±æ¥ã—ã¾ã™ã€‚**ç¾åœ¨ãƒãƒ¼ãƒ ã§ã¯[Senior iOS Engineer](https://kkday.bamboohr.com/careers/25?source=aWQ9Mjk%3D){:target="_blank"}ã‚’ç©æ¥µçš„ã«å‹Ÿé›†ã—ã¦ã„ã¾ã™ã€‚èˆˆå‘³ã®ã‚ã‚‹æ–¹ã¯ãœã²ã”å¿œå‹Ÿãã ã•ã„ã€‚**ğŸ‘ˆğŸ‘ˆğŸ‘ˆ

#### å‚è€ƒè³‡æ–™

#### [Visionãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®Swiftå¼·åŒ–ã‚’ç™ºè¦‹ã™ã‚‹](https://developer.apple.com/videos/play/wwdc2024/10163/){:target="_blank"}

Vision Frameworkã®APIã¯ã€ä¸¦è¡Œå‡¦ç†ãªã©ã®æœ€æ–°ã®Swiftæ©Ÿèƒ½ã‚’æ´»ç”¨ã™ã‚‹ã‚ˆã†ã«å†è¨­è¨ˆã•ã‚Œã¦ãŠã‚Šã€ã•ã¾ã–ã¾ãªVisionã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ã‚¢ãƒ—ãƒªã«ã‚ˆã‚Šç°¡å˜ã‹ã¤é«˜é€Ÿã«çµ±åˆã§ãã¾ã™ã€‚æ›´æ–°ã•ã‚ŒãŸAPIã‚’ç´¹ä»‹ã—ã€ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚„ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’å…±æœ‰ã—ã¦ã€ã‚ˆã‚Šå°‘ãªã„ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®åˆ©ç‚¹ã‚’æ´»ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚ã¾ãŸã€æ–°æ©Ÿèƒ½ã®ç”»åƒç¾å­¦è©•ä¾¡ã¨å…¨èº«å§¿å‹¢æ¤œå‡ºã«ã¤ã„ã¦ã‚‚å®Ÿæ¼”ã—ã¾ã™ã€‚

### ç« ç¯€

- 0:00 â€” [ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³](https://developer.apple.com/videos/play/wwdc2024/10163/?time=0){:target="_blank"}

- 1:07 â€” [æ–°ã—ã„Vision API](https://developer.apple.com/videos/play/wwdc2024/10163/?time=67){:target="_blank"}

- 1:47 â€” [Visionã®ä½¿ã„æ–¹ã‚’å§‹ã‚ã‚‹](https://developer.apple.com/videos/play/wwdc2024/10163/?time=107){:target="_blank"}

- 8:59 â€” [Swift Concurrencyã§æœ€é©åŒ–](https://developer.apple.com/videos/play/wwdc2024/10163/?time=539){:target="_blank"}

- 11:05 â€” [æ—¢å­˜ã®Visionã‚¢ãƒ—ãƒªã‚’æ›´æ–°ã™ã‚‹](https://developer.apple.com/videos/play/wwdc2024/10163/?time=665){:target="_blank"}

- 13:46 â€” [Visionã®æ–°æ©Ÿèƒ½](https://developer.apple.com/videos/play/wwdc2024/10163/?time=826){:target="_blank"}

#### [Vision framework Apple Developer Documentation](https://developer.apple.com/documentation/vision/){:target="_blank"}

-

ã”è³ªå•ã‚„ã”æ„è¦‹ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã€[ã“ã¡ã‚‰ã‹ã‚‰ã”é€£çµ¡ãã ã•ã„](https://www.zhgchg.li/contact){:target="_blank"} ã€‚

*[Post](https://medium.com/kkdaytech/ios-vision-framework-x-wwdc-24-discover-swift-enhancements-in-the-vision-framework-session-755509180ca8){:target="_blank"} ã¯ [ZMediumToMarkdown](https://github.com/ZhgChgLi/ZMediumToMarkdown){:target="_blank"} ã«ã‚ˆã£ã¦ Medium ã‹ã‚‰å¤‰æ›ã•ã‚Œã¾ã—ãŸã€‚*