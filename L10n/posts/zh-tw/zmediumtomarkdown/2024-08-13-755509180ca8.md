---
author: ZhgChgLi
categories:
- KKday Tech Blog
date: 2024-08-13T08:10:37.015+0000
description: Vision framework åŠŸèƒ½å›é¡§ & iOS 18 æ–° Swift API è©¦ç©
image:
  path: /assets/755509180ca8/1*NqN-_MAE4tt11n6MnUQWxQ.jpeg
last_modified_at: 2024-08-14T12:07:49.774+0000
render_with_liquid: false
tags:
- ios-app-development
- vision-framework
- apple-intelligence
- ai
- machine-learning
title: iOS Vision framework x WWDC 24 Discover Swift enhancements in the Vision framework
  Session
---

### iOS Vision framework x WWDC 24 Discover Swift enhancements in the Vision framework Session

Vision framework åŠŸèƒ½å›é¡§ & iOS 18 æ–° Swift API è©¦ç©


![Photo by [BoliviaInteligente](https://unsplash.com/@boliviainteligente?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash){:target="_blank"}](/assets/755509180ca8/1*NqN-_MAE4tt11n6MnUQWxQ.jpeg)

Photo by [BoliviaInteligente](https://unsplash.com/@boliviainteligente?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash){:target="_blank"}
#### ä¸»é¡Œ


![è·Ÿ Vision Pro çš„é—œä¿‚å°±è·Ÿç†±ç‹—è·Ÿç‹—çš„é—œä¿‚ä¸€æ¨£ï¼Œæ¯«ç„¡é—œä¿‚ã€‚](/assets/755509180ca8/1*ebqm2jzCK1GSrDDY0XtrUA.png)

è·Ÿ Vision Pro çš„é—œä¿‚å°±è·Ÿç†±ç‹—è·Ÿç‹—çš„é—œä¿‚ä¸€æ¨£ï¼Œæ¯«ç„¡é—œä¿‚ã€‚
### Vision framework

Vision framework æ˜¯ Apple æ•´åˆæ©Ÿå™¨å­¸ç¿’çš„åœ–åƒè¾¨è­˜æ¡†æ¶ï¼Œè®“é–‹ç™¼è€…å¯ä»¥ç°¡å–®å¿«é€Ÿåœ°å¯¦ç¾å¸¸è¦‹çš„åœ–åƒè¾¨è­˜åŠŸèƒ½ï¼›Vision framework æ—©åœ¨ iOS 11\.0\+ \(2017/ iPhone 8\) å°±å·²æ¨å‡ºï¼ŒæœŸé–“ä¸æ–·åœ°è¿­ä»£å„ªåŒ–ï¼Œä¸¦å®Œå–„èˆ‡ Swift Concurrency çš„ç‰¹æ€§æ•´åˆæå‡åŸ·è¡Œæ•ˆèƒ½ï¼Œä¸¦ä¸”å¾ iOS 18\.0 æä¾›å…¨æ–°çš„ Swift Vision framework API ç™¼æ® Swift Concurrency æœ€å¤§æ•ˆæœã€‚

**Vision framework ç‰¹è‰²**
- å…§å»ºçœ¾å¤šåœ–ç‰‡è¾¨è­˜ã€å‹•æ…‹è¿½è¹¤æ–¹æ³• \(iOS 18 ç‚ºæ­¢ä¸€å…± 31 ç¨®\)
- On\-Device å–®ç´”ä½¿ç”¨æ‰‹æ©Ÿæ™¶ç‰‡é‹ç®—ï¼Œè¾¨è­˜éç¨‹ä¸ä¾è³´é›²ç«¯æœå‹™ï¼Œå¿«é€Ÿåˆå®‰å…¨
- API ç°¡å–®å¥½æ“ä½œ
- Apple å…¨å¹³å°å‡æ”¯æ´ iOS 11\.0\+, iPadOS 11\.0\+, Mac Catalyst 13\.0\+, macOS 10\.13\+, tvOS 11\.0\+, visionOS 1\.0\+
- å·²ç™¼å¸ƒå¤šå¹´ \(2017~ä»Š\) ä¸”ä¸æ–·æ›´æ–°
- æ•´åˆ Swift èªè¨€ç‰¹æ€§æå‡é‹ç®—æ•ˆèƒ½



> **_6 å¹´å‰æ›¾ç¶“å°ç©éï¼š [Vision åˆæ¢ â€” APP é ­åƒä¸Šå‚³ è‡ªå‹•è­˜åˆ¥äººè‡‰è£åœ– \(Swift\)](../9a9aa892f9a9/)_** 





> _é€™æ¬¡æ­é… [WWDC 24 Discover Swift enhancements in the Vision framework Session](https://developer.apple.com/videos/play/wwdc2024/10163/){:target="_blank"} é‡æ–°å›é¡§ä¸¦çµåˆæ–°çš„ Swfit ç‰¹æ€§å†ç©ä¸€æ¬¡ã€‚_ 




#### CoreML

Apple é‚„æœ‰å¦å¤–ä¸€å€‹ Framework å« [CoreML](https://developer.apple.com/documentation/coreml){:target="_blank"} ï¼Œä¹Ÿæ˜¯åŸºæ–¼ On\-Device æ™¶ç‰‡çš„æ©Ÿå™¨å­¸ç¿’æ¡†æ¶ï¼›ä½†ä»–å¯ä»¥è®“ä½ è‡ªå·±è¨“ç·´æƒ³è¾¨è­˜çš„ç‰©ä»¶ã€æ–‡ä»¶æ¨¡å‹ï¼Œä¸¦å°‡æ¨¡å‹æ”¾åˆ° App ä¸­ç›´æ¥ä½¿ç”¨ï¼Œæœ‰èˆˆè¶£çš„æœ‹å‹ä¹Ÿå¯ä»¥ç©çœ‹çœ‹ã€‚\(e\.g\. [å³æ™‚æ–‡ç« åˆ†é¡](../793bf2cdda0f/) ã€å³æ™‚ [åƒåœ¾è¨Šæ¯æª¢æ¸¬](https://apps.apple.com/tw/app/%E7%86%8A%E7%8C%AB%E5%90%83%E7%9F%AD%E4%BF%A1-%E5%9E%83%E5%9C%BE%E7%9F%AD%E4%BF%A1%E8%BF%87%E6%BB%A4/id1319191852){:target="_blank"} â€¦\)
#### p\.s\.

[**Vision**](https://developer.apple.com/documentation/vision/){:target="_blank"} **v\.s\. [VisionKit](https://developer.apple.com/documentation/visionkit){:target="_blank"} ï¼š**


> [**_Vision_**](https://developer.apple.com/documentation/vision/){:target="_blank"} _ï¼šä¸»è¦ç”¨æ–¼åœ–åƒåˆ†æä»»å‹™ï¼Œå¦‚è‡‰éƒ¨è­˜åˆ¥ã€æ¢ç¢¼æª¢æ¸¬ã€æ–‡æœ¬è­˜åˆ¥ç­‰ã€‚å®ƒæä¾›äº†å¼·å¤§çš„ API ä¾†è™•ç†å’Œåˆ†æéœæ…‹åœ–åƒæˆ–è¦–é »ä¸­çš„è¦–è¦ºå…§å®¹ã€‚_ 





> [**_VisionKit_**](https://developer.apple.com/documentation/visionkit){:target="_blank"} _ï¼šå°ˆé–€ç”¨æ–¼è™•ç†èˆ‡æ–‡ä»¶æƒæç›¸é—œçš„ä»»å‹™ã€‚å®ƒæä¾›äº†ä¸€å€‹æƒæå„€è¦–åœ–æ§åˆ¶å™¨ï¼Œå¯ä»¥ç”¨ä¾†æƒææ–‡æª”ï¼Œä¸¦ç”Ÿæˆé«˜è³ªé‡çš„ PDF æˆ–åœ–åƒã€‚_ 





Vision framework åœ¨ M1 æ©Ÿå‹ä¸Šç„¡æ³•è·‘åœ¨æ¨¡æ“¬å™¨ï¼Œåªèƒ½æ¥å¯¦é«”æ‰‹æ©Ÿæ¸¬è©¦ï¼›åœ¨æ¨¡æ“¬å™¨ç’°å¢ƒåŸ·è¡Œæœƒæ‹‹å‡º `Could not create Espresso context` Errorï¼ŒæŸ¥ [å®˜æ–¹è«–å£‡è¨è«–ï¼Œæ²’æ‰¾åˆ°è§£ç­”](https://forums.developer.apple.com/forums/thread/675806){:target="_blank"} ã€‚


> _å› æ‰‹é‚Šæ²’æœ‰å¯¦é«” iOS 18 è£ç½®é€²è¡Œæ¸¬è©¦ï¼Œæ‰€ä»¥æœ¬æ–‡ä¸­çš„æ‰€æœ‰åŸ·è¡Œçµæœéƒ½æ˜¯ä½¿ç”¨èˆŠçš„ \(iOS 18 ä»¥å‰\) çš„å¯«æ³•çµæœï¼› **å¦‚æ–°å¯«æ³•æœ‰å‡ºç¾éŒ¯èª¤å†éº»ç…©ç•™è¨€æŒ‡æ•™** ã€‚_ 




### WWDC 2024 â€” Discover Swift enhancements in the Vision framework


![[Discover Swift enhancements in the Vision framework](https://developer.apple.com/videos/play/wwdc2024/10163/?time=45){:target="_blank"}](/assets/755509180ca8/1*8N5GtY1uqxP-4iAAAticOA.png)

[Discover Swift enhancements in the Vision framework](https://developer.apple.com/videos/play/wwdc2024/10163/?time=45){:target="_blank"}


> _æœ¬æ–‡æ˜¯é‡å° WWDC 24 â€” [Discover Swift enhancements in the Vision framework](https://developer.apple.com/videos/play/wwdc2024/10163/?time=45){:target="_blank"} Session çš„åˆ†äº«ç­†è¨˜ï¼Œè·Ÿä¸€äº›è‡ªå·±å¯¦é©—çš„å¿ƒå¾—ã€‚_ 




### Introduction â€” Vision framework Features
#### äººè‡‰è¾¨è­˜ã€è¼ªå»“è­˜åˆ¥


![](/assets/755509180ca8/1*RNGfE_EeaQhiKAPdJeFYQw.png)



![](/assets/755509180ca8/1*iMdzeLm2aWjATVV6_Kvrjg.png)

#### åœ–åƒå…§å®¹æ–‡å­—è¾¨è­˜

æˆªè‡³ iOS 18 ç‚ºæ­¢ï¼Œæ”¯æ´ 18 ç¨®èªè¨€ã€‚


![](/assets/755509180ca8/1*kU_OYn5w368h-ahDYU4lDw.png)

```swift
// æ”¯æ´çš„èªç³»åˆ—è¡¨
if #available(iOS 18.0, *) {
  print(RecognizeTextRequest().supportedRecognitionLanguages.map { "\($0.languageCode!)-\(($0.region?.identifier ?? $0.script?.identifier)!)" })
} else {
  print(try! VNRecognizeTextRequest().supportedRecognitionLanguages())
}

// å¯¦éš›å¯ç”¨è¾¨è­˜èªè¨€ä»¥é€™ç‚ºä¸»ã€‚
// å¯¦æ¸¬ iOS 18 è¼¸å‡ºä»¥ä¸‹çµæœï¼š
// ["en-US", "fr-FR", "it-IT", "de-DE", "es-ES", "pt-BR", "zh-Hans", "zh-Hant", "yue-Hans", "yue-Hant", "ko-KR", "ja-JP", "ru-RU", "uk-UA", "th-TH", "vi-VT", "ar-SA", "ars-SA"]
// æœªçœ‹åˆ° WWDC æåˆ°çš„ Swedish èªè¨€ï¼Œä¸ç¢ºå®šæ˜¯é‚„æ²’æ¨å‡ºé‚„æ˜¯è·Ÿè£ç½®åœ°å€ã€èªç³»æœ‰é—œè¯
```
#### å‹•æ…‹å‹•ä½œæ•æ‰


![](/assets/755509180ca8/1*6TfyCcszdD1NdId0bdM16Q.gif)



![](/assets/755509180ca8/1*8y_XXdH36uKpfP0p6BCJQA.gif)

- å¯ä»¥å¯¦ç¾äººã€ç‰©ä»¶å‹•æ…‹æ•æ‰
- æ‰‹å‹¢è£œæ‰å¯¦ç¾éš”ç©ºç°½ååŠŸèƒ½

#### Whatâ€™s new in Vision? \(iOS 18\)â€” åœ–ç‰‡è©•åˆ†åŠŸèƒ½ \(å“è³ªã€è¨˜æ†¶é»\)
- å¯å°è¼¸å…¥åœ–ç‰‡å¾—è¨ˆç®—å‡ºåˆ†æ•¸ï¼Œæ–¹ä¾¿ç¯©é¸å‡ºå„ªè³ªç…§ç‰‡
- åˆ†æ•¸è¨ˆç®—æ–¹å¼åŒ…å«å¤šå€‹ç¶­åº¦ï¼Œä¸åªæ˜¯ç•«è³ªï¼Œé‚„æœ‰å…‰ç·šã€è§’åº¦ã€æ‹æ”ä¸»é«”ã€ **æ˜¯å¦æœ‰è®“äººæ„Ÿåˆ°çš„è¨˜æ†¶é»** â€¦ç­‰ç­‰



![](/assets/755509180ca8/1*XwjeaHcB6arxJhIR7cFsWg.png)



![](/assets/755509180ca8/1*YdhZlZBlTaIZd4nLxhBtaQ.png)



![](/assets/755509180ca8/1*IhMDFdk6DWwTv1qIG0Gi0Q.png)


WWDC ä¸­çµ¦äº†ä»¥ä¸Šä¸‰å¼µåœ–ç‰‡åšèªªæ˜\(ç›¸åŒç•«è³ªä¹‹ä¸‹\)ï¼Œåˆ†åˆ¥æ˜¯ï¼š
- é«˜åˆ†çš„åœ–ç‰‡ï¼šå–æ™¯ã€å…‰ç·šã€æœ‰è¨˜æ†¶é»
- ä½åˆ†çš„åœ–ç‰‡ï¼šæ²’æœ‰ä¸»é«”ã€åƒæ˜¯éš¨æ‰‹æˆ–ä¸å°å¿ƒæ‹çš„
- ç´ æçš„åœ–ç‰‡ï¼šæŠ€è¡“ä¸Šæ‹çš„å¾ˆå¥½ä½†æ˜¯æ²’æœ‰è¨˜æ†¶é»ï¼Œåƒæ˜¯ä½œç‚ºç´ æåœ–åº«ç”¨çš„åœ–ç‰‡


**iOS â‰¥ 18 New API: [CalculateImageAestheticsScoresRequest](https://developer.apple.com/documentation/vision/calculateimageaestheticsscoresrequest){:target="_blank"}**
```swift
let request = CalculateImageAestheticsScoresRequest()
let result = try await request.perform(on: URL(string: "https://zhgchg.li/assets/cb65fd5ab770/1*yL3vI1ADzwlovctW5WQgJw.jpeg")!)

// ç…§ç‰‡åˆ†æ•¸
print(result.overallScore)

// æ˜¯å¦è¢«åˆ¤å®šç‚ºç´ æåœ–ç‰‡
print(result.isUtility)
```
#### Whatâ€™s new in Vision? \(iOS 18\) â€” èº«é«”ï¼‹æ‰‹å‹¢å§¿å‹¢åŒæ™‚åµæ¸¬


![](/assets/755509180ca8/1*A9320aRV-jdccgiXrmSrJw.png)


ä»¥å¾€åªèƒ½å€‹åˆ¥åµæ¸¬äººé«” Pose å’Œ æ‰‹éƒ¨ Poseï¼Œé€™æ¬¡æ›´æ–°å¯ä»¥è®“é–‹ç™¼è€…åŒæ™‚åµæ¸¬èº«é«” Pose \+ æ‰‹éƒ¨ Poseï¼ŒåˆæˆåŒä¸€å€‹è«‹æ±‚è·Ÿçµæœï¼Œæ–¹ä¾¿æˆ‘å€‘åšæ›´å¤šæ‡‰ç”¨åŠŸèƒ½é–‹ç™¼ã€‚

**iOS â‰¥ 18 New API: [DetectHumanBodyPoseRequest](https://developer.apple.com/documentation/vision/detecthumanbodyposerequest){:target="_blank"}**
```swift
var request = DetectHumanBodyPoseRequest()
// ä¸€ä½µåµæ¸¬æ‰‹éƒ¨ Pose
request.detectsHands = true

guard let bodyPose = try await request.perform(on: image). first else { return }

// èº«é«” Pose Joints
let bodyJoints = bodyPose.allJoints()
// å·¦æ‰‹ Pose Joints
let leftHandJoints = bodyPose.leftHand.allJoints()
// å³æ‰‹ Pose Joints
let rightHandJoints = bodyPose.rightHand.allJoints()
```
### New Vision API

Apple åœ¨é€™æ¬¡çš„æ›´æ–°ç•¶ä¸­æä¾›äº†æ–°çš„ Swift Vision API å°è£çµ¦é–‹ç™¼è€…ä½¿ç”¨ï¼Œé™¤äº†åŸºæœ¬çš„åŒ…å«åŸæœ¬çš„åŠŸèƒ½æ”¯æ´ä¹‹å¤–ï¼Œä¸»è¦é‡å°åŠ å¼· Swift 6 / Swift Concurrency çš„ç‰¹æ€§ï¼Œæä¾›æ•ˆèƒ½æ›´å„ªã€å¯«èµ·ä¾†æ›´ Swift çš„ API æ“ä½œæ–¹å¼ã€‚
### Get started with Vision


![](/assets/755509180ca8/1*mv9g5jmqrS6YScxoGYJemQ.png)



![](/assets/755509180ca8/1*iidNN7nKHoskh_tcjfuHKQ.png)


é€™é‚Šè¬›è€…åˆé‡æ–°ä»‹ç´¹äº†ä¸€æ¬¡ Vision framework çš„åŸºç¤ä½¿ç”¨æ–¹å¼ï¼ŒApple å·²ç¶“å°è£å¥½äº† [31 ç¨®](https://developer.apple.com/documentation/vision/visionrequest){:target="_blank"} \(æˆªè‡³ iOS 18\)å¸¸è¦‹çš„åœ–åƒè¾¨è­˜è«‹æ±‚ã€ŒRequestã€èˆ‡å°æ‡‰å›å‚³çš„ã€ŒObservationã€ç‰©ä»¶ã€‚
1. **Request:** DetectFaceRectanglesRequest äººè‡‰å€åŸŸè­˜åˆ¥è«‹æ±‚
**Result:** FaceObservation
ä¹‹å‰çš„æ–‡ç« ã€Œ [Vision åˆæ¢ â€” APP é ­åƒä¸Šå‚³ è‡ªå‹•è­˜åˆ¥äººè‡‰è£åœ– \(Swift\)](../9a9aa892f9a9/) ã€å°±æ˜¯ç”¨é€™å°è«‹æ±‚ã€‚
2. **Request:** RecognizeTextRequest æ–‡å­—è¾¨è­˜è«‹æ±‚
**Result:** RecognizedTextObservation
3. **Request:** GenerateObjectnessBasedSaliencyImageRequest ä¸»é«”ç‰©ä»¶è¾¨è­˜è«‹æ±‚
**Result:** SaliencyImageObservation

### å…¨éƒ¨ 31 ç¨®è«‹æ±‚ Requestï¼š

[VisionRequest](https://developer.apple.com/documentation/vision/visionrequest){:target="_blank"} ã€‚

| Request ç”¨é€”                                 | Observation èªªæ˜                                                  |
|-----------------------------------------------|------------------------------------------------------------------|
| CalculateImageAestheticsScoresRequest<br/>è¨ˆç®—åœ–åƒçš„ç¾å­¸åˆ†æ•¸ã€‚                                 | AestheticsObservation<br/>è¿”å›åœ–åƒçš„ç¾å­¸è©•åˆ†ï¼Œå¦‚æ§‹åœ–ã€è‰²å½©ç­‰å› ç´ ã€‚                           |
| ClassifyImageRequest<br/>åˆ†é¡åœ–åƒå…§å®¹ã€‚                                      | ClassificationObservation<br/>è¿”å›åœ–åƒä¸­ç‰©é«”æˆ–å ´æ™¯çš„åˆ†é¡æ¨™ç±¤åŠç½®ä¿¡åº¦ã€‚                           |
| CoreMLRequest<br/>ä½¿ç”¨ Core ML æ¨¡å‹åˆ†æåœ–åƒã€‚                          | CoreMLFeatureValueObservation<br/>æ ¹æ“š Core ML æ¨¡å‹çš„è¼¸å‡ºçµæœç”Ÿæˆè§€å¯Ÿå€¼ã€‚                            |
| DetectAnimalBodyPoseRequest<br/>æª¢æ¸¬åœ–åƒä¸­çš„å‹•ç‰©å§¿å‹¢ã€‚                               | RecognizedPointsObservation<br/>è¿”å›å‹•ç‰©çš„éª¨æ¶é»åŠå…¶ä½ç½®ã€‚                                         |
| DetectBarcodesRequest<br/>æª¢æ¸¬åœ–åƒä¸­çš„æ¢ç¢¼ã€‚                                   | BarcodeObservation<br/>è¿”å›æ¢ç¢¼æ•¸æ“šåŠé¡å‹ï¼ˆå¦‚ QR codeï¼‰ã€‚                                 |
| DetectContoursRequest<br/>æª¢æ¸¬åœ–åƒä¸­çš„è¼ªå»“ã€‚                                   | ContoursObservation<br/>è¿”å›åœ–åƒä¸­æª¢æ¸¬åˆ°çš„è¼ªå»“ç·šã€‚                                         |
| DetectDocumentSegmentationRequest<br/>æª¢æ¸¬ä¸¦åˆ†å‰²åœ–åƒä¸­çš„æ–‡ä»¶ã€‚                             | RectangleObservation<br/>è¿”å›æ–‡ä»¶é‚Šç•Œçš„çŸ©å½¢æ¡†ä½ç½®ã€‚                                         |
| DetectFaceCaptureQualityRequest<br/>è©•ä¼°é¢éƒ¨æ•æ‰è³ªé‡ã€‚                                   | FaceObservation<br/>è¿”å›é¢éƒ¨åœ–åƒçš„è³ªé‡è©•ä¼°åˆ†æ•¸ã€‚                                       |
| DetectFaceLandmarksRequest<br/>æª¢æ¸¬é¢éƒ¨ç‰¹å¾µé»ã€‚                                     | FaceObservation<br/>è¿”å›é¢éƒ¨ç‰¹å¾µé»ï¼ˆå¦‚çœ¼ç›ã€é¼»å­ç­‰ï¼‰çš„è©³ç´°ä½ç½®ã€‚                       |
| DetectFaceRectanglesRequest<br/>æª¢æ¸¬åœ–åƒä¸­çš„é¢éƒ¨ã€‚                                   | FaceObservation<br/>è¿”å›äººè‡‰çš„é‚Šç•Œæ¡†ä½ç½®ã€‚                                             |
| DetectHorizonRequest<br/>æª¢æ¸¬åœ–åƒä¸­çš„åœ°å¹³ç·šã€‚                                 | HorizonObservation<br/>è¿”å›åœ°å¹³ç·šçš„è§’åº¦å’Œä½ç½®ã€‚                                           |
| DetectHumanBodyPose3DRequest<br/>æª¢æ¸¬åœ–åƒä¸­çš„ 3D äººé«”å§¿å‹¢ã€‚                           | RecognizedPointsObservation<br/>è¿”å› 3D äººé«”éª¨æ¶é»åŠå…¶ç©ºé–“åæ¨™ã€‚                                    |
| DetectHumanBodyPoseRequest<br/>æª¢æ¸¬åœ–åƒä¸­çš„äººé«”å§¿å‹¢ã€‚                               | RecognizedPointsObservation<br/>è¿”å›äººé«”éª¨æ¶é»åŠå…¶åæ¨™ã€‚                                           |
| DetectHumanHandPoseRequest<br/>æª¢æ¸¬åœ–åƒä¸­çš„æ‰‹éƒ¨å§¿å‹¢ã€‚                               | RecognizedPointsObservation<br/>è¿”å›æ‰‹éƒ¨éª¨æ¶é»åŠå…¶ä½ç½®ã€‚                                           |
| DetectHumanRectanglesRequest<br/>æª¢æ¸¬åœ–åƒä¸­çš„äººé«”ã€‚                                   | HumanObservation<br/>è¿”å›äººé«”çš„é‚Šç•Œæ¡†ä½ç½®ã€‚                                             |
| DetectRectanglesRequest<br/>æª¢æ¸¬åœ–åƒä¸­çš„çŸ©å½¢ã€‚                                   | RectangleObservation<br/>è¿”å›çŸ©å½¢çš„å››å€‹é ‚é»åæ¨™ã€‚                                           |
| DetectTextRectanglesRequest<br/>æª¢æ¸¬åœ–åƒä¸­çš„æ–‡æœ¬å€åŸŸã€‚                               | TextObservation<br/>è¿”å›æ–‡æœ¬å€åŸŸçš„ä½ç½®å’Œé‚Šç•Œæ¡†ã€‚                                       |
| DetectTrajectoriesRequest<br/>æª¢æ¸¬ä¸¦åˆ†æç‰©é«”é‹å‹•è»Œè·¡ã€‚                             | TrajectoryObservation<br/>è¿”å›é‹å‹•è»Œè·¡é»åŠå…¶æ™‚é–“åºåˆ—ã€‚                                       |
| GenerateAttentionBasedSaliencyImageRequest<br/>ç”ŸæˆåŸºæ–¼æ³¨æ„åŠ›çš„é¡¯è‘—æ€§åœ–åƒã€‚                         | SaliencyImageObservation<br/>è¿”å›åœ–åƒä¸­æœ€å…·å¸å¼•åŠ›å€åŸŸçš„é¡¯è‘—æ€§åœ°åœ–ã€‚                             |
| GenerateForegroundInstanceMaskRequest<br/>ç”Ÿæˆå‰æ™¯å¯¦ä¾‹æ©è†œåœ–åƒã€‚                               | InstanceMaskObservation<br/>è¿”å›å‰æ™¯ç‰©é«”çš„æ©è†œã€‚                                               |
| GenerateImageFeaturePrintRequest<br/>ç”Ÿæˆåœ–åƒç‰¹å¾µæŒ‡ç´‹ä»¥é€²è¡Œæ¯”è¼ƒã€‚                         | FeaturePrintObservation<br/>è¿”å›åœ–åƒçš„ç‰¹å¾µæŒ‡ç´‹æ•¸æ“šï¼Œç”¨æ–¼ç›¸ä¼¼åº¦æ¯”è¼ƒã€‚                           |
| GenerateObjectnessBasedSaliencyImageRequest<br/>ç”ŸæˆåŸºæ–¼ç‰©é«”é¡¯è‘—æ€§çš„åœ–åƒã€‚                           | SaliencyImageObservation<br/>è¿”å›ç‰©é«”é¡¯è‘—æ€§å€åŸŸçš„é¡¯è‘—æ€§åœ°åœ–ã€‚                                   |
| GeneratePersonInstanceMaskRequest<br/>ç”Ÿæˆäººç‰©å¯¦ä¾‹æ©è†œåœ–åƒã€‚                               | InstanceMaskObservation<br/>è¿”å›äººç‰©å¯¦ä¾‹çš„æ©è†œã€‚                                               |
| GeneratePersonSegmentationRequest<br/>ç”Ÿæˆäººç‰©åˆ†å‰²åœ–åƒã€‚                                   | SegmentationObservation<br/>è¿”å›äººç‰©åˆ†å‰²çš„äºŒå€¼åœ–ã€‚                                             |
| RecognizeAnimalsRequest<br/>æª¢æ¸¬ä¸¦è­˜åˆ¥åœ–åƒä¸­çš„å‹•ç‰©ã€‚                             | RecognizedObjectObservation<br/>è¿”å›å‹•ç‰©é¡å‹åŠå…¶ç½®ä¿¡åº¦ã€‚                                           |
| RecognizeTextRequest<br/>æª¢æ¸¬ä¸¦è­˜åˆ¥åœ–åƒä¸­çš„æ–‡æœ¬ã€‚                             | RecognizedTextObservation<br/>è¿”å›æª¢æ¸¬åˆ°çš„æ–‡æœ¬å…§å®¹åŠå…¶å€åŸŸä½ç½®ã€‚                                 |
| TrackHomographicImageRegistrationRequest<br/>è·Ÿè¸ªåœ–åƒçš„åŒä½å½±åƒé…æº–ã€‚                             | ImageAlignmentObservation<br/>è¿”å›åœ–åƒé–“çš„åŒä½è®Šæ›çŸ©é™£ï¼Œç”¨æ–¼å½±åƒé…æº–ã€‚                           |
| TrackObjectRequest<br/>è·Ÿè¸ªåœ–åƒä¸­çš„ç‰©é«”ã€‚                                   | DetectedObjectObservation<br/>è¿”å›ç‰©é«”åœ¨å½±åƒä¸­çš„ä½ç½®å’Œé€Ÿåº¦ä¿¡æ¯ã€‚                                 |
| TrackOpticalFlowRequest<br/>è·Ÿè¸ªåœ–åƒä¸­çš„å…‰æµã€‚                                   | OpticalFlowObservation<br/>è¿”å›å…‰æµçŸ¢é‡å ´ï¼Œç”¨æ–¼æè¿°åƒç´ ç§»å‹•æƒ…æ³ã€‚                             |
| TrackRectangleRequest<br/>è·Ÿè¸ªåœ–åƒä¸­çš„çŸ©å½¢ã€‚                                   | RectangleObservation<br/>è¿”å›çŸ©å½¢åœ¨å½±åƒä¸­çš„ä½ç½®ã€å¤§å°å’Œæ—‹è½‰è§’åº¦ã€‚                           |
| TrackTranslationalImageRegistrationRequest<br/>è·Ÿè¸ªåœ–åƒçš„å¹³ç§»å½±åƒé…æº–ã€‚                             | ImageAlignmentObservation<br/>è¿”å›åœ–åƒé–“çš„å¹³ç§»è®Šæ›çŸ©é™£ï¼Œç”¨æ–¼å½±åƒé…æº–ã€‚                           |

- å‰é¢è£œä¸Š VN å°±æ˜¯èˆŠçš„ API å¯«æ³• \(iOS 18 ä»¥å‰çš„ç‰ˆæœ¬\)


è¬›è€…æåˆ°äº†å¹¾å€‹å¸¸ç”¨çš„ Requestï¼Œå¦‚ä¸‹ã€‚
#### ClassifyImageRequest

è¾¨è­˜è¼¸å…¥çš„åœ–ç‰‡ï¼Œå¾—åˆ°æ¨™ç±¤åˆ†é¡èˆ‡ç½®ä¿¡åº¦ã€‚


![](/assets/755509180ca8/1*8NSQEjxGejujKLbXcILmxQ.jpeg)



![\[éŠè¨˜\] 2024 äºŒè¨ªä¹å· 9 æ—¥è‡ªç”±è¡Œï¼Œç¶“é‡œå±±â†’åšå¤šéƒµè¼ªå…¥å¢ƒ](/assets/755509180ca8/1*f1rNoOIQbE33M9F9NmoTXg.png)

\[éŠè¨˜\] 2024 äºŒè¨ªä¹å· 9 æ—¥è‡ªç”±è¡Œï¼Œç¶“é‡œå±±â†’åšå¤šéƒµè¼ªå…¥å¢ƒ
```swift
if #available(iOS 18.0, *) {
    // æ–°çš„ä½¿ç”¨ Swift ç‰¹æ€§çš„ API
    let request = ClassifyImageRequest()
    Task {
        do {
            let observations = try await request.perform(on: URL(string: "https://zhgchg.li/assets/cb65fd5ab770/1*yL3vI1ADzwlovctW5WQgJw.jpeg")!)
            observations.forEach {
                observation in
                print("\(observation.identifier): \(observation.confidence)")
            }
        }
        catch {
            print("Request failed: \(error)")
        }
    }
} else {
    // èˆŠçš„å¯«æ³•
    let completionHandler: VNRequestCompletionHandler = {
        request, error in
        guard error == nil else {
            print("Request failed: \(String(describing: error))")
            return
        }
        guard let observations = request.results as? [VNClassificationObservation] else {
            return
        }
        observations.forEach {
            observation in
            print("\(observation.identifier): \(observation.confidence)")
        }
    }

    let request = VNClassifyImageRequest(completionHandler: completionHandler)
    DispatchQueue.global().async {
        let handler = VNImageRequestHandler(url: URL(string: "https://zhgchg.li/assets/cb65fd5ab770/1*3_jdrLurFuUfNdW4BJaRww.jpeg")!, options: [:])
        do {
            try handler.perform([request])
        }
        catch {
            print("Request failed: \(error)")
        }
    }
}
```

**åˆ†æçµæœï¼š**
```r
 â€¢ outdoorï¼ˆæˆ¶å¤–ï¼‰: 0.75392926
 â€¢ skyï¼ˆå¤©ç©ºï¼‰: 0.75392926
 â€¢ blue_skyï¼ˆè—å¤©ï¼‰: 0.7519531
 â€¢ machineï¼ˆæ©Ÿå™¨ï¼‰: 0.6958008
 â€¢ cloudyï¼ˆå¤šé›²ï¼‰: 0.26538086
 â€¢ structureï¼ˆçµæ§‹ï¼‰: 0.15728651
 â€¢ signï¼ˆæ¨™èªŒï¼‰: 0.14224191
 â€¢ fenceï¼ˆæŸµæ¬„ï¼‰: 0.118652344
 â€¢ bannerï¼ˆæ©«å¹…ï¼‰: 0.0793457
 â€¢ materialï¼ˆææ–™ï¼‰: 0.075975396
 â€¢ plantï¼ˆæ¤ç‰©ï¼‰: 0.054406323
 â€¢ foliageï¼ˆæ¨¹è‘‰ï¼‰: 0.05029297
 â€¢ lightï¼ˆå…‰ï¼‰: 0.048126098
 â€¢ lamppostï¼ˆç‡ˆæŸ±ï¼‰: 0.048095703
 â€¢ billboardsï¼ˆå»£å‘Šç‰Œï¼‰: 0.040039062
 â€¢ artï¼ˆè—è¡“ï¼‰: 0.03977703
 â€¢ branchï¼ˆæ¨¹æï¼‰: 0.03930664
 â€¢ decorationï¼ˆè£é£¾ï¼‰: 0.036868922
 â€¢ flagï¼ˆæ——å¹Ÿï¼‰: 0.036865234
....ç•¥
```
#### RecognizeTextRequest

è¾¨è­˜åœ–ç‰‡ä¸­çš„æ–‡å­—å…§å®¹ã€‚\(a\.k\.a åœ–ç‰‡è½‰æ–‡å­—\)


![[\[éŠè¨˜\] 2023 æ±äº¬ 5 æ—¥è‡ªç”±è¡Œ](../9da2c51fa4f2/)](/assets/755509180ca8/1*XL40lLT774PfO60rCIfnxA.jpeg)

[\[éŠè¨˜\] 2023 æ±äº¬ 5 æ—¥è‡ªç”±è¡Œ](../9da2c51fa4f2/)
```swift
if #available(iOS 18.0, *) {
    // æ–°çš„ä½¿ç”¨ Swift ç‰¹æ€§çš„ API
    var request = RecognizeTextRequest()
    request.recognitionLevel = .accurate
    request.recognitionLanguages = [.init(identifier: "ja-JP"), .init(identifier: "en-US")] // Specify language code, e.g., Traditional Chinese
    Task {
        do {
            let observations = try await request.perform(on: URL(string: "https://zhgchg.li/assets/9da2c51fa4f2/1*fBbNbDepYioQ-3-0XUkF6Q.jpeg")!)
            observations.forEach {
                observation in
                let topCandidate = observation.topCandidates(1).first
                print(topCandidate?.string ?? "No text recognized")
            }
        }
        catch {
            print("Request failed: \(error)")
        }
    }
} else {
    // èˆŠçš„å¯«æ³•
    let completionHandler: VNRequestCompletionHandler = {
        request, error in
        guard error == nil else {
            print("Request failed: \(String(describing: error))")
            return
        }
        guard let observations = request.results as? [VNRecognizedTextObservation] else {
            return
        }
        observations.forEach {
            observation in
            let topCandidate = observation.topCandidates(1).first
            print(topCandidate?.string ?? "No text recognized")
        }
    }

    let request = VNRecognizeTextRequest(completionHandler: completionHandler)
    request.recognitionLevel = .accurate
    request.recognitionLanguages = ["ja-JP", "en-US"] // Specify language code, e.g., Traditional Chinese
    DispatchQueue.global().async {
        let handler = VNImageRequestHandler(url: URL(string: "https://zhgchg.li/assets/9da2c51fa4f2/1*fBbNbDepYioQ-3-0XUkF6Q.jpeg")!, options: [:])
        do {
            try handler.perform([request])
        }
        catch {
            print("Request failed: \(error)")
        }
    }
}
```

**åˆ†æçµæœï¼š**
```makefile
LE LABO é’å±±åº—
TEL:03-6419-7167
ï¼ŠãŠè²·ã„ä¸Šã’ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™*
No: 21347
æ—¥ä»˜ï¼š2023/06/10 14.14.57
æ‹…å½“ï¼š
1690370
ãƒ¬ã‚¸ï¼š008A 1
å•†å“å
ç¨è¾¼ä¸Šä»£æ•°é‡ç¨è¾¼åˆè¨ˆ
ã‚«ã‚¤ã‚¢ãƒƒã‚¯ 10 EDP FB 15ML
J1P7010000S
16,800
16,800
ã‚¢ãƒŠã‚¶ãƒ¼ 13 EDP FB 15ML
J1PJ010000S
10,700
10,700
ãƒªãƒƒãƒ—ãƒ‘ãƒ¼ãƒ  15ML
JOWC010000S
2,000
1
åˆè¨ˆé‡‘é¡
ï¼ˆå†…ç¨é¡ï¼‰
CARD
2,000
3ç‚¹å¾¡è²·ä¸Šã’
29,500
0
29,500
29,500
```
#### DetectBarcodesRequest

åµæ¸¬åœ–ç‰‡ä¸­çš„æ¢ç¢¼ã€QRCode æ•¸æ“šã€‚


![](/assets/755509180ca8/1*Z72y9rIwIKQCmnnuwsq0uQ.png)



![æ³°åœ‹ç•¶åœ°äººæ¨è–¦éµç‰Œæ¸…æ¶¼è†](/assets/755509180ca8/1*s3V1UQRIqto-iG1e30PK7Q.jpeg)

æ³°åœ‹ç•¶åœ°äººæ¨è–¦éµç‰Œæ¸…æ¶¼è†
```swift
let filePath = Bundle.main.path(forResource: "IMG_6777", ofType: "png")! // æœ¬åœ°æ¸¬è©¦åœ–ç‰‡
let fileURL = URL(filePath: filePath)
if #available(iOS 18.0, *) {
    // æ–°çš„ä½¿ç”¨ Swift ç‰¹æ€§çš„ API
    let request = DetectBarcodesRequest()
    Task {
        do {
            let observations = try await request.perform(on: fileURL)
            observations.forEach {
                observation in
                print("Payload: \(observation.payloadString ?? "No payload")")
                print("Symbology: \(observation.symbology)")
            }
        }
        catch {
            print("Request failed: \(error)")
        }
    }
} else {
    // èˆŠçš„å¯«æ³•
    let completionHandler: VNRequestCompletionHandler = {
        request, error in
        guard error == nil else {
            print("Request failed: \(String(describing: error))")
            return
        }
        guard let observations = request.results as? [VNBarcodeObservation] else {
            return
        }
        observations.forEach {
            observation in
            print("Payload: \(observation.payloadStringValue ?? "No payload")")
            print("Symbology: \(observation.symbology.rawValue)")
        }
    }

    let request = VNDetectBarcodesRequest(completionHandler: completionHandler)
    DispatchQueue.global().async {
        let handler = VNImageRequestHandler(url: fileURL, options: [:])
        do {
            try handler.perform([request])
        }
        catch {
            print("Request failed: \(error)")
        }
    }
}
```

**åˆ†æçµæœï¼š**
```makefile
Payload: 8859126000911
Symbology: VNBarcodeSymbologyEAN13
Payload: https://lin.ee/hGynbVM
Symbology: VNBarcodeSymbologyQR
Payload: http://www.hongthaipanich.com/
Symbology: VNBarcodeSymbologyQR
Payload: https://www.facebook.com/qr?id=100063856061714
Symbology: VNBarcodeSymbologyQR
```
#### RecognizeAnimalsRequest

è¾¨è­˜åœ–ç‰‡ä¸­çš„å‹•ç‰©èˆ‡ç½®ä¿¡åº¦ã€‚


![](/assets/755509180ca8/1*5zF3gA3WB1Q0-_cgt6mTCw.png)



![[meme Source](https://www.redbubble.com/i/canvas-print/Funny-AI-Woman-yelling-at-a-cat-meme-design-Machine-learning-by-omolog/43039298.5Y5V7){:target="_blank"}](/assets/755509180ca8/1*KZ7mdE8fobP-_oj7tJf_Ww.jpeg)

[meme Source](https://www.redbubble.com/i/canvas-print/Funny-AI-Woman-yelling-at-a-cat-meme-design-Machine-learning-by-omolog/43039298.5Y5V7){:target="_blank"}
```swift
let filePath = Bundle.main.path(forResource: "IMG_5026", ofType: "png")! // æœ¬åœ°æ¸¬è©¦åœ–ç‰‡
let fileURL = URL(filePath: filePath)
if #available(iOS 18.0, *) {
    // æ–°çš„ä½¿ç”¨ Swift ç‰¹æ€§çš„ API
    let request = RecognizeAnimalsRequest()
    Task {
        do {
            let observations = try await request.perform(on: fileURL)
            observations.forEach {
                observation in
                let labels = observation.labels
                labels.forEach {
                    label in
                    print("Detected animal: \(label.identifier) with confidence: \(label.confidence)")
                }
            }
        }
        catch {
            print("Request failed: \(error)")
        }
    }
} else {
    // èˆŠçš„å¯«æ³•
    let completionHandler: VNRequestCompletionHandler = {
        request, error in
        guard error == nil else {
            print("Request failed: \(String(describing: error))")
            return
        }
        guard let observations = request.results as? [VNRecognizedObjectObservation] else {
            return
        }
        observations.forEach {
            observation in
            let labels = observation.labels
            labels.forEach {
                label in
                print("Detected animal: \(label.identifier) with confidence: \(label.confidence)")
            }
        }
    }

    let request = VNRecognizeAnimalsRequest(completionHandler: completionHandler)
    DispatchQueue.global().async {
        let handler = VNImageRequestHandler(url: fileURL, options: [:])
        do {
            try handler.perform([request])
        }
        catch {
            print("Request failed: \(error)")
        }
    }
}
```

åˆ†æçµæœï¼š
```csharp
Detected animal: Cat with confidence: 0.77245045
```
#### å…¶ä»–ï¼š
- åµæ¸¬åœ–åƒä¸­çš„äººé«”ï¼šDetectHumanRectanglesRequest
- åµæ¸¬äººã€å‹•ç‰©çš„ Pose å‹•ä½œ \(3D or 2D éƒ½å¯ä»¥\)ï¼šDetectAnimalBodyPoseRequestã€DetectHumanBodyPose3DRequestã€DetectHumanBodyPoseRequestã€DetectHumanHandPoseRequest
- æª¢æ¸¬ä¸¦è¿½è¹¤ç‰©ä»¶çš„é‹å‹•è»Œè·¡\(åœ¨å½±ç‰‡ã€å‹•ç•«ä¸åŒçš„åµä¸­\)ï¼šDetectTrajectoriesRequestã€TrackObjectRequestã€TrackRectangleRequest

#### **iOS â‰¥ 18 Update Highlight:**
```rust
VN*Request -> *Request (e.g. VNDetectBarcodesRequest -> DetectBarcodesRequest)
VN*Observation -> *Observation (e.g. VNRecognizedObjectObservation -> RecognizedObjectObservation)
VNRequestCompletionHandler -> async/await
VNImageRequestHandler.perform([VN*Request]) -> *Request.perform()
```
### WWDC Example

WWDC å®˜æ–¹å½±ç‰‡ä»¥è¶…å¸‚å•†å“æƒæå™¨ç‚ºä¾‹ã€‚
#### é¦–å…ˆå¤§å¤šæ•¸çš„å•†å“éƒ½æœ‰ Barcode å¯ä¾›æƒæ


![](/assets/755509180ca8/1*YT_Uf8eEi36Iv7zcOrmP4A.png)



![](/assets/755509180ca8/1*J9uIwRKubLoJoC7i096AdQ.png)



![](/assets/755509180ca8/1*gKg-NfHYqy7uBqe5hxzBSw.png)


æˆ‘å€‘å¯ä»¥å¾ `observation.boundingBox` å–å¾— Barcode æ‰€åœ¨ä½ç½®ï¼Œä½†ä¸åŒæ–¼å¸¸è¦‹ UIView åº§æ¨™ç³»ï¼Œ `BoundingBox` çš„ç›¸å°ä½ç½®èµ·é»æ˜¯å¾å·¦ä¸‹è§’ï¼Œå€¼çš„ç¯„åœè½åœ¨ 0~1 ä¹‹é–“ã€‚
```swift
let filePath = Bundle.main.path(forResource: "IMG_6785", ofType: "png")! // æœ¬åœ°æ¸¬è©¦åœ–ç‰‡
let fileURL = URL(filePath: filePath)
if #available(iOS 18.0, *) {
    // æ–°çš„ä½¿ç”¨ Swift ç‰¹æ€§çš„ API
    var request = DetectBarcodesRequest()
    request.symbologies = [.ean13] // å¦‚æœåªè¦æƒæ EAN13 Barcodeï¼Œå¯ç›´æ¥æŒ‡å®šï¼Œæå‡æ•ˆèƒ½
    Task {
        do {
            let observations = try await request.perform(on: fileURL)
            if let observation = observations.first {
                DispatchQueue.main.async {
                    self.infoLabel.text = observation.payloadString
                    // æ¨™è¨˜é¡è‰² Layer
                    let colorLayer = CALayer()
                    // iOS >=18 æ–°çš„åº§æ¨™è½‰æ› API toImageCoordinates
                    // æœªç¶“æ¸¬è©¦ï¼Œå¯¦éš›å¯èƒ½é‚„éœ€è¦è¨ˆç®— ContentMode = AspectFit çš„ä½ç§»:
                    colorLayer.frame = observation.boundingBox.toImageCoordinates(self.baseImageView.frame.size, origin: .upperLeft)
                    colorLayer.backgroundColor = UIColor.red.withAlphaComponent(0.5).cgColor
                    self.baseImageView.layer.addSublayer(colorLayer)
                }
                print("BoundingBox: \(observation.boundingBox.cgRect)")
                print("Payload: \(observation.payloadString ?? "No payload")")
                print("Symbology: \(observation.symbology)")
            }
        }
        catch {
            print("Request failed: \(error)")
        }
    }
} else {
    // èˆŠçš„å¯«æ³•
    let completionHandler: VNRequestCompletionHandler = {
        request, error in
        guard error == nil else {
            print("Request failed: \(String(describing: error))")
            return
        }
        guard let observations = request.results as? [VNBarcodeObservation] else {
            return
        }
        if let observation = observations.first {
            DispatchQueue.main.async {
                self.infoLabel.text = observation.payloadStringValue
                // æ¨™è¨˜é¡è‰² Layer
                let colorLayer = CALayer()
                colorLayer.frame = self.convertBoundingBox(observation.boundingBox, to: self.baseImageView)
                colorLayer.backgroundColor = UIColor.red.withAlphaComponent(0.5).cgColor
                self.baseImageView.layer.addSublayer(colorLayer)
            }
            print("BoundingBox: \(observation.boundingBox)")
            print("Payload: \(observation.payloadStringValue ?? "No payload")")
            print("Symbology: \(observation.symbology.rawValue)")
        }
    }

    let request = VNDetectBarcodesRequest(completionHandler: completionHandler)
    request.symbologies = [.ean13] // å¦‚æœåªè¦æƒæ EAN13 Barcodeï¼Œå¯ç›´æ¥æŒ‡å®šï¼Œæå‡æ•ˆèƒ½
    DispatchQueue.global().async {
        let handler = VNImageRequestHandler(url: fileURL, options: [:])
        do {
            try handler.perform([request])
        }
        catch {
            print("Request failed: \(error)")
        }
    }
}
```

**iOS â‰¥ 18 Update Highlight:**
```less
// iOS >=18 æ–°çš„åº§æ¨™è½‰æ› API toImageCoordinates
observation.boundingBox.toImageCoordinates(CGSize, origin: .upperLeft)
// https://developer.apple.com/documentation/vision/normalizedpoint/toimagecoordinates(from:imagesize:origin:)
```

**Helper:**
```swift
// Gen by ChatGPT 4o
// å› ç‚ºç…§ç‰‡åœ¨ ImageView æ˜¯è¨­å®š ContentMode = AspectFit
// æ‰€ä»¥è¦å¤šè¨ˆç®—ä¸Šä¸‹å›  Fit é€ æˆçš„ç©ºç™½ä½ç§»
func convertBoundingBox(_ boundingBox: CGRect, to view: UIImageView) -> CGRect {
    guard let image = view.image else {
        return .zero
    }

    let imageSize = image.size
    let viewSize = view.bounds.size
    let imageRatio = imageSize.width / imageSize.height
    let viewRatio = viewSize.width / viewSize.height
    var scaleFactor: CGFloat
    var offsetX: CGFloat = 0
    var offsetY: CGFloat = 0
    if imageRatio > viewRatio {
        // åœ–åƒåœ¨å¯¬åº¦æ–¹å‘ä¸Šé©é…
        scaleFactor = viewSize.width / imageSize.width
        offsetY = (viewSize.height - imageSize.height * scaleFactor) / 2
    }

    else {
        // åœ–åƒåœ¨é«˜åº¦æ–¹å‘ä¸Šé©é…
        scaleFactor = viewSize.height / imageSize.height
        offsetX = (viewSize.width - imageSize.width * scaleFactor) / 2
    }

    let x = boundingBox.minX * imageSize.width * scaleFactor + offsetX
    let y = (1 - boundingBox.maxY) * imageSize.height * scaleFactor + offsetY
    let width = boundingBox.width * imageSize.width * scaleFactor
    let height = boundingBox.height * imageSize.height * scaleFactor
    return CGRect(x: x, y: y, width: width, height: height)
}
```

**è¼¸å‡ºçµæœ**
```makefile
BoundingBox: (0.5295758928571429, 0.21408638121589782, 0.0943080357142857, 0.21254415360708087)
Payload: 4710018183805
Symbology: VNBarcodeSymbologyEAN13
```
#### éƒ¨åˆ†å•†å“ç„¡ Barcodeï¼Œå¦‚æ•£è£æ°´æœåªæœ‰å•†å“æ¨™ç±¤


![](/assets/755509180ca8/1*jeZhLtg9j11kgOAvKZmevg.jpeg)



![](/assets/755509180ca8/1*YNokMMUewMA2kzjoGmMJPw.png)


å› æ­¤æˆ‘å€‘çš„æƒç„å™¨ä¹Ÿéœ€è¦åŒæ™‚æ”¯æ´æƒæç´”æ–‡å­—æ¨™ç±¤ã€‚
```swift
let filePath = Bundle.main.path(forResource: "apple", ofType: "jpg")! // æœ¬åœ°æ¸¬è©¦åœ–ç‰‡
let fileURL = URL(filePath: filePath)
if #available(iOS 18.0, *) {
    // æ–°çš„ä½¿ç”¨ Swift ç‰¹æ€§çš„ API
    var barcodesRequest = DetectBarcodesRequest()
    barcodesRequest.symbologies = [.ean13] // å¦‚æœåªè¦æƒæ EAN13 Barcodeï¼Œå¯ç›´æ¥æŒ‡å®šï¼Œæå‡æ•ˆèƒ½
    var textRequest = RecognizeTextRequest()
    textRequest.recognitionLanguages = [.init(identifier: "zh-Hnat"), .init(identifier: "en-US")]
    Task {
        do {
            let handler = ImageRequestHandler(fileURL)
            // parameter pack syntax and we must wait for all requests to finish before we can use their results.
            // let (barcodesObservation, textObservation, ...) = try await handler.perform(barcodesRequest, textRequest, ...)
            let (barcodesObservation, textObservation) = try await handler.perform(barcodesRequest, textRequest)
            if let observation = barcodesObservation.first {
                DispatchQueue.main.async {
                    self.infoLabel.text = observation.payloadString
                    // æ¨™è¨˜é¡è‰² Layer
                    let colorLayer = CALayer()
                    // iOS >=18 æ–°çš„åº§æ¨™è½‰æ› API toImageCoordinates
                    // æœªç¶“æ¸¬è©¦ï¼Œå¯¦éš›å¯èƒ½é‚„éœ€è¦è¨ˆç®— ContentMode = AspectFit çš„ä½ç§»:
                    colorLayer.frame = observation.boundingBox.toImageCoordinates(self.baseImageView.frame.size, origin: .upperLeft)
                    colorLayer.backgroundColor = UIColor.red.withAlphaComponent(0.5).cgColor
                    self.baseImageView.layer.addSublayer(colorLayer)
                }
                print("BoundingBox: \(observation.boundingBox.cgRect)")
                print("Payload: \(observation.payloadString ?? "No payload")")
                print("Symbology: \(observation.symbology)")
            }
            textObservation.forEach {
                observation in
                let topCandidate = observation.topCandidates(1).first
                print(topCandidate?.string ?? "No text recognized")
            }
        }
        catch {
            print("Request failed: \(error)")
        }
    }
} else {
    // èˆŠçš„å¯«æ³•
    let barcodesCompletionHandler: VNRequestCompletionHandler = {
        request, error in
        guard error == nil else {
            print("Request failed: \(String(describing: error))")
            return
        }
        guard let observations = request.results as? [VNBarcodeObservation] else {
            return
        }
        if let observation = observations.first {
            DispatchQueue.main.async {
                self.infoLabel.text = observation.payloadStringValue
                // æ¨™è¨˜é¡è‰² Layer
                let colorLayer = CALayer()
                colorLayer.frame = self.convertBoundingBox(observation.boundingBox, to: self.baseImageView)
                colorLayer.backgroundColor = UIColor.red.withAlphaComponent(0.5).cgColor
                self.baseImageView.layer.addSublayer(colorLayer)
            }
            print("BoundingBox: \(observation.boundingBox)")
            print("Payload: \(observation.payloadStringValue ?? "No payload")")
            print("Symbology: \(observation.symbology.rawValue)")
        }
    }

    let textCompletionHandler: VNRequestCompletionHandler = {
        request, error in
        guard error == nil else {
            print("Request failed: \(String(describing: error))")
            return
        }
        guard let observations = request.results as? [VNRecognizedTextObservation] else {
            return
        }
        observations.forEach {
            observation in
            let topCandidate = observation.topCandidates(1).first
            print(topCandidate?.string ?? "No text recognized")
        }
    }

    let barcodesRequest = VNDetectBarcodesRequest(completionHandler: barcodesCompletionHandler)
    barcodesRequest.symbologies = [.ean13] // å¦‚æœåªè¦æƒæ EAN13 Barcodeï¼Œå¯ç›´æ¥æŒ‡å®šï¼Œæå‡æ•ˆèƒ½
    let textRequest = VNRecognizeTextRequest(completionHandler: textCompletionHandler)
    textRequest.recognitionLevel = .accurate
    textRequest.recognitionLanguages = ["en-US"]
    DispatchQueue.global().async {
        let handler = VNImageRequestHandler(url: fileURL, options: [:])
        do {
            try handler.perform([barcodesRequest, textRequest])
        }
        catch {
            print("Request failed: \(error)")
        }
    }
}
```

**è¼¸å‡ºçµæœï¼š**
```
94128s
ORGANIC
Pink LadyÂ®
Produce of USh
```

**iOS â‰¥ 18 Update Highlight:**
```swift
let handler = ImageRequestHandler(fileURL)
// parameter pack syntax and we must wait for all requests to finish before we can use their results.
// let (barcodesObservation, textObservation, ...) = try await handler.perform(barcodesRequest, textRequest, ...)
let (barcodesObservation, textObservation) = try await handler.perform(barcodesRequest, textRequest)
```
#### iOS â‰¥ 18 [performAll\( \)](https://developer.apple.com/documentation/vision/imagerequesthandler/performall(_:)?changes=latest_minor){:target="_blank"} æ–¹æ³•


![](/assets/755509180ca8/1*z0364eYD4F4On194EgQ1kQ.png)


å‰é¢çš„ `perform(barcodesRequest, textRequest)` è™•ç† Barcode æƒæè·Ÿæ–‡å­—æƒæçš„æ–¹å¼éœ€è¦ç­‰åˆ°å…©å€‹ Request éƒ½å®Œæˆæ‰èƒ½ç¹¼çºŒåŸ·è¡Œï¼›iOS 18 é–‹å§‹æä¾›æ–°çš„ `performAll()` æ–¹æ³•ï¼Œå°‡å›æ‡‰æ–¹å¼æ”¹ç‚ºä¸²æµï¼Œåœ¨æ”¶åˆ°å…¶ä¸­ä¸€å€‹ Reqeust çµæœæ˜¯å°±èƒ½åšå°æ‡‰è™•ç†ï¼Œä¾‹å¦‚æƒæåˆ° Barcode å°±ç›´æ¥éŸ¿æ‡‰ã€‚
```swift
if #available(iOS 18.0, *) {
    // æ–°çš„ä½¿ç”¨ Swift ç‰¹æ€§çš„ API
    var barcodesRequest = DetectBarcodesRequest()
    barcodesRequest.symbologies = [.ean13] // å¦‚æœåªè¦æƒæ EAN13 Barcodeï¼Œå¯ç›´æ¥æŒ‡å®šï¼Œæå‡æ•ˆèƒ½
    var textRequest = RecognizeTextRequest()
    textRequest.recognitionLanguages = [.init(identifier: "zh-Hnat"), .init(identifier: "en-US")]
    Task {
        let handler = ImageRequestHandler(fileURL)
        let observation = handler.performAll([barcodesRequest, textRequest] as [any VisionRequest])
        for try await result in observation {
            switch result {
                case .detectBarcodes(_, let barcodesObservation):
                if let observation = barcodesObservation.first {
                    DispatchQueue.main.async {
                        self.infoLabel.text = observation.payloadString
                        // æ¨™è¨˜é¡è‰² Layer
                        let colorLayer = CALayer()
                        // iOS >=18 æ–°çš„åº§æ¨™è½‰æ› API toImageCoordinates
                        // æœªç¶“æ¸¬è©¦ï¼Œå¯¦éš›å¯èƒ½é‚„éœ€è¦è¨ˆç®— ContentMode = AspectFit çš„ä½ç§»:
                        colorLayer.frame = observation.boundingBox.toImageCoordinates(self.baseImageView.frame.size, origin: .upperLeft)
                        colorLayer.backgroundColor = UIColor.red.withAlphaComponent(0.5).cgColor
                        self.baseImageView.layer.addSublayer(colorLayer)
                    }
                    print("BoundingBox: \(observation.boundingBox.cgRect)")
                    print("Payload: \(observation.payloadString ?? "No payload")")
                    print("Symbology: \(observation.symbology)")
                }
                case .recognizeText(_, let textObservation):
                textObservation.forEach {
                    observation in
                    let topCandidate = observation.topCandidates(1).first
                    print(topCandidate?.string ?? "No text recognized")
                }
                default:
                print("Unrecongnized result: \(result)")
            }
        }
    }
}
```
### Optimize with Swift Concurrency


![](/assets/755509180ca8/1*LgxxMOVS6is3n6EqPWqA6Q.png)



![](/assets/755509180ca8/1*80CFJpkb-gjy3bJs4jAC2A.png)


å‡è¨­æˆ‘å€‘æœ‰ä¸€å€‹åœ–ç‰‡ç‰†åˆ—è¡¨ï¼Œæ¯å¼µåœ–ç‰‡éƒ½éœ€è¦è‡ªå‹•è£åˆ‡å‡ºç‰©ä»¶ä¸»é«”ï¼›é€™æ™‚å€™å¯ä»¥å–„ç”¨ Swift Concurrency å¢åŠ è¼‰å…¥æ•ˆç‡ã€‚
#### **åŸå§‹å¯«æ³•**
```swift
func generateThumbnail(url: URL) async throws -> UIImage {
  let request = GenerateAttentionBasedSaliencyImageRequest()
  let saliencyObservation = try await request.perform(on: url)
  return cropImage(url, to: saliencyObservation.salientObjects)
}
    
func generateAllThumbnails() async throws {
  for image in images {
    image.thumbnail = try await generateThumbnail(url: image.url)
  }
}
```

ä¸€æ¬¡åªåŸ·è¡Œä¸€å€‹ï¼Œæ•ˆç‡ã€æ•ˆèƒ½ç·©æ…¢ã€‚
#### **å„ªåŒ– \(1\) â€” TaskGroup** Concurrency
```swift

func generateAllThumbnails() async throws {
  try await withThrowingDiscardingTaskGroup { taskGroup in
    for image in images {
      image.thumbnail = try await generateThumbnail(url: image.url)
     }
  }
}
```

å°‡æ¯å€‹ Task éƒ½åŠ å…¥ TaskGroup Concurrency åŸ·è¡Œã€‚


> **_å•é¡Œï¼šåœ–ç‰‡è¾¨è­˜ã€æˆªåœ–æ“ä½œéå¸¸æ¶ˆè€—è¨˜æ†¶é«”æ€§èƒ½ï¼Œå¦‚æœç„¡ç¯€åˆ¶ç‹‚åŠ ä¸¦è¡Œä»»å‹™ï¼Œå¯èƒ½é€ æˆä½¿ç”¨è€…å¡é “ã€OOM é–ƒé€€å•é¡Œã€‚_** 




#### å„ªåŒ– \(2\) â€” TaskGroup Concurrency \+ é™åˆ¶ä¸¦è¡Œæ•¸é‡
```swift
func generateAllThumbnails() async throws {
    try await withThrowingDiscardingTaskGroup {
        taskGroup in
        // æœ€å¤šåŸ·è¡Œæ•¸é‡ä¸å¾—è¶…é 5
        let maxImageTasks = min(5, images.count)
        // å…ˆå¡«å…… 5 å€‹ Task
        for index in 0..<maxImageTasks {
            taskGroup.addTask {
                image[index].thumbnail = try await generateThumbnail(url: image[index].url)
            }
        }
        var nextIndex = maxImageTasks
        for try await _ in taskGroup {
            // taskGroup è£¡ Task await å®Œæˆæ™‚...
            // æª¢æŸ¥ Index æ˜¯å¦åˆ°å°¾éƒ¨
            if nextIndex < images.count {
                let image = images[nextIndex]
                // ç¹¼çºŒé€å€‹å¡«å…… Task (å°‡ç¶­æŒåœ¨æœ€å¤š 5 å€‹)
                taskGroup.addTask {
                    image.thumbnail = try await generateThumbnail(url: image.url)
                }
                nextIndex += 1
            }
        }
    }
}
```
### Update an existing Vision app


![](/assets/755509180ca8/1*0OhzcxQ7OpSujeyvt9918Q.png)



![](/assets/755509180ca8/1*MH4Xa0RB2DZQ1Fl9-kItSw.png)

1. Vision å°‡åœ¨å…·å‚™ç¥ç¶“å¼•æ“çš„è¨­å‚™ä¸Šç§»é™¤å°éƒ¨åˆ†è«‹æ±‚çš„ CPU å’Œ GPU æ”¯æŒã€‚åœ¨é€™äº›è¨­å‚™ä¸Šï¼Œç¥ç¶“å¼•æ“æ˜¯æ€§èƒ½æœ€å¥½çš„é¸æ“‡ã€‚
å¯ä»¥ä½¿ç”¨ `supportedComputeDevices()` API é€²è¡Œæª¢æŸ¥
2. ç§»é™¤æ‰€æœ‰ VN å‰ç¶´
`VNXXRequest` , `VNXXXObservation` \-&gt; `Reqeust` , `Observation`
3. ä½¿ç”¨ async/await å–ä»£åŸæœ¬çš„ VNRequestCompletionHandler
4. ç›´æ¥ä½¿ç”¨ `*Request.perform()` å–ä»£åŸæœ¬çš„ `VNImageRequestHandler.perform([VN*Request])`

### Wrap\-up
- ç‚º Swift èªè¨€ç‰¹æ€§æ–°è¨­è¨ˆçš„ API
- æ–°çš„åŠŸèƒ½ã€æ–¹æ³•éƒ½ç‚º Swift Only, iOS â‰¥ 18 å¯ç”¨
- æ–°çš„åœ–ç‰‡è©•åˆ†åŠŸèƒ½ã€èº«é«”ï¼‹æ‰‹éƒ¨å‹•ä½œè¿½è¹¤

### Thanks\!


![](/assets/755509180ca8/1*BK_5eH1i4-drOUOGnuQRSg.png)

### KKday æ‹›å‹Ÿå·¥å•†


![](/assets/755509180ca8/1*kjcldhvCP1cM-QqDfRFaYg.png)


ğŸ‘‰ğŸ‘‰ğŸ‘‰æœ¬æ¬¡è®€æ›¸æœƒåˆ†äº«æºæ–¼ KKday App Team çµ„å…§æ¯é€±æŠ€è¡“åˆ†äº«æ´»å‹•ï¼Œ **ç›®å‰åœ˜éšŠä¹Ÿæ­£åœ¨ç†±æƒ…æ‹›å‹Ÿ [Senior iOS Engineer](https://kkday.bamboohr.com/careers/25?source=aWQ9Mjk%3D){:target="_blank"} ï¼Œæœ‰èˆˆè¶£çš„æœ‹å‹æ­¡è¿æŠ•éå±¥æ­·** ã€‚ğŸ‘ˆğŸ‘ˆğŸ‘ˆ
#### åƒè€ƒè³‡æ–™
#### [Discover Swift enhancements in the Vision framework](https://developer.apple.com/videos/play/wwdc2024/10163/){:target="_blank"}

The Vision Framework API has been redesigned to leverage modern Swift features like concurrency, making it easier and faster to integrate a wide array of Vision algorithms into your app\. Weâ€™ll tour the updated API and share sample code, along with best practices, to help you get the benefits of this framework with less coding effort\. Weâ€™ll also demonstrate two new features: image aesthetics and holistic body pose\.
### Chapters
- 0:00 â€” [Introduction](https://developer.apple.com/videos/play/wwdc2024/10163/?time=0){:target="_blank"}
- 1:07 â€” [New Vision API](https://developer.apple.com/videos/play/wwdc2024/10163/?time=67){:target="_blank"}
- 1:47 â€” [Get started with Vision](https://developer.apple.com/videos/play/wwdc2024/10163/?time=107){:target="_blank"}
- 8:59 â€” [Optimize with Swift Concurrency](https://developer.apple.com/videos/play/wwdc2024/10163/?time=539){:target="_blank"}
- 11:05 â€” [Update an existing Vision app](https://developer.apple.com/videos/play/wwdc2024/10163/?time=665){:target="_blank"}
- 13:46 â€” [Whatâ€™s new in Vision?](https://developer.apple.com/videos/play/wwdc2024/10163/?time=826){:target="_blank"}

#### [Vision framework Apple Developer Documentation](https://developer.apple.com/documentation/vision/){:target="_blank"}

\-


æœ‰ä»»ä½•å•é¡ŒåŠæŒ‡æ•™æ­¡è¿ [èˆ‡æˆ‘è¯çµ¡](https://www.zhgchg.li/contact){:target="_blank"} ã€‚



_[Post](https://medium.com/kkdaytech/ios-vision-framework-x-wwdc-24-discover-swift-enhancements-in-the-vision-framework-session-755509180ca8){:target="_blank"} converted from Medium by [ZMediumToMarkdown](https://github.com/ZhgChgLi/ZMediumToMarkdown){:target="_blank"}._