---
author: ZhgChgLi
categories:
- KKday Tech Blog
date: 2024-08-13T08:10:37.015+0000
description: Vision framework åŠŸèƒ½å›é¡¾ & iOS 18 æ–° Swift API è¯•ç©
image:
  path: /assets/755509180ca8/1*NqN-_MAE4tt11n6MnUQWxQ.jpeg
last_modified_at: 2024-08-14T12:07:49.774+0000
render_with_liquid: false
tags:
- ios-app-development
- vision-framework
- apple-intelligence
- ai
- machine-learning
title: iOS Vision framework x WWDC 24 Discover Swift enhancements in the Vision framework
  Session
---

### iOS Vision framework x WWDC 24 Discover Swift enhancements in the Vision framework Session



Vision framework åŠŸèƒ½å›é¡¾ & iOS 18 æ–° Swift API è¯•ç©



![Photo by [BoliviaInteligente](https://unsplash.com/@boliviainteligente?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash){:target="_blank"}](/assets/755509180ca8/1*NqN-_MAE4tt11n6MnUQWxQ.jpeg)



Photo by [BoliviaInteligente](https://unsplash.com/@boliviainteligente?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash){:target="_blank"}



#### ä¸»é¢˜



![è·Ÿ Vision Pro çš„å…³ç³»å°±è·Ÿçƒ­ç‹—è·Ÿç‹—çš„å…³ç³»ä¸€æ ·ï¼Œæ¯«æ— å…³ç³»ã€‚](/assets/755509180ca8/1*ebqm2jzCK1GSrDDY0XtrUA.png)



è·Ÿ Vision Pro çš„å…³ç³»å°±è·Ÿçƒ­ç‹—è·Ÿç‹—çš„å…³ç³»ä¸€æ ·ï¼Œæ¯«æ— å…³ç³»ã€‚



### Vision framework



Vision framework æ˜¯ Apple æ•´åˆæœºå™¨å­¦ä¹ çš„å›¾åƒè¾¨è¯†æ¡†æ¶ï¼Œè®©å¼€å‘è€…å¯ä»¥ç®€å•å¿«é€Ÿåœ°å®ç°å¸¸è§çš„å›¾åƒè¾¨è¯†åŠŸèƒ½ï¼›Vision framework æ—©åœ¨ iOS 11.0+ (2017/ iPhone 8) å°±å·²æ¨å‡ºï¼ŒæœŸé—´ä¸æ–­åœ°è¿­ä»£ä¼˜åŒ–ï¼Œå¹¶å®Œå–„ä¸ Swift Concurrency çš„ç‰¹æ€§æ•´åˆæå‡æ‰§è¡Œæ•ˆèƒ½ï¼Œå¹¶ä¸”ä» iOS 18.0 æä¾›å…¨æ–°çš„ Swift Vision framework API å‘æŒ¥ Swift Concurrency æœ€å¤§æ•ˆæœã€‚



**Vision framework ç‰¹è‰²**



- å†…å»ºä¼—å¤šå›¾ç‰‡è¾¨è¯†ã€åŠ¨æ€è¿½è¸ªæ–¹æ³• (iOS 18 ä¸ºæ­¢ä¸€å…± 31 ç§)


- On-Device å•çº¯ä½¿ç”¨æ‰‹æœºæ™¶ç‰‡è¿ç®—ï¼Œè¾¨è¯†è¿‡ç¨‹ä¸ä¾èµ–äº‘ç«¯æœåŠ¡ï¼Œå¿«é€Ÿåˆå®‰å…¨


- API ç®€å•å¥½æ“ä½œ


- Apple å…¨å¹³å°å‡æ”¯æ´ iOS 11.0+, iPadOS 11.0+, Mac Catalyst 13.0+, macOS 10.13+, tvOS 11.0+, visionOS 1.0+


- å·²å‘å¸ƒå¤šå¹´ (2017~ä»Š) ä¸”ä¸æ–­æ›´æ–°


- æ•´åˆ Swift è¯­è¨€ç‰¹æ€§æå‡è¿ç®—æ•ˆèƒ½



> ***6 å¹´å‰æ›¾ç»å°ç©è¿‡ï¼š [Vision åˆæ¢ â€” APP å¤´åƒä¸Šä¼  è‡ªåŠ¨è¯†åˆ«äººè„¸è£å›¾ (Swift)](../9a9aa892f9a9/)***



> *è¿™æ¬¡æ­é… [WWDC 24 Discover Swift enhancements in the Vision framework Session](https://developer.apple.com/videos/play/wwdc2024/10163/){:target="_blank"} é‡æ–°å›é¡¾å¹¶ç»“åˆæ–°çš„ Swfit ç‰¹æ€§å†ç©ä¸€æ¬¡ã€‚*



#### CoreML



Apple è¿˜æœ‰å¦å¤–ä¸€ä¸ª Framework å« [CoreML](https://developer.apple.com/documentation/coreml){:target="_blank"} ï¼Œä¹Ÿæ˜¯åŸºäº On-Device æ™¶ç‰‡çš„æœºå™¨å­¦ä¹ æ¡†æ¶ï¼›ä½†ä»–å¯ä»¥è®©ä½ è‡ªå·±è®­ç»ƒæƒ³è¾¨è¯†çš„ç‰©ä»¶ã€æ–‡ä»¶æ¨¡å‹ï¼Œå¹¶å°†æ¨¡å‹æ”¾åˆ° App ä¸­ç›´æ¥ä½¿ç”¨ï¼Œæœ‰å…´è¶£çš„æœ‹å‹ä¹Ÿå¯ä»¥ç©çœ‹çœ‹ã€‚(e.g. [å³æ—¶æ–‡ç« åˆ†ç±»](../793bf2cdda0f/) ã€å³æ—¶ [åƒåœ¾è®¯æ¯æ£€æµ‹](https://apps.apple.com/tw/app/%E7%86%8A%E7%8C%AB%E5%90%83%E7%9F%AD%E4%BF%A1-%E5%9E%83%E5%9C%BE%E7%9F%AD%E4%BF%A1%E8%BF%87%E6%BB%A4/id1319191852){:target="_blank"} â€¦)



#### p.s.



[**Vision**](https://developer.apple.com/documentation/vision/){:target="_blank"} **v.s. [VisionKit](https://developer.apple.com/documentation/visionkit){:target="_blank"} ï¼š**



> [***Vision***](https://developer.apple.com/documentation/vision/){:target="*blank"} _ï¼šä¸»è¦ç”¨äºå›¾åƒåˆ†æä»»åŠ¡ï¼Œå¦‚è„¸éƒ¨è¯†åˆ«ã€æ¡ç æ£€æµ‹ã€æ–‡æœ¬è¯†åˆ«ç­‰ã€‚å®ƒæä¾›äº†å¼ºå¤§çš„ API æ¥å¤„ç†å’Œåˆ†æé™æ€å›¾åƒæˆ–è§†é¢‘ä¸­çš„è§†è§‰å†…å®¹ã€‚*



> [***VisionKit***](https://developer.apple.com/documentation/visionkit){:target="*blank"} _ï¼šä¸“é—¨ç”¨äºå¤„ç†ä¸æ–‡ä»¶æ‰«æç›¸å…³çš„ä»»åŠ¡ã€‚å®ƒæä¾›äº†ä¸€ä¸ªæ‰«æä»ªè§†å›¾æ§åˆ¶å™¨ï¼Œå¯ä»¥ç”¨æ¥æ‰«ææ–‡æ¡£ï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡çš„ PDF æˆ–å›¾åƒã€‚*



Vision framework åœ¨ M1 æœºå‹ä¸Šæ— æ³•è·‘åœ¨æ¨¡æ‹Ÿå™¨ï¼Œåªèƒ½æ¥å®ä½“æ‰‹æœºæµ‹è¯•ï¼›åœ¨æ¨¡æ‹Ÿå™¨ç¯å¢ƒæ‰§è¡Œä¼šæŠ›å‡º `Could not create Espresso context` Errorï¼ŒæŸ¥ [å®˜æ–¹è®ºå›è®¨è®ºï¼Œæ²¡æ‰¾åˆ°è§£ç­”](https://forums.developer.apple.com/forums/thread/675806){:target="_blank"} ã€‚



> *å› æ‰‹è¾¹æ²¡æœ‰å®ä½“ iOS 18 è£…ç½®è¿›è¡Œæµ‹è¯•ï¼Œæ‰€ä»¥æœ¬æ–‡ä¸­çš„æ‰€æœ‰æ‰§è¡Œç»“æœéƒ½æ˜¯ä½¿ç”¨æ—§çš„ (iOS 18 ä»¥å‰) çš„å†™æ³•ç»“æœï¼› **å¦‚æ–°å†™æ³•æœ‰å‡ºç°é”™è¯¯å†éº»çƒ¦ç•™è¨€æŒ‡æ•™** ã€‚*



### WWDC 2024 â€” Discover Swift enhancements in the Vision framework



![[Discover Swift enhancements in the Vision framework](https://developer.apple.com/videos/play/wwdc2024/10163/?time=45){:target="_blank"}](/assets/755509180ca8/1*8N5GtY1uqxP-4iAAAticOA.png)



[Discover Swift enhancements in the Vision framework](https://developer.apple.com/videos/play/wwdc2024/10163/?time=45){:target="_blank"}



> *æœ¬æ–‡æ˜¯é’ˆå¯¹ WWDC 24 â€” [Discover Swift enhancements in the Vision framework](https://developer.apple.com/videos/play/wwdc2024/10163/?time=45){:target="_blank"} Session çš„åˆ†äº«ç¬”è®°ï¼Œè·Ÿä¸€äº›è‡ªå·±å®éªŒçš„å¿ƒå¾—ã€‚*



### Introduction â€” Vision framework Features



#### äººè„¸è¾¨è¯†ã€è½®å»“è¯†åˆ«



![](/assets/755509180ca8/1*RNGfE_EeaQhiKAPdJeFYQw.png)



![](/assets/755509180ca8/1*iMdzeLm2aWjATVV6_Kvrjg.png)



#### å›¾åƒå†…å®¹æ–‡å­—è¾¨è¯†



æˆªè‡³ iOS 18 ä¸ºæ­¢ï¼Œæ”¯æ´ 18 ç§è¯­è¨€ã€‚



![](/assets/755509180ca8/1*kU_OYn5w368h-ahDYU4lDw.png)



```swift
// æ”¯æ´çš„è¯­ç³»åˆ—è¡¨
if #available(iOS 18.0, *) {
  print(RecognizeTextRequest().supportedRecognitionLanguages.map { "\($0.languageCode!)-\(($0.region?.identifier ?? $0.script?.identifier)!)" })
} else {
  print(try! VNRecognizeTextRequest().supportedRecognitionLanguages())
}

// å®é™…å¯ç”¨è¾¨è¯†è¯­è¨€ä»¥è¿™ä¸ºä¸»ã€‚
// å®æµ‹ iOS 18 è¾“å‡ºä»¥ä¸‹ç»“æœï¼š
// ["en-US", "fr-FR", "it-IT", "de-DE", "es-ES", "pt-BR", "zh-Hans", "zh-Hant", "yue-Hans", "yue-Hant", "ko-KR", "ja-JP", "ru-RU", "uk-UA", "th-TH", "vi-VT", "ar-SA", "ars-SA"]
// æœªçœ‹åˆ° WWDC æåˆ°çš„ Swedish è¯­è¨€ï¼Œä¸ç¡®å®šæ˜¯è¿˜æ²¡æ¨å‡ºè¿˜æ˜¯è·Ÿè£…ç½®åœ°åŒºã€è¯­ç³»æœ‰å…³è”
```



#### åŠ¨æ€åŠ¨ä½œæ•æ‰



![](/assets/755509180ca8/1*6TfyCcszdD1NdId0bdM16Q.gif)



![](/assets/755509180ca8/1*8y_XXdH36uKpfP0p6BCJQA.gif)



- å¯ä»¥å®ç°äººã€ç‰©ä»¶åŠ¨æ€æ•æ‰


- æ‰‹åŠ¿è¡¥æ‰å®ç°éš”ç©ºç­¾ååŠŸèƒ½



#### Whatâ€™s new in Vision? (iOS 18)â€” å›¾ç‰‡è¯„åˆ†åŠŸèƒ½ (å“è´¨ã€è®°å¿†ç‚¹)



- å¯å¯¹è¾“å…¥å›¾ç‰‡å¾—è®¡ç®—å‡ºåˆ†æ•°ï¼Œæ–¹ä¾¿ç­›é€‰å‡ºä¼˜è´¨ç…§ç‰‡


- åˆ†æ•°è®¡ç®—æ–¹å¼åŒ…å«å¤šä¸ªç»´åº¦ï¼Œä¸åªæ˜¯ç”»è´¨ï¼Œè¿˜æœ‰å…‰çº¿ã€è§’åº¦ã€æ‹æ‘„ä¸»ä½“ã€ **æ˜¯å¦æœ‰è®©äººæ„Ÿåˆ°çš„è®°å¿†ç‚¹** â€¦ç­‰ç­‰



![](/assets/755509180ca8/1*XwjeaHcB6arxJhIR7cFsWg.png)



![](/assets/755509180ca8/1*YdhZlZBlTaIZd4nLxhBtaQ.png)



![](/assets/755509180ca8/1*IhMDFdk6DWwTv1qIG0Gi0Q.png)



WWDC ä¸­ç»™äº†ä»¥ä¸Šä¸‰å¼ å›¾ç‰‡åšè¯´æ˜(ç›¸åŒç”»è´¨ä¹‹ä¸‹)ï¼Œåˆ†åˆ«æ˜¯ï¼š



- é«˜åˆ†çš„å›¾ç‰‡ï¼šå–æ™¯ã€å…‰çº¿ã€æœ‰è®°å¿†ç‚¹


- ä½åˆ†çš„å›¾ç‰‡ï¼šæ²¡æœ‰ä¸»ä½“ã€åƒæ˜¯éšæ‰‹æˆ–ä¸å°å¿ƒæ‹çš„


- ç´ æçš„å›¾ç‰‡ï¼šæŠ€æœ¯ä¸Šæ‹çš„å¾ˆå¥½ä½†æ˜¯æ²¡æœ‰è®°å¿†ç‚¹ï¼Œåƒæ˜¯ä½œä¸ºç´ æå›¾åº“ç”¨çš„å›¾ç‰‡



**iOS â‰¥ 18 New API: [CalculateImageAestheticsScoresRequest](https://developer.apple.com/documentation/vision/calculateimageaestheticsscoresrequest){:target="_blank"}**



```swift
let request = CalculateImageAestheticsScoresRequest()
let result = try await request.perform(on: URL(string: "https://zhgchg.li/assets/cb65fd5ab770/1*yL3vI1ADzwlovctW5WQgJw.jpeg")!)

// ç…§ç‰‡åˆ†æ•°
print(result.overallScore)

// æ˜¯å¦è¢«åˆ¤å®šä¸ºç´ æå›¾ç‰‡
print(result.isUtility)
```



#### Whatâ€™s new in Vision? (iOS 18) â€” èº«ä½“ï¼‹æ‰‹åŠ¿å§¿åŠ¿åŒæ—¶ä¾¦æµ‹



![](/assets/755509180ca8/1*A9320aRV-jdccgiXrmSrJw.png)



ä»¥å¾€åªèƒ½ä¸ªåˆ«ä¾¦æµ‹äººä½“ Pose å’Œ æ‰‹éƒ¨ Poseï¼Œè¿™æ¬¡æ›´æ–°å¯ä»¥è®©å¼€å‘è€…åŒæ—¶ä¾¦æµ‹èº«ä½“ Pose + æ‰‹éƒ¨ Poseï¼ŒåˆæˆåŒä¸€ä¸ªè¯·æ±‚è·Ÿç»“æœï¼Œæ–¹ä¾¿æˆ‘ä»¬åšæ›´å¤šåº”ç”¨åŠŸèƒ½å¼€å‘ã€‚



**iOS â‰¥ 18 New API: [DetectHumanBodyPoseRequest](https://developer.apple.com/documentation/vision/detecthumanbodyposerequest){:target="_blank"}**



```swift
var request = DetectHumanBodyPoseRequest()
// ä¸€å¹¶ä¾¦æµ‹æ‰‹éƒ¨ Pose
request.detectsHands = true

guard let bodyPose = try await request.perform(on: image). first else { return }

// èº«ä½“ Pose Joints
let bodyJoints = bodyPose.allJoints()
// å·¦æ‰‹ Pose Joints
let leftHandJoints = bodyPose.leftHand.allJoints()
// å³æ‰‹ Pose Joints
let rightHandJoints = bodyPose.rightHand.allJoints()
```



### New Vision API



Apple åœ¨è¿™æ¬¡çš„æ›´æ–°å½“ä¸­æä¾›äº†æ–°çš„ Swift Vision API å°è£…ç»™å¼€å‘è€…ä½¿ç”¨ï¼Œé™¤äº†åŸºæœ¬çš„åŒ…å«åŸæœ¬çš„åŠŸèƒ½æ”¯æ´ä¹‹å¤–ï¼Œä¸»è¦é’ˆå¯¹åŠ å¼º Swift 6 / Swift Concurrency çš„ç‰¹æ€§ï¼Œæä¾›æ•ˆèƒ½æ›´ä¼˜ã€å†™èµ·æ¥æ›´ Swift çš„ API æ“ä½œæ–¹å¼ã€‚



### Get started with Vision



![](/assets/755509180ca8/1*mv9g5jmqrS6YScxoGYJemQ.png)



![](/assets/755509180ca8/1*iidNN7nKHoskh_tcjfuHKQ.png)



è¿™è¾¹è®²è€…åˆé‡æ–°ä»‹ç»äº†ä¸€æ¬¡ Vision framework çš„åŸºç¡€ä½¿ç”¨æ–¹å¼ï¼ŒApple å·²ç»å°è£…å¥½äº† [31 ç§](https://developer.apple.com/documentation/vision/visionrequest){:target="_blank"} (æˆªè‡³ iOS 18)å¸¸è§çš„å›¾åƒè¾¨è¯†è¯·æ±‚ã€ŒRequestã€ä¸å¯¹åº”å›ä¼ çš„ã€ŒObservationã€ç‰©ä»¶ã€‚



1. **Request:** DetectFaceRectanglesRequest äººè„¸åŒºåŸŸè¯†åˆ«è¯·æ±‚
   **Result:** FaceObservation
   ä¹‹å‰çš„æ–‡ç« ã€Œ [Vision åˆæ¢ â€” APP å¤´åƒä¸Šä¼  è‡ªåŠ¨è¯†åˆ«äººè„¸è£å›¾ (Swift)](../9a9aa892f9a9/) ã€å°±æ˜¯ç”¨è¿™å¯¹è¯·æ±‚ã€‚


2. **Request:** RecognizeTextRequest æ–‡å­—è¾¨è¯†è¯·æ±‚
   **Result:** RecognizedTextObservation


3. **Request:** GenerateObjectnessBasedSaliencyImageRequest ä¸»ä½“ç‰©ä»¶è¾¨è¯†è¯·æ±‚
   **Result:** SaliencyImageObservation



### å…¨éƒ¨ 31 ç§è¯·æ±‚ Requestï¼š



[VisionRequest](https://developer.apple.com/documentation/vision/visionrequest){:target="_blank"} ã€‚



\\| Request ç”¨é€”                                 \\| Observation è¯´æ˜                                                  \\|
\\|-----------------------------------------------\\|------------------------------------------------------------------\\|
\\| CalculateImageAestheticsScoresRequest<br/>è®¡ç®—å›¾åƒçš„ç¾å­¦åˆ†æ•°ã€‚                                 \\| AestheticsObservation<br/>è¿”å›å›¾åƒçš„ç¾å­¦è¯„åˆ†ï¼Œå¦‚æ„å›¾ã€è‰²å½©ç­‰å› ç´ ã€‚                           \\|
\\| ClassifyImageRequest<br/>åˆ†ç±»å›¾åƒå†…å®¹ã€‚                                      \\| ClassificationObservation<br/>è¿”å›å›¾åƒä¸­ç‰©ä½“æˆ–åœºæ™¯çš„åˆ†ç±»æ ‡ç­¾åŠç½®ä¿¡åº¦ã€‚                           \\|
\\| CoreMLRequest<br/>ä½¿ç”¨ Core ML æ¨¡å‹åˆ†æå›¾åƒã€‚                          \\| CoreMLFeatureValueObservation<br/>æ ¹æ® Core ML æ¨¡å‹çš„è¾“å‡ºç»“æœç”Ÿæˆè§‚å¯Ÿå€¼ã€‚                            \\|
\\| DetectAnimalBodyPoseRequest<br/>æ£€æµ‹å›¾åƒä¸­çš„åŠ¨ç‰©å§¿åŠ¿ã€‚                               \\| RecognizedPointsObservation<br/>è¿”å›åŠ¨ç‰©çš„éª¨æ¶ç‚¹åŠå…¶ä½ç½®ã€‚                                         \\|
\\| DetectBarcodesRequest<br/>æ£€æµ‹å›¾åƒä¸­çš„æ¡ç ã€‚                                   \\| BarcodeObservation<br/>è¿”å›æ¡ç æ•°æ®åŠç±»å‹ï¼ˆå¦‚ QR codeï¼‰ã€‚                                 \\|
\\| DetectContoursRequest<br/>æ£€æµ‹å›¾åƒä¸­çš„è½®å»“ã€‚                                   \\| ContoursObservation<br/>è¿”å›å›¾åƒä¸­æ£€æµ‹åˆ°çš„è½®å»“çº¿ã€‚                                         \\|
\\| DetectDocumentSegmentationRequest<br/>æ£€æµ‹å¹¶åˆ†å‰²å›¾åƒä¸­çš„æ–‡ä»¶ã€‚                             \\| RectangleObservation<br/>è¿”å›æ–‡ä»¶è¾¹ç•Œçš„çŸ©å½¢æ¡†ä½ç½®ã€‚                                         \\|
\\| DetectFaceCaptureQualityRequest<br/>è¯„ä¼°é¢éƒ¨æ•æ‰è´¨é‡ã€‚                                   \\| FaceObservation<br/>è¿”å›é¢éƒ¨å›¾åƒçš„è´¨é‡è¯„ä¼°åˆ†æ•°ã€‚                                       \\|
\\| DetectFaceLandmarksRequest<br/>æ£€æµ‹é¢éƒ¨ç‰¹å¾ç‚¹ã€‚                                     \\| FaceObservation<br/>è¿”å›é¢éƒ¨ç‰¹å¾ç‚¹ï¼ˆå¦‚çœ¼ç›ã€é¼»å­ç­‰ï¼‰çš„è¯¦ç»†ä½ç½®ã€‚                       \\|
\\| DetectFaceRectanglesRequest<br/>æ£€æµ‹å›¾åƒä¸­çš„é¢éƒ¨ã€‚                                   \\| FaceObservation<br/>è¿”å›äººè„¸çš„è¾¹ç•Œæ¡†ä½ç½®ã€‚                                             \\|
\\| DetectHorizonRequest<br/>æ£€æµ‹å›¾åƒä¸­çš„åœ°å¹³çº¿ã€‚                                 \\| HorizonObservation<br/>è¿”å›åœ°å¹³çº¿çš„è§’åº¦å’Œä½ç½®ã€‚                                           \\|
\\| DetectHumanBodyPose3DRequest<br/>æ£€æµ‹å›¾åƒä¸­çš„ 3D äººä½“å§¿åŠ¿ã€‚                           \\| RecognizedPointsObservation<br/>è¿”å› 3D äººä½“éª¨æ¶ç‚¹åŠå…¶ç©ºé—´åæ ‡ã€‚                                    \\|
\\| DetectHumanBodyPoseRequest<br/>æ£€æµ‹å›¾åƒä¸­çš„äººä½“å§¿åŠ¿ã€‚                               \\| RecognizedPointsObservation<br/>è¿”å›äººä½“éª¨æ¶ç‚¹åŠå…¶åæ ‡ã€‚                                           \\|
\\| DetectHumanHandPoseRequest<br/>æ£€æµ‹å›¾åƒä¸­çš„æ‰‹éƒ¨å§¿åŠ¿ã€‚                               \\| RecognizedPointsObservation<br/>è¿”å›æ‰‹éƒ¨éª¨æ¶ç‚¹åŠå…¶ä½ç½®ã€‚                                           \\|
\\| DetectHumanRectanglesRequest<br/>æ£€æµ‹å›¾åƒä¸­çš„äººä½“ã€‚                                   \\| HumanObservation<br/>è¿”å›äººä½“çš„è¾¹ç•Œæ¡†ä½ç½®ã€‚                                             \\|
\\| DetectRectanglesRequest<br/>æ£€æµ‹å›¾åƒä¸­çš„çŸ©å½¢ã€‚                                   \\| RectangleObservation<br/>è¿”å›çŸ©å½¢çš„å››ä¸ªé¡¶ç‚¹åæ ‡ã€‚                                           \\|
\\| DetectTextRectanglesRequest<br/>æ£€æµ‹å›¾åƒä¸­çš„æ–‡æœ¬åŒºåŸŸã€‚                               \\| TextObservation<br/>è¿”å›æ–‡æœ¬åŒºåŸŸçš„ä½ç½®å’Œè¾¹ç•Œæ¡†ã€‚                                       \\|
\\| DetectTrajectoriesRequest<br/>æ£€æµ‹å¹¶åˆ†æç‰©ä½“è¿åŠ¨è½¨è¿¹ã€‚                             \\| TrajectoryObservation<br/>è¿”å›è¿åŠ¨è½¨è¿¹ç‚¹åŠå…¶æ—¶é—´åºåˆ—ã€‚                                       \\|
\\| GenerateAttentionBasedSaliencyImageRequest<br/>ç”ŸæˆåŸºäºæ³¨æ„åŠ›çš„æ˜¾è‘—æ€§å›¾åƒã€‚                         \\| SaliencyImageObservation<br/>è¿”å›å›¾åƒä¸­æœ€å…·å¸å¼•åŠ›åŒºåŸŸçš„æ˜¾è‘—æ€§åœ°å›¾ã€‚                             \\|
\\| GenerateForegroundInstanceMaskRequest<br/>ç”Ÿæˆå‰æ™¯å®ä¾‹æ©è†œå›¾åƒã€‚                               \\| InstanceMaskObservation<br/>è¿”å›å‰æ™¯ç‰©ä½“çš„æ©è†œã€‚                                               \\|
\\| GenerateImageFeaturePrintRequest<br/>ç”Ÿæˆå›¾åƒç‰¹å¾æŒ‡çº¹ä»¥è¿›è¡Œæ¯”è¾ƒã€‚                         \\| FeaturePrintObservation<br/>è¿”å›å›¾åƒçš„ç‰¹å¾æŒ‡çº¹æ•°æ®ï¼Œç”¨äºç›¸ä¼¼åº¦æ¯”è¾ƒã€‚                           \\|
\\| GenerateObjectnessBasedSaliencyImageRequest<br/>ç”ŸæˆåŸºäºç‰©ä½“æ˜¾è‘—æ€§çš„å›¾åƒã€‚                           \\| SaliencyImageObservation<br/>è¿”å›ç‰©ä½“æ˜¾è‘—æ€§åŒºåŸŸçš„æ˜¾è‘—æ€§åœ°å›¾ã€‚                                   \\|
\\| GeneratePersonInstanceMaskRequest<br/>ç”Ÿæˆäººç‰©å®ä¾‹æ©è†œå›¾åƒã€‚                               \\| InstanceMaskObservation<br/>è¿”å›äººç‰©å®ä¾‹çš„æ©è†œã€‚                                               \\|
\\| GeneratePersonSegmentationRequest<br/>ç”Ÿæˆäººç‰©åˆ†å‰²å›¾åƒã€‚                                   \\| SegmentationObservation<br/>è¿”å›äººç‰©åˆ†å‰²çš„äºŒå€¼å›¾ã€‚                                             \\|
\\| RecognizeAnimalsRequest<br/>æ£€æµ‹å¹¶è¯†åˆ«å›¾åƒä¸­çš„åŠ¨ç‰©ã€‚                             \\| RecognizedObjectObservation<br/>è¿”å›åŠ¨ç‰©ç±»å‹åŠå…¶ç½®ä¿¡åº¦ã€‚                                           \\|
\\| RecognizeTextRequest<br/>æ£€æµ‹å¹¶è¯†åˆ«å›¾åƒä¸­çš„æ–‡æœ¬ã€‚                             \\| RecognizedTextObservation<br/>è¿”å›æ£€æµ‹åˆ°çš„æ–‡æœ¬å†…å®¹åŠå…¶åŒºåŸŸä½ç½®ã€‚                                 \\|
\\| TrackHomographicImageRegistrationRequest<br/>è·Ÿè¸ªå›¾åƒçš„åŒä½å½±åƒé…å‡†ã€‚                             \\| ImageAlignmentObservation<br/>è¿”å›å›¾åƒé—´çš„åŒä½å˜æ¢çŸ©é˜µï¼Œç”¨äºå½±åƒé…å‡†ã€‚                           \\|
\\| TrackObjectRequest<br/>è·Ÿè¸ªå›¾åƒä¸­çš„ç‰©ä½“ã€‚                                   \\| DetectedObjectObservation<br/>è¿”å›ç‰©ä½“åœ¨å½±åƒä¸­çš„ä½ç½®å’Œé€Ÿåº¦ä¿¡æ¯ã€‚                                 \\|
\\| TrackOpticalFlowRequest<br/>è·Ÿè¸ªå›¾åƒä¸­çš„å…‰æµã€‚                                   \\| OpticalFlowObservation<br/>è¿”å›å…‰æµçŸ¢é‡åœºï¼Œç”¨äºæè¿°åƒç´ ç§»åŠ¨æƒ…å†µã€‚                             \\|
\\| TrackRectangleRequest<br/>è·Ÿè¸ªå›¾åƒä¸­çš„çŸ©å½¢ã€‚                                   \\| RectangleObservation<br/>è¿”å›çŸ©å½¢åœ¨å½±åƒä¸­çš„ä½ç½®ã€å¤§å°å’Œæ—‹è½¬è§’åº¦ã€‚                           \\|
\\| TrackTranslationalImageRegistrationRequest<br/>è·Ÿè¸ªå›¾åƒçš„å¹³ç§»å½±åƒé…å‡†ã€‚                             \\| ImageAlignmentObservation<br/>è¿”å›å›¾åƒé—´çš„å¹³ç§»å˜æ¢çŸ©é˜µï¼Œç”¨äºå½±åƒé…å‡†ã€‚                           \\|



- å‰é¢è¡¥ä¸Š VN å°±æ˜¯æ—§çš„ API å†™æ³• (iOS 18 ä»¥å‰çš„ç‰ˆæœ¬)



è®²è€…æåˆ°äº†å‡ ä¸ªå¸¸ç”¨çš„ Requestï¼Œå¦‚ä¸‹ã€‚



#### ClassifyImageRequest



è¾¨è¯†è¾“å…¥çš„å›¾ç‰‡ï¼Œå¾—åˆ°æ ‡ç­¾åˆ†ç±»ä¸ç½®ä¿¡åº¦ã€‚



![](/assets/755509180ca8/1*8NSQEjxGejujKLbXcILmxQ.jpeg)



![[æ¸¸è®°] 2024 äºŒè®¿ä¹å· 9 æ—¥è‡ªç”±è¡Œï¼Œç»é‡œå±±â†’åšå¤šé‚®è½®å…¥å¢ƒ](/assets/755509180ca8/1*f1rNoOIQbE33M9F9NmoTXg.png)



[æ¸¸è®°] 2024 äºŒè®¿ä¹å· 9 æ—¥è‡ªç”±è¡Œï¼Œç»é‡œå±±â†’åšå¤šé‚®è½®å…¥å¢ƒ



```swift
if #available(iOS 18.0, *) {
    // æ–°çš„ä½¿ç”¨ Swift ç‰¹æ€§çš„ API
    let request = ClassifyImageRequest()
    Task {
        do {
            let observations = try await request.perform(on: URL(string: "https://zhgchg.li/assets/cb65fd5ab770/1*yL3vI1ADzwlovctW5WQgJw.jpeg")!)
            observations.forEach {
                observation in
                print("\(observation.identifier): \(observation.confidence)")
            }
        }
        catch {
            print("Request failed: \(error)")
        }
    }
} else {
    // æ—§çš„å†™æ³•
    let completionHandler: VNRequestCompletionHandler = {
        request, error in
        guard error == nil else {
            print("Request failed: \(String(describing: error))")
            return
        }
        guard let observations = request.results as? [VNClassificationObservation] else {
            return
        }
        observations.forEach {
            observation in
            print("\(observation.identifier): \(observation.confidence)")
        }
    }

    let request = VNClassifyImageRequest(completionHandler: completionHandler)
    DispatchQueue.global().async {
        let handler = VNImageRequestHandler(url: URL(string: "https://zhgchg.li/assets/cb65fd5ab770/1*3_jdrLurFuUfNdW4BJaRww.jpeg")!, options: [:])
        do {
            try handler.perform([request])
        }
        catch {
            print("Request failed: \(error)")
        }
    }
}
```



**åˆ†æç»“æœï¼š**



```r
 â€¢ outdoorï¼ˆæˆ·å¤–ï¼‰: 0.75392926
 â€¢ skyï¼ˆå¤©ç©ºï¼‰: 0.75392926
 â€¢ blue_skyï¼ˆè“å¤©ï¼‰: 0.7519531
 â€¢ machineï¼ˆæœºå™¨ï¼‰: 0.6958008
 â€¢ cloudyï¼ˆå¤šäº‘ï¼‰: 0.26538086
 â€¢ structureï¼ˆç»“æ„ï¼‰: 0.15728651
 â€¢ signï¼ˆæ ‡å¿—ï¼‰: 0.14224191
 â€¢ fenceï¼ˆæ …æ ï¼‰: 0.118652344
 â€¢ bannerï¼ˆæ¨ªå¹…ï¼‰: 0.0793457
 â€¢ materialï¼ˆææ–™ï¼‰: 0.075975396
 â€¢ plantï¼ˆæ¤ç‰©ï¼‰: 0.054406323
 â€¢ foliageï¼ˆæ ‘å¶ï¼‰: 0.05029297
 â€¢ lightï¼ˆå…‰ï¼‰: 0.048126098
 â€¢ lamppostï¼ˆç¯æŸ±ï¼‰: 0.048095703
 â€¢ billboardsï¼ˆå¹¿å‘Šç‰Œï¼‰: 0.040039062
 â€¢ artï¼ˆè‰ºæœ¯ï¼‰: 0.03977703
 â€¢ branchï¼ˆæ ‘æï¼‰: 0.03930664
 â€¢ decorationï¼ˆè£…é¥°ï¼‰: 0.036868922
 â€¢ flagï¼ˆæ——å¸œï¼‰: 0.036865234
....ç•¥
```



#### RecognizeTextRequest



è¾¨è¯†å›¾ç‰‡ä¸­çš„æ–‡å­—å†…å®¹ã€‚(a.k.a å›¾ç‰‡è½¬æ–‡å­—)



![[[æ¸¸è®°] 2023 ä¸œäº¬ 5 æ—¥è‡ªç”±è¡Œ](../9da2c51fa4f2/)](/assets/755509180ca8/1*XL40lLT774PfO60rCIfnxA.jpeg)



[[æ¸¸è®°] 2023 ä¸œäº¬ 5 æ—¥è‡ªç”±è¡Œ](../9da2c51fa4f2/)



```swift
if #available(iOS 18.0, *) {
    // æ–°çš„ä½¿ç”¨ Swift ç‰¹æ€§çš„ API
    var request = RecognizeTextRequest()
    request.recognitionLevel = .accurate
    request.recognitionLanguages = [.init(identifier: "ja-JP"), .init(identifier: "en-US")] // Specify language code, e.g., Traditional Chinese
    Task {
        do {
            let observations = try await request.perform(on: URL(string: "https://zhgchg.li/assets/9da2c51fa4f2/1*fBbNbDepYioQ-3-0XUkF6Q.jpeg")!)
            observations.forEach {
                observation in
                let topCandidate = observation.topCandidates(1).first
                print(topCandidate?.string ?? "No text recognized")
            }
        }
        catch {
            print("Request failed: \(error)")
        }
    }
} else {
    // æ—§çš„å†™æ³•
    let completionHandler: VNRequestCompletionHandler = {
        request, error in
        guard error == nil else {
            print("Request failed: \(String(describing: error))")
            return
        }
        guard let observations = request.results as? [VNRecognizedTextObservation] else {
            return
        }
        observations.forEach {
            observation in
            let topCandidate = observation.topCandidates(1).first
            print(topCandidate?.string ?? "No text recognized")
        }
    }

    let request = VNRecognizeTextRequest(completionHandler: completionHandler)
    request.recognitionLevel = .accurate
    request.recognitionLanguages = ["ja-JP", "en-US"] // Specify language code, e.g., Traditional Chinese
    DispatchQueue.global().async {
        let handler = VNImageRequestHandler(url: URL(string: "https://zhgchg.li/assets/9da2c51fa4f2/1*fBbNbDepYioQ-3-0XUkF6Q.jpeg")!, options: [:])
        do {
            try handler.perform([request])
        }
        catch {
            print("Request failed: \(error)")
        }
    }
}
```



**åˆ†æç»“æœï¼š**



```makefile
LE LABO é’å±±åº—
TEL:03-6419-7167
ï¼ŠãŠä¹°ã„ä¸Šã’ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™*
No: 21347
æ—¥ä»˜ï¼š2023/06/10 14.14.57
æ‹…å½“ï¼š
1690370
ãƒ¬ã‚¸ï¼š008A 1
å•†å“å
ç¨è¾¼ä¸Šä»£æ•°é‡ç¨è¾¼åˆè®¡
ã‚«ã‚¤ã‚¢ãƒƒã‚¯ 10 EDP FB 15ML
J1P7010000S
16,800
16,800
ã‚¢ãƒŠã‚¶ãƒ¼ 13 EDP FB 15ML
J1PJ010000S
10,700
10,700
ãƒªãƒƒãƒ—ãƒ‘ãƒ¼ãƒ  15ML
JOWC010000S
2,000
1
åˆè®¡é‡‘é¢
ï¼ˆå†…ç¨é¢ï¼‰
CARD
2,000
3ç‚¹å¾¡ä¹°ä¸Šã’
29,500
0
29,500
29,500
```



#### DetectBarcodesRequest



ä¾¦æµ‹å›¾ç‰‡ä¸­çš„æ¡ç ã€QRCode æ•°æ®ã€‚



![](/assets/755509180ca8/1*Z72y9rIwIKQCmnnuwsq0uQ.png)



![æ³°å›½å½“åœ°äººæ¨èé¹…ç‰Œæ¸…å‡‰è†](/assets/755509180ca8/1*s3V1UQRIqto-iG1e30PK7Q.jpeg)



æ³°å›½å½“åœ°äººæ¨èé¹…ç‰Œæ¸…å‡‰è†



```swift
let filePath = Bundle.main.path(forResource: "IMG_6777", ofType: "png")! // æœ¬åœ°æµ‹è¯•å›¾ç‰‡
let fileURL = URL(filePath: filePath)
if #available(iOS 18.0, *) {
    // æ–°çš„ä½¿ç”¨ Swift ç‰¹æ€§çš„ API
    let request = DetectBarcodesRequest()
    Task {
        do {
            let observations = try await request.perform(on: fileURL)
            observations.forEach {
                observation in
                print("Payload: \(observation.payloadString ?? "No payload")")
                print("Symbology: \(observation.symbology)")
            }
        }
        catch {
            print("Request failed: \(error)")
        }
    }
} else {
    // æ—§çš„å†™æ³•
    let completionHandler: VNRequestCompletionHandler = {
        request, error in
        guard error == nil else {
            print("Request failed: \(String(describing: error))")
            return
        }
        guard let observations = request.results as? [VNBarcodeObservation] else {
            return
        }
        observations.forEach {
            observation in
            print("Payload: \(observation.payloadStringValue ?? "No payload")")
            print("Symbology: \(observation.symbology.rawValue)")
        }
    }

    let request = VNDetectBarcodesRequest(completionHandler: completionHandler)
    DispatchQueue.global().async {
        let handler = VNImageRequestHandler(url: fileURL, options: [:])
        do {
            try handler.perform([request])
        }
        catch {
            print("Request failed: \(error)")
        }
    }
}
```



**åˆ†æç»“æœï¼š**



```makefile
Payload: 8859126000911
Symbology: VNBarcodeSymbologyEAN13
Payload: https://lin.ee/hGynbVM
Symbology: VNBarcodeSymbologyQR
Payload: http://www.hongthaipanich.com/
Symbology: VNBarcodeSymbologyQR
Payload: https://www.facebook.com/qr?id=100063856061714
Symbology: VNBarcodeSymbologyQR
```



#### RecognizeAnimalsRequest



è¾¨è¯†å›¾ç‰‡ä¸­çš„åŠ¨ç‰©ä¸ç½®ä¿¡åº¦ã€‚



![](/assets/755509180ca8/1*5zF3gA3WB1Q0-_cgt6mTCw.png)



![[meme Source](https://www.redbubble.com/i/canvas-print/Funny-AI-Woman-yelling-at-a-cat-meme-design-Machine-learning-by-omolog/43039298.5Y5V7){:target="_blank"}](/assets/755509180ca8/1*KZ7mdE8fobP-_oj7tJf_Ww.jpeg)



[meme Source](https://www.redbubble.com/i/canvas-print/Funny-AI-Woman-yelling-at-a-cat-meme-design-Machine-learning-by-omolog/43039298.5Y5V7){:target="_blank"}



```swift
let filePath = Bundle.main.path(forResource: "IMG_5026", ofType: "png")! // æœ¬åœ°æµ‹è¯•å›¾ç‰‡
let fileURL = URL(filePath: filePath)
if #available(iOS 18.0, *) {
    // æ–°çš„ä½¿ç”¨ Swift ç‰¹æ€§çš„ API
    let request = RecognizeAnimalsRequest()
    Task {
        do {
            let observations = try await request.perform(on: fileURL)
            observations.forEach {
                observation in
                let labels = observation.labels
                labels.forEach {
                    label in
                    print("Detected animal: \(label.identifier) with confidence: \(label.confidence)")
                }
            }
        }
        catch {
            print("Request failed: \(error)")
        }
    }
} else {
    // æ—§çš„å†™æ³•
    let completionHandler: VNRequestCompletionHandler = {
        request, error in
        guard error == nil else {
            print("Request failed: \(String(describing: error))")
            return
        }
        guard let observations = request.results as? [VNRecognizedObjectObservation] else {
            return
        }
        observations.forEach {
            observation in
            let labels = observation.labels
            labels.forEach {
                label in
                print("Detected animal: \(label.identifier) with confidence: \(label.confidence)")
            }
        }
    }

    let request = VNRecognizeAnimalsRequest(completionHandler: completionHandler)
    DispatchQueue.global().async {
        let handler = VNImageRequestHandler(url: fileURL, options: [:])
        do {
            try handler.perform([request])
        }
        catch {
            print("Request failed: \(error)")
        }
    }
}
```



åˆ†æç»“æœï¼š



```csharp
Detected animal: Cat with confidence: 0.77245045
```



#### å…¶ä»–ï¼š



- ä¾¦æµ‹å›¾åƒä¸­çš„äººä½“ï¼šDetectHumanRectanglesRequest


- ä¾¦æµ‹äººã€åŠ¨ç‰©çš„ Pose åŠ¨ä½œ (3D or 2D éƒ½å¯ä»¥)ï¼šDetectAnimalBodyPoseRequestã€DetectHumanBodyPose3DRequestã€DetectHumanBodyPoseRequestã€DetectHumanHandPoseRequest


- æ£€æµ‹å¹¶è¿½è¸ªç‰©ä»¶çš„è¿åŠ¨è½¨è¿¹(åœ¨å½±ç‰‡ã€åŠ¨ç”»ä¸åŒçš„ä¾¦ä¸­)ï¼šDetectTrajectoriesRequestã€TrackObjectRequestã€TrackRectangleRequest



#### **iOS â‰¥ 18 Update Highlight:**



```rust
VN*Request -> *Request (e.g. VNDetectBarcodesRequest -> DetectBarcodesRequest)
VN*Observation -> *Observation (e.g. VNRecognizedObjectObservation -> RecognizedObjectObservation)
VNRequestCompletionHandler -> async/await
VNImageRequestHandler.perform([VN*Request]) -> *Request.perform()
```



### WWDC Example



WWDC å®˜æ–¹å½±ç‰‡ä»¥è¶…å¸‚å•†å“æ‰«æå™¨ä¸ºä¾‹ã€‚



#### é¦–å…ˆå¤§å¤šæ•°çš„å•†å“éƒ½æœ‰ Barcode å¯ä¾›æ‰«æ



![](/assets/755509180ca8/1*YT_Uf8eEi36Iv7zcOrmP4A.png)



![](/assets/755509180ca8/1*J9uIwRKubLoJoC7i096AdQ.png)



![](/assets/755509180ca8/1*gKg-NfHYqy7uBqe5hxzBSw.png)



æˆ‘ä»¬å¯ä»¥ä» `observation.boundingBox` å–å¾— Barcode æ‰€åœ¨ä½ç½®ï¼Œä½†ä¸åŒäºå¸¸è§ UIView åº§æ ‡ç³»ï¼Œ `BoundingBox` çš„ç›¸å¯¹ä½ç½®èµ·ç‚¹æ˜¯ä»å·¦ä¸‹è§’ï¼Œå€¼çš„èŒƒå›´è½åœ¨ 0~1 ä¹‹é—´ã€‚



```swift
let filePath = Bundle.main.path(forResource: "IMG_6785", ofType: "png")! // æœ¬åœ°æµ‹è¯•å›¾ç‰‡
let fileURL = URL(filePath: filePath)
if #available(iOS 18.0, *) {
    // æ–°çš„ä½¿ç”¨ Swift ç‰¹æ€§çš„ API
    var request = DetectBarcodesRequest()
    request.symbologies = [.ean13] // å¦‚æœåªè¦æ‰«æ EAN13 Barcodeï¼Œå¯ç›´æ¥æŒ‡å®šï¼Œæå‡æ•ˆèƒ½
    Task {
        do {
            let observations = try await request.perform(on: fileURL)
            if let observation = observations.first {
                DispatchQueue.main.async {
                    self.infoLabel.text = observation.payloadString
                    // æ ‡è®°é¢œè‰² Layer
                    let colorLayer = CALayer()
                    // iOS >=18 æ–°çš„åº§æ ‡è½¬æ¢ API toImageCoordinates
                    // æœªç»æµ‹è¯•ï¼Œå®é™…å¯èƒ½è¿˜éœ€è¦è®¡ç®— ContentMode = AspectFit çš„ä½ç§»:
                    colorLayer.frame = observation.boundingBox.toImageCoordinates(self.baseImageView.frame.size, origin: .upperLeft)
                    colorLayer.backgroundColor = UIColor.red.withAlphaComponent(0.5).cgColor
                    self.baseImageView.layer.addSublayer(colorLayer)
                }
                print("BoundingBox: \(observation.boundingBox.cgRect)")
                print("Payload: \(observation.payloadString ?? "No payload")")
                print("Symbology: \(observation.symbology)")
            }
        }
        catch {
            print("Request failed: \(error)")
        }
    }
} else {
    // æ—§çš„å†™æ³•
    let completionHandler: VNRequestCompletionHandler = {
        request, error in
        guard error == nil else {
            print("Request failed: \(String(describing: error))")
            return
        }
        guard let observations = request.results as? [VNBarcodeObservation] else {
            return
        }
        if let observation = observations.first {
            DispatchQueue.main.async {
                self.infoLabel.text = observation.payloadStringValue
                // æ ‡è®°é¢œè‰² Layer
                let colorLayer = CALayer()
                colorLayer.frame = self.convertBoundingBox(observation.boundingBox, to: self.baseImageView)
                colorLayer.backgroundColor = UIColor.red.withAlphaComponent(0.5).cgColor
                self.baseImageView.layer.addSublayer(colorLayer)
            }
            print("BoundingBox: \(observation.boundingBox)")
            print("Payload: \(observation.payloadStringValue ?? "No payload")")
            print("Symbology: \(observation.symbology.rawValue)")
        }
    }

    let request = VNDetectBarcodesRequest(completionHandler: completionHandler)
    request.symbologies = [.ean13] // å¦‚æœåªè¦æ‰«æ EAN13 Barcodeï¼Œå¯ç›´æ¥æŒ‡å®šï¼Œæå‡æ•ˆèƒ½
    DispatchQueue.global().async {
        let handler = VNImageRequestHandler(url: fileURL, options: [:])
        do {
            try handler.perform([request])
        }
        catch {
            print("Request failed: \(error)")
        }
    }
}
```



**iOS â‰¥ 18 Update Highlight:**



```less
// iOS >=18 æ–°çš„åº§æ ‡è½¬æ¢ API toImageCoordinates
observation.boundingBox.toImageCoordinates(CGSize, origin: .upperLeft)
// https://developer.apple.com/documentation/vision/normalizedpoint/toimagecoordinates(from:imagesize:origin:)
```



**Helper:**



```swift
// Gen by ChatGPT 4o
// å› ä¸ºç…§ç‰‡åœ¨ ImageView æ˜¯è®¾å®š ContentMode = AspectFit
// æ‰€ä»¥è¦å¤šè®¡ç®—ä¸Šä¸‹å›  Fit é€ æˆçš„ç©ºç™½ä½ç§»
func convertBoundingBox(_ boundingBox: CGRect, to view: UIImageView) -> CGRect {
    guard let image = view.image else {
        return .zero
    }

    let imageSize = image.size
    let viewSize = view.bounds.size
    let imageRatio = imageSize.width / imageSize.height
    let viewRatio = viewSize.width / viewSize.height
    var scaleFactor: CGFloat
    var offsetX: CGFloat = 0
    var offsetY: CGFloat = 0
    if imageRatio > viewRatio {
        // å›¾åƒåœ¨å®½åº¦æ–¹å‘ä¸Šé€‚é…
        scaleFactor = viewSize.width / imageSize.width
        offsetY = (viewSize.height - imageSize.height * scaleFactor) / 2
    }

    else {
        // å›¾åƒåœ¨é«˜åº¦æ–¹å‘ä¸Šé€‚é…
        scaleFactor = viewSize.height / imageSize.height
        offsetX = (viewSize.width - imageSize.width * scaleFactor) / 2
    }

    let x = boundingBox.minX * imageSize.width * scaleFactor + offsetX
    let y = (1 - boundingBox.maxY) * imageSize.height * scaleFactor + offsetY
    let width = boundingBox.width * imageSize.width * scaleFactor
    let height = boundingBox.height * imageSize.height * scaleFactor
    return CGRect(x: x, y: y, width: width, height: height)
}
```



**è¾“å‡ºç»“æœ**



```makefile
BoundingBox: (0.5295758928571429, 0.21408638121589782, 0.0943080357142857, 0.21254415360708087)
Payload: 4710018183805
Symbology: VNBarcodeSymbologyEAN13
```



#### éƒ¨åˆ†å•†å“æ—  Barcodeï¼Œå¦‚æ•£è£…æ°´æœåªæœ‰å•†å“æ ‡ç­¾



![](/assets/755509180ca8/1*jeZhLtg9j11kgOAvKZmevg.jpeg)



![](/assets/755509180ca8/1*YNokMMUewMA2kzjoGmMJPw.png)



å› æ­¤æˆ‘ä»¬çš„æ‰«ç„å™¨ä¹Ÿéœ€è¦åŒæ—¶æ”¯æ´æ‰«æçº¯æ–‡å­—æ ‡ç­¾ã€‚



```swift
let filePath = Bundle.main.path(forResource: "apple", ofType: "jpg")! // æœ¬åœ°æµ‹è¯•å›¾ç‰‡
let fileURL = URL(filePath: filePath)
if #available(iOS 18.0, *) {
    // æ–°çš„ä½¿ç”¨ Swift ç‰¹æ€§çš„ API
    var barcodesRequest = DetectBarcodesRequest()
    barcodesRequest.symbologies = [.ean13] // å¦‚æœåªè¦æ‰«æ EAN13 Barcodeï¼Œå¯ç›´æ¥æŒ‡å®šï¼Œæå‡æ•ˆèƒ½
    var textRequest = RecognizeTextRequest()
    textRequest.recognitionLanguages = [.init(identifier: "zh-Hnat"), .init(identifier: "en-US")]
    Task {
        do {
            let handler = ImageRequestHandler(fileURL)
            // parameter pack syntax and we must wait for all requests to finish before we can use their results.
            // let (barcodesObservation, textObservation, ...) = try await handler.perform(barcodesRequest, textRequest, ...)
            let (barcodesObservation, textObservation) = try await handler.perform(barcodesRequest, textRequest)
            if let observation = barcodesObservation.first {
                DispatchQueue.main.async {
                    self.infoLabel.text = observation.payloadString
                    // æ ‡è®°é¢œè‰² Layer
                    let colorLayer = CALayer()
                    // iOS >=18 æ–°çš„åº§æ ‡è½¬æ¢ API toImageCoordinates
                    // æœªç»æµ‹è¯•ï¼Œå®é™…å¯èƒ½è¿˜éœ€è¦è®¡ç®— ContentMode = AspectFit çš„ä½ç§»:
                    colorLayer.frame = observation.boundingBox.toImageCoordinates(self.baseImageView.frame.size, origin: .upperLeft)
                    colorLayer.backgroundColor = UIColor.red.withAlphaComponent(0.5).cgColor
                    self.baseImageView.layer.addSublayer(colorLayer)
                }
                print("BoundingBox: \(observation.boundingBox.cgRect)")
                print("Payload: \(observation.payloadString ?? "No payload")")
                print("Symbology: \(observation.symbology)")
            }
            textObservation.forEach {
                observation in
                let topCandidate = observation.topCandidates(1).first
                print(topCandidate?.string ?? "No text recognized")
            }
        }
        catch {
            print("Request failed: \(error)")
        }
    }
} else {
    // æ—§çš„å†™æ³•
    let barcodesCompletionHandler: VNRequestCompletionHandler = {
        request, error in
        guard error == nil else {
            print("Request failed: \(String(describing: error))")
            return
        }
        guard let observations = request.results as? [VNBarcodeObservation] else {
            return
        }
        if let observation = observations.first {
            DispatchQueue.main.async {
                self.infoLabel.text = observation.payloadStringValue
                // æ ‡è®°é¢œè‰² Layer
                let colorLayer = CALayer()
                colorLayer.frame = self.convertBoundingBox(observation.boundingBox, to: self.baseImageView)
                colorLayer.backgroundColor = UIColor.red.withAlphaComponent(0.5).cgColor
                self.baseImageView.layer.addSublayer(colorLayer)
            }
            print("BoundingBox: \(observation.boundingBox)")
            print("Payload: \(observation.payloadStringValue ?? "No payload")")
            print("Symbology: \(observation.symbology.rawValue)")
        }
    }

    let textCompletionHandler: VNRequestCompletionHandler = {
        request, error in
        guard error == nil else {
            print("Request failed: \(String(describing: error))")
            return
        }
        guard let observations = request.results as? [VNRecognizedTextObservation] else {
            return
        }
        observations.forEach {
            observation in
            let topCandidate = observation.topCandidates(1).first
            print(topCandidate?.string ?? "No text recognized")
        }
    }

    let barcodesRequest = VNDetectBarcodesRequest(completionHandler: barcodesCompletionHandler)
    barcodesRequest.symbologies = [.ean13] // å¦‚æœåªè¦æ‰«æ EAN13 Barcodeï¼Œå¯ç›´æ¥æŒ‡å®šï¼Œæå‡æ•ˆèƒ½
    let textRequest = VNRecognizeTextRequest(completionHandler: textCompletionHandler)
    textRequest.recognitionLevel = .accurate
    textRequest.recognitionLanguages = ["en-US"]
    DispatchQueue.global().async {
        let handler = VNImageRequestHandler(url: fileURL, options: [:])
        do {
            try handler.perform([barcodesRequest, textRequest])
        }
        catch {
            print("Request failed: \(error)")
        }
    }
}
```



**è¾“å‡ºç»“æœï¼š**



```
94128s
ORGANIC
Pink LadyÂ®
Produce of USh
```



**iOS â‰¥ 18 Update Highlight:**



```swift
let handler = ImageRequestHandler(fileURL)
// parameter pack syntax and we must wait for all requests to finish before we can use their results.
// let (barcodesObservation, textObservation, ...) = try await handler.perform(barcodesRequest, textRequest, ...)
let (barcodesObservation, textObservation) = try await handler.perform(barcodesRequest, textRequest)
```



#### iOS â‰¥ 18 [performAll( )](<https://developer.apple.com/documentation/vision/imagerequesthandler/performall(_:>)?changes=latest_minor){:target="_blank"} æ–¹æ³•



![](/assets/755509180ca8/1*z0364eYD4F4On194EgQ1kQ.png)



å‰é¢çš„ `perform(barcodesRequest, textRequest)` å¤„ç† Barcode æ‰«æè·Ÿæ–‡å­—æ‰«æçš„æ–¹å¼éœ€è¦ç­‰åˆ°ä¸¤ä¸ª Request éƒ½å®Œæˆæ‰èƒ½ç»§ç»­æ‰§è¡Œï¼›iOS 18 å¼€å§‹æä¾›æ–°çš„ `performAll()` æ–¹æ³•ï¼Œå°†å›åº”æ–¹å¼æ”¹ä¸ºä¸²æµï¼Œåœ¨æ”¶åˆ°å…¶ä¸­ä¸€ä¸ª Reqeust ç»“æœæ˜¯å°±èƒ½åšå¯¹åº”å¤„ç†ï¼Œä¾‹å¦‚æ‰«æåˆ° Barcode å°±ç›´æ¥å“åº”ã€‚



```swift
if #available(iOS 18.0, *) {
    // æ–°çš„ä½¿ç”¨ Swift ç‰¹æ€§çš„ API
    var barcodesRequest = DetectBarcodesRequest()
    barcodesRequest.symbologies = [.ean13] // å¦‚æœåªè¦æ‰«æ EAN13 Barcodeï¼Œå¯ç›´æ¥æŒ‡å®šï¼Œæå‡æ•ˆèƒ½
    var textRequest = RecognizeTextRequest()
    textRequest.recognitionLanguages = [.init(identifier: "zh-Hnat"), .init(identifier: "en-US")]
    Task {
        let handler = ImageRequestHandler(fileURL)
        let observation = handler.performAll([barcodesRequest, textRequest] as [any VisionRequest])
        for try await result in observation {
            switch result {
                case .detectBarcodes(_, let barcodesObservation):
                if let observation = barcodesObservation.first {
                    DispatchQueue.main.async {
                        self.infoLabel.text = observation.payloadString
                        // æ ‡è®°é¢œè‰² Layer
                        let colorLayer = CALayer()
                        // iOS >=18 æ–°çš„åº§æ ‡è½¬æ¢ API toImageCoordinates
                        // æœªç»æµ‹è¯•ï¼Œå®é™…å¯èƒ½è¿˜éœ€è¦è®¡ç®— ContentMode = AspectFit çš„ä½ç§»:
                        colorLayer.frame = observation.boundingBox.toImageCoordinates(self.baseImageView.frame.size, origin: .upperLeft)
                        colorLayer.backgroundColor = UIColor.red.withAlphaComponent(0.5).cgColor
                        self.baseImageView.layer.addSublayer(colorLayer)
                    }
                    print("BoundingBox: \(observation.boundingBox.cgRect)")
                    print("Payload: \(observation.payloadString ?? "No payload")")
                    print("Symbology: \(observation.symbology)")
                }
                case .recognizeText(_, let textObservation):
                textObservation.forEach {
                    observation in
                    let topCandidate = observation.topCandidates(1).first
                    print(topCandidate?.string ?? "No text recognized")
                }
                default:
                print("Unrecongnized result: \(result)")
            }
        }
    }
}
```



### Optimize with Swift Concurrency



![](/assets/755509180ca8/1*LgxxMOVS6is3n6EqPWqA6Q.png)



![](/assets/755509180ca8/1*80CFJpkb-gjy3bJs4jAC2A.png)



å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªå›¾ç‰‡å¢™åˆ—è¡¨ï¼Œæ¯å¼ å›¾ç‰‡éƒ½éœ€è¦è‡ªåŠ¨è£åˆ‡å‡ºç‰©ä»¶ä¸»ä½“ï¼›è¿™æ—¶å€™å¯ä»¥å–„ç”¨ Swift Concurrency å¢åŠ è½½å…¥æ•ˆç‡ã€‚



#### **åŸå§‹å†™æ³•**



```swift
func generateThumbnail(url: URL) async throws -> UIImage {
  let request = GenerateAttentionBasedSaliencyImageRequest()
  let saliencyObservation = try await request.perform(on: url)
  return cropImage(url, to: saliencyObservation.salientObjects)
}
    
func generateAllThumbnails() async throws {
  for image in images {
    image.thumbnail = try await generateThumbnail(url: image.url)
  }
}
```



ä¸€æ¬¡åªæ‰§è¡Œä¸€ä¸ªï¼Œæ•ˆç‡ã€æ•ˆèƒ½ç¼“æ…¢ã€‚



#### **ä¼˜åŒ– (1) â€” TaskGroup** Concurrency



```swift

func generateAllThumbnails() async throws {
  try await withThrowingDiscardingTaskGroup { taskGroup in
    for image in images {
      image.thumbnail = try await generateThumbnail(url: image.url)
     }
  }
}
```



å°†æ¯ä¸ª Task éƒ½åŠ å…¥ TaskGroup Concurrency æ‰§è¡Œã€‚



> ***é—®é¢˜ï¼šå›¾ç‰‡è¾¨è¯†ã€æˆªå›¾æ“ä½œéå¸¸æ¶ˆè€—è®°å¿†ä½“æ€§èƒ½ï¼Œå¦‚æœæ— èŠ‚åˆ¶ç‹‚åŠ å¹¶è¡Œä»»åŠ¡ï¼Œå¯èƒ½é€ æˆä½¿ç”¨è€…å¡é¡¿ã€OOM é—ªé€€é—®é¢˜ã€‚***



#### ä¼˜åŒ– (2) â€” TaskGroup Concurrency + é™åˆ¶å¹¶è¡Œæ•°é‡



```swift
func generateAllThumbnails() async throws {
    try await withThrowingDiscardingTaskGroup {
        taskGroup in
        // æœ€å¤šæ‰§è¡Œæ•°é‡ä¸å¾—è¶…è¿‡ 5
        let maxImageTasks = min(5, images.count)
        // å…ˆå¡«å…… 5 ä¸ª Task
        for index in 0..<maxImageTasks {
            taskGroup.addTask {
                image[index].thumbnail = try await generateThumbnail(url: image[index].url)
            }
        }
        var nextIndex = maxImageTasks
        for try await _ in taskGroup {
            // taskGroup é‡Œ Task await å®Œæˆæ—¶...
            // æ£€æŸ¥ Index æ˜¯å¦åˆ°å°¾éƒ¨
            if nextIndex < images.count {
                let image = images[nextIndex]
                // ç»§ç»­é€ä¸ªå¡«å…… Task (å°†ç»´æŒåœ¨æœ€å¤š 5 ä¸ª)
                taskGroup.addTask {
                    image.thumbnail = try await generateThumbnail(url: image.url)
                }
                nextIndex += 1
            }
        }
    }
}
```



### Update an existing Vision app



![](/assets/755509180ca8/1*0OhzcxQ7OpSujeyvt9918Q.png)



![](/assets/755509180ca8/1*MH4Xa0RB2DZQ1Fl9-kItSw.png)



1. Vision å°†åœ¨å…·å¤‡ç¥ç»å¼•æ“çš„è®¾å¤‡ä¸Šç§»é™¤å¯¹éƒ¨åˆ†è¯·æ±‚çš„ CPU å’Œ GPU æ”¯æŒã€‚åœ¨è¿™äº›è®¾å¤‡ä¸Šï¼Œç¥ç»å¼•æ“æ˜¯æ€§èƒ½æœ€å¥½çš„é€‰æ‹©ã€‚
   å¯ä»¥ä½¿ç”¨ `supportedComputeDevices()` API è¿›è¡Œæ£€æŸ¥


2. ç§»é™¤æ‰€æœ‰ VN å‰ç¼€
   `VNXXRequest` , `VNXXXObservation` -&gt; `Reqeust` , `Observation`


3. ä½¿ç”¨ async/await å–ä»£åŸæœ¬çš„ VNRequestCompletionHandler


4. ç›´æ¥ä½¿ç”¨ `*Request.perform()` å–ä»£åŸæœ¬çš„ `VNImageRequestHandler.perform([VN*Request])`



### Wrap-up



- ä¸º Swift è¯­è¨€ç‰¹æ€§æ–°è®¾è®¡çš„ API


- æ–°çš„åŠŸèƒ½ã€æ–¹æ³•éƒ½ä¸º Swift Only, iOS â‰¥ 18 å¯ç”¨


- æ–°çš„å›¾ç‰‡è¯„åˆ†åŠŸèƒ½ã€èº«ä½“ï¼‹æ‰‹éƒ¨åŠ¨ä½œè¿½è¸ª



### Thanks!



![](/assets/755509180ca8/1*BK_5eH1i4-drOUOGnuQRSg.png)



### KKday æ‹›å‹Ÿå·¥å•†



![](/assets/755509180ca8/1*kjcldhvCP1cM-QqDfRFaYg.png)



ğŸ‘‰ğŸ‘‰ğŸ‘‰æœ¬æ¬¡è¯»ä¹¦ä¼šåˆ†äº«æºäº KKday App Team ç»„å†…æ¯å‘¨æŠ€æœ¯åˆ†äº«æ´»åŠ¨ï¼Œ **ç›®å‰å›¢é˜Ÿä¹Ÿæ­£åœ¨çƒ­æƒ…æ‹›å‹Ÿ [Senior iOS Engineer](https://kkday.bamboohr.com/careers/25?source=aWQ9Mjk%3D){:target="_blank"} ï¼Œæœ‰å…´è¶£çš„æœ‹å‹æ¬¢è¿æŠ•é€’å±¥å†** ã€‚ğŸ‘ˆğŸ‘ˆğŸ‘ˆ



#### å‚è€ƒèµ„æ–™



#### [Discover Swift enhancements in the Vision framework](https://developer.apple.com/videos/play/wwdc2024/10163/){:target="_blank"}



The Vision Framework API has been redesigned to leverage modern Swift features like concurrency, making it easier and faster to integrate a wide array of Vision algorithms into your app. Weâ€™ll tour the updated API and share sample code, along with best practices, to help you get the benefits of this framework with less coding effort. Weâ€™ll also demonstrate two new features: image aesthetics and holistic body pose.



### Chapters



- 0:00 â€” [Introduction](https://developer.apple.com/videos/play/wwdc2024/10163/?time=0){:target="_blank"}


- 1:07 â€” [New Vision API](https://developer.apple.com/videos/play/wwdc2024/10163/?time=67){:target="_blank"}


- 1:47 â€” [Get started with Vision](https://developer.apple.com/videos/play/wwdc2024/10163/?time=107){:target="_blank"}


- 8:59 â€” [Optimize with Swift Concurrency](https://developer.apple.com/videos/play/wwdc2024/10163/?time=539){:target="_blank"}


- 11:05 â€” [Update an existing Vision app](https://developer.apple.com/videos/play/wwdc2024/10163/?time=665){:target="_blank"}


- 13:46 â€” [Whatâ€™s new in Vision?](https://developer.apple.com/videos/play/wwdc2024/10163/?time=826){:target="_blank"}



#### [Vision framework Apple Developer Documentation](https://developer.apple.com/documentation/vision/){:target="_blank"}



-



æœ‰ä»»ä½•é—®é¢˜åŠæŒ‡æ•™æ¬¢è¿ [ä¸æˆ‘è”ç»œ](https://www.zhgchg.li/contact){:target="_blank"} ã€‚



*[Post](https://medium.com/kkdaytech/ios-vision-framework-x-wwdc-24-discover-swift-enhancements-in-the-vision-framework-session-755509180ca8){:target="_blank"} converted from Medium by [ZMediumToMarkdown](https://github.com/ZhgChgLi/ZMediumToMarkdown){:target="_blank"}.*