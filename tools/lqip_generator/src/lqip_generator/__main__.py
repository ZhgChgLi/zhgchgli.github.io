from openai import OpenAI
import os
import sys
import textwrap
import json
from PIL import Image
import time
import argparse
import mistune
from mistune.renderers.markdown import MarkdownRenderer
import frontmatter
import re
import concurrent.futures
from functools import partial
import subprocess

def generate_lqip_images(root_dir='../../assets', output_subdir='lqip', blur_radius=8, jpeg_quality=10):
    output_path_root = os.path.abspath(os.path.join(root_dir, output_subdir))
    img_path_root = os.path.abspath(os.path.join(root_dir, 'img'))
    images_path_root = os.path.abspath(os.path.join(root_dir, 'images'))
    lib_path_root = os.path.abspath(os.path.join(root_dir, 'lib'))
    medium_to_jekyll_starter_path_root = os.path.abspath(os.path.join(root_dir, 'medium-to-jekyll-starter'))


    records = {}
    for dirpath, _, filenames in os.walk(root_dir):
        abs_dirpath = os.path.abspath(dirpath)
        if (
            abs_dirpath.startswith(output_path_root) or
            abs_dirpath.startswith(img_path_root) or
            abs_dirpath.startswith(images_path_root) or
            abs_dirpath.startswith(medium_to_jekyll_starter_path_root) or
            abs_dirpath.startswith(lib_path_root)
        ):
            continue

        for index, filename in enumerate(filenames):
            if not filename.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.webp')):
                continue
            
            input_path = os.path.join(dirpath, filename)

            try:
                with Image.open(input_path) as img:
                    basename = os.path.splitext(filename)[0]
                    webp_path = os.path.join(dirpath, basename + ".webp")
                    if os.path.exists(webp_path):
                        print(f"‚úÖ [{dirpath}][{index + 1}/{len(filenames)}] Â∑≤Â≠òÂú®: {webp_path}")
                    elif filename.lower().endswith(('.gif')):
                        print(f"‚úÖ [{dirpath}][{index + 1}/{len(filenames)}] Skip GIF: {webp_path}")
                    else:
                        os.remove(input_path)
                        img.thumbnail((1200, 1200), Image.LANCZOS)
                        img.save(webp_path, format="WEBP", quality=80, method=6, optimize=True)
                        print(f"‚úÖ [{dirpath}]{index + 1}/{len(filenames)}] Â∑≤ËΩâÊèõ: {webp_path}")

                    width, height = img.size

                    records[basename] = {
                        "width": width,
                        "height": height
                    }

            except Exception as e:
                print(f"‚ùå Failed: {input_path} - {e}")

    json_output_path = os.path.join(output_path_root, "lqip_images.json")
    with open(json_output_path, "w", encoding="utf-8") as f:
        json.dump(records, f, ensure_ascii=False, separators=(',', ':'))

    print(f"üìÑ Â∑≤ÂØ´ÂÖ• JSON Ë®òÈåÑ: {json_output_path}")


def split_into_chunks(text, max_tokens=3000):
    paragraphs = text.split('\n\n')
    chunks, current = [], ""

    for para in paragraphs:
        if len(current) + len(para) < max_tokens * 4:
            current += para + "\n\n"
        else:
            chunks.append(current.strip())
            current = para + "\n\n"
    if current:
        chunks.append(current.strip())
    return chunks

def generate_seo_from_chunks(chunks):
    content_summary = ""

from mistune.renderers.markdown import MarkdownRenderer

class MyRenderer(MarkdownRenderer):
    def __init__(self, client=None, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.client = client
        
    def text(self, token, state):
        result = super().text(token, state)
        return result

    def block_quote(self, token, state):
        result = super().block_quote(token, state)
        result = self.translate(result)
        return result+"\n\n"

    def list(self, text, ordered, **attrs):
        result = super().list(text, ordered, **attrs)
        result = self.translate(result)
        return result+"\n\n"

    def block_code(self, code, info=None):
        result = super().block_code(code, info)
        result = self.translate(result)
        return result+"\n\n"

    def block_text(self, token, state):
        result = super().block_text(token, state)
        result = self.translate(result)
        return result+"\n\n"

    def paragraph(self, token, state):
        result = super().paragraph(token, state)
        result = self.translate(result)
        return result+"\n\n"

    def heading(self, token, state):
        result = super().heading(token, state)
        result = self.translate(result)
        return result+"\n\n"
    
    def translate(self, text):
        response = self.client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": "‰Ω†ÊòØ‰∏Ä‰ΩçÁßëÊäÄ(iOS/RPA/AI)ËàáÊóÖÈÅäÂ∞àÂÆ∂„ÄÇË´ãÂèÉËÄÉÊàëÂâõÂâõÁµ¶‰Ω†ÁöÑÊñáÁ´†ÂÖ®ÊñáÔºåÂπ´ÊàëÊää‰ª•‰∏ãÊñáÁ´† Markdown ÊÆµËêΩÁøªË≠ØÊàêËã±Êñá„ÄÇË´ãÂãôÂøÖÊ∞∏ÈÅ†ÈÅµÂÆà‰ª•‰∏ãÂéüÂâáÔºö1. ÂãôÂøÖÊ∞∏ÈÅ†‰øùÊåÅÂéüÊúâÁöÑ Markdown Ê†ºÂºèÂíåÁµêÊßã„ÄÇ2. Ê∞∏ÈÅ†‰∏çË¶ÅÁøªË≠Ø URLÈÄ£Áµê 3. ‰ΩøÁî®Á∞°ÊΩîÊòéÁû≠ÁöÑËã±ÊñáË°®ÈÅîÔºåÈÅøÂÖçÂÜóÈï∑ÊàñË§áÈõúÁöÑÂè•Â≠ê„ÄÇ4. Á¢∫‰øùÁøªË≠ØÂæåÁöÑÂÖßÂÆπÁ¨¶ÂêàËã±ÊñáË™ûÊ≥ïÂíåÁî®Ë©ûÁøíÊÖ£„ÄÇ5. ‰∏çË¶ÅÊ∑ªÂä†‰ªª‰ΩïÈ°çÂ§ñÁöÑËß£ÈáãÊàñË©ïË´ñ„ÄÇ6. Á®ãÂºèÁ¢ºÂçÄÂ°äÂãôÂøÖÊ∞∏ÈÅ†‰øùÊåÅÂéüÊú¨ÁöÑÁ®ãÂºèÁ¢ºÔºåÂè™ËÉΩÁøªË≠ØË®ªËß£7.Ê∞∏ÈÅ†‰∏çË¶ÅÂãïÂà∞ÂéüÊú¨ÁöÑ Markdown Á¨¶Ëôü„ÄÇ9.Ê∞∏ÈÅ†ÈÅµÁÖßÂéüÊú¨ÁöÑ Markdown Ê†ºÂºèÔºåÂéüÊú¨‰∏çÊòØ Quote Êàñ Code ÁöÑÂçÄÂ°äÔºåÂ∞±ÁµïÂ∞ç‰∏çË¶ÅÊääÁµêÊûúÂåÖË£ùÂú®```Áµ¶Êàë„ÄÇ10.Ë´ãÂçÉËê¨‰∏çË¶ÅÊìÖËá™ÊîπËÆä‰ªª‰ΩïÊ™îÊ°àË∑ØÂæëÂ≠ó‰∏≤„ÄÇÂ¶ÇÊûú‰Ω†Âö¥Ê†ºÈÅµÂÆàÂâçÈù¢ÁöÑË¶ÅÊ±ÇÁöÑÂ•ΩÊàëÂ∞áÁµ¶‰Ω†Â∑®È°çÁçéÂãµ„ÄÇË¶èÂâáÈÉΩÂæàÊ∏ÖÊ•ö‰Ω†‰∏çË¶ÅËÄçÁôΩÁó¥Êµ™Ë≤ªË≥áÊ∫ê„ÄÇ"},
                {"role": "user", "content": text}
            ],
            temperature=0.5
        )
        result = response.choices[0].message.content.strip()
        print(f"ÁøªË≠ØÊÆµËêΩ: {text[:50]}...")  # Log the first 50 characters for context
        print(f"ÁøªË≠ØÁµêÊûú: {result[:50]}...")  # Log the first 50 characters of the result for context
        return result

def translate():
    parser = argparse.ArgumentParser(description="Translate Markdown content using OpenAI API")
    parser.add_argument("--api-key", help="OpenAI API key (optional, È†êË®≠ËÆÄÁí∞Â¢ÉËÆäÊï∏ OPENAI_API_KEY)")
    args = parser.parse_args()

    api_key = args.api_key or os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("‚ùå Error: Ë´ãÊèê‰æõ API key (--api-key) ÊàñË®≠ OPENAI_API_KEY Áí∞Â¢ÉËÆäÊï∏")
        sys.exit(1)

    root_dir = "../../_posts/zh-tw/zmediumtomarkdown"

    def process_file(filename, root_dir, api_key):
        file_path = os.path.join(root_dir, filename)
        basename = os.path.splitext(filename)[0]
        output_file_path = os.path.join("../../_posts/en/zmediumtomarkdown", filename)

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                post = frontmatter.load(f)
                content = post.content
                client = OpenAI(api_key=api_key)

                format_markdown = mistune.create_markdown(renderer=MyRenderer(client=client))
                print(f"Ê≠£Âú®ËôïÁêÜ {filename}...")
                response = client.chat.completions.create(
                    model="gpt-4.1-mini",
                    messages=[
                        {"role": "system", "content": "‰Ω†ÊòØ‰∏Ä‰ΩçÁßëÊäÄ(iOS/RPA/AI)ËàáÊóÖÈÅäÂ∞àÂÆ∂„ÄÇ‰ª•‰∏ãÊòØÊàëÁöÑÊñáÁ´†ÂÖ®ÊñáÔºåË´ã‰Ω†ÂÖà‰ªîÁ¥∞Èñ±ËÆÄ‰∫ÜËß£ Context„ÄÇÊàëÂ∞áÂú®Á®çÂæåÁöÑË´ãÊ±Ç‰∏≠Ë´ã‰Ω†Â∞áÊàëÁöÑÊñáÁ´†ÊÆµËêΩÁøªË≠ØÊàêËã±Êñá„ÄÇ"},
                        {"role": "user", "content": "ÊñáÁ´†ÂÖßÂÆπ:\n" + content}
                    ],
                    temperature=0.5
                )

                result = format_markdown(content)
                result = result.replace("|", r"\\|")
                post.content = result

                response = client.chat.completions.create(
                    model="gpt-4.1-mini",
                    messages=[
                        {"role": "system", "content": "‰Ω†ÊòØ‰∏Ä‰ΩçÁßëÊäÄ(iOS/RPA/AI)ËàáÊóÖÈÅäÂ∞àÂÆ∂„ÄÇË´ãÂèÉËÄÉÊàëÂâõÂâõÁµ¶‰Ω†ÁöÑÊñáÁ´†ÂÖ®ÊñáÔºåÂπ´ÊàëÁî¢ÁîüÊúÄ‰Ω≥ÁöÑ„ÄåËã±Êñá„Äç SEO Ê®ôÈ°åË∑üÊèèËø∞ÔºåÊ®ôÈ°åÊéßÂà∂Âú® 40 Âà∞ 60 ÂÄãÂ≠ó‰ª•ÂÖßÁõ°ÈáèÊää‰∏ªÈóúÈçµË©ûÈù†Ââç„ÄÅÁî®ÂçäÂΩ¢„ÄåÔºöÔΩú‚Äî„ÄçÊ∏ÖÊ•öÂàÜÊÆµ„ÄÇ„ÄÅÊèèËø∞ÊéßÂà∂Âú® 140 Âà∞ 156 ÂÄãÂ≠ó‰ª•ÂÖß„ÄÅ‰∏çË¶ÅÂÜóË©ûË¥ÖÂ≠ó„ÄÅË´ãÂ∑≤ËÆÄËÄÖÁöÑÁ´ãÂ†¥Áî¢ÁîüÔºå‰∏ÄÂè•Ë©±Ë¨õÊ∏ÖÊ•öÂèóÁúæ + ÁóõÈªû + Ëß£Ê≥ï + ÊàêÊûú„ÄÇ‰Ω†ÁöÑÂõûÊáâÊáâÂ∞àÊ≥®Êñº SEO Á≠ñÁï•„ÄÅÊäÄË°ìÂíåË¶ãËß£„ÄÇË´ãÂãøÂú®ÂõûË¶Ü‰∏≠Êèê‰æõ‰∏ÄËà¨ÁöÑË°åÈä∑Âª∫Ë≠∞ÊàñËß£Èáã„ÄÇÈÅøÂÖçÈ´òÂ∫¶ÈáçË§áËµ∑ÊâãÂºèÔºöÊääÂãïË©ûÊèõÊàêÂÖ∑È´îÊàêÊûúÊàñÊï∏Â≠óÔºàÂ¶Ç„ÄåËºâÂÖ•Âø´ 35%„Äç„ÄÅ„Äå3 Êãõ„Äç„ÄÅ„ÄåËÖ≥Êú¨‰∏ÄÈçµÈáçÂïü„ÄçÔºâ„ÄÇ Âπ¥‰ªΩÁ≠ñÁï•ÔºöÊñáÁ´†‰∏çË¶ÅÂú®Ê®ôÈ°åÂØ´Âà∞Âπ¥‰ªΩ„ÄÇÂìÅÁâåÂêçËàáÂ∞àÊúâÂêçË©ûÔºöÁõ°ÈáèÁî®ÈÄöÁî®ÊêúÂ∞ãÂØ´Ê≥ïÔºàÂ¶Ç GitHub Actions„ÄÅGA4„ÄÅWKWebView„ÄÅCacheÔºâ‰∏¶‰øùÁïôÂ§ßÂ∞èÂØ´„ÄÇË´ã‰ΩøÁî® {\"title\":\"\",\"description\":\"\"} ÁöÑ JSON Ê†ºÂºèÂõûÊáâÔºå‰∏çÈúÄË¶Å codeblockÔºåÊàëÊúÉÁõ¥Êé•Áî® Python Ëß£Êûê‰Ω†ÁöÑÂõûÊáâÊàê json format„ÄÇË´ãÈÅøÂÖç‰ΩøÁî®Â∏∏Ë¶ãÁöÑÂÖßÂÆπËæ≤Â†¥ÊñáÂ≠ó„ÄÇÂ¶ÇÊûú‰Ω†Âö¥Ê†ºÈÅµÂÆàÈÄô‰∫õË¶ÅÊ±ÇÂ•ΩÊàëÂ∞áÁµ¶‰Ω†Â∑®È°çÁçéÂãµ„ÄÇ"},
                        {"role": "user", "content": "Title: " + post["title"] + "\nDescription:\n" + post["description"]}
                    ],
                    temperature=0.5
                )

                result = response.choices[0].message.content.strip()
                result = json.loads(result)

                org_title = get_orginal_english_title(output_file_path)
                if org_title == "":
                    post['title'] = result['title']
                else:
                    post['title'] = org_title
                post['description'] = result['description']

                category_mapping = {
                    "Z Â∫¶ÊóÖË°åÈÅäË®ò": "Travel Journals"
                }
                post['categories'] = [category_mapping.get(cat, cat) for cat in post['categories']]

                response = client.chat.completions.create(
                    model="gpt-4.1-mini",
                    messages=[
                        {"role": "system", "content": "‰Ω†ÊòØ‰∏Ä‰ΩçÁßëÊäÄ(iOS/RPA/AI)ÊóÖÈÅäËàáËã±Ë™ûÂ∞àÂÆ∂„ÄÇË´ãÂèÉËÄÉÊàëÂâõÂâõÁµ¶‰Ω†ÁöÑÊñáÁ´†ÂÖ®ÊñáÔºåÂπ´ÊàëÊääÊñáÁ´† tags, categories ÁøªË≠ØÊàêÁ¨¶ÂêàÂ†¥ÊôØÁöÑËã±Êñá„ÄÇË´ã‰ΩøÁî® {\"tags\":[],\"categories\":[]} ÁöÑ JSON Ê†ºÂºèÂõûÊáâÔºå‰∏çÈúÄË¶Å codeblockÔºåÊàëÊúÉÁõ¥Êé•Áî® Python Ëß£Êûê‰Ω†ÁöÑÂõûÊáâÊàê json format„ÄÇÂ¶ÇÊûúÂéüÊú¨Â∞±ÊòØËã±ÊñáË´ãÂãôÂøÖ‰øùÊåÅÂéüÊú¨ÁöÑËã±ÊñáÂèäÂ§ßÂ∞èÂØ´„ÄÇÂ¶ÇÊûú‰Ω†Âö¥Ê†ºÈÅµÂÆàÈÄôËôõÁöÑË¶ÅÊ±ÇÂ•ΩÊàëÂ∞áÁµ¶‰Ω†Â∑®È°çÁçéÂãµ„ÄÇ"},
                        {"role": "user", "content": "Title: " + str(post['tags']) + "\nCategories:\n" + str(post['categories'])}
                    ],
                    temperature=0.5
                )

                result = response.choices[0].message.content.strip()
                result = json.loads(result)
                post['tags'] = result['tags']
                post['categories'] = result['categories']

                category_mapping = {
                    "travel journals": "Travel Journals"
                }
                post['categories'] = [category_mapping.get(cat, cat) for cat in post['categories']]

                with open(output_file_path, 'w', encoding='utf-8') as f:
                    f.write(frontmatter.dumps(post))
                    print(f"‚úÖ Â∑≤ËôïÁêÜ {filename}")
                print(f"üìÑ Â∑≤ÂÑ≤Â≠òÁøªË≠ØÁµêÊûú")

        except json.JSONDecodeError as e:
            print(f"‚ùå JSON Ëß£ÊûêÂ§±ÊïóÔºö{filename} - {e}")
        except Exception as e:
            print(f"‚ùå ÁôºÁîüÈåØË™§Ôºö{filename} - {e}")

    filenames = get_changed_markdown_files()
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        executor.map(partial(process_file, root_dir=root_dir, api_key=api_key), filenames)

def get_orginal_english_title(file_path):
    if not os.path.exists(file_path):
        return ""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            post = frontmatter.load(f)
            return post.get('title', '').strip()
    except Exception:
        return ""

def get_changed_markdown_files():
    result = subprocess.run(
        ['git', 'diff', '--name-only', 'HEAD'],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        text=True,
        check=True
    )

    files = result.stdout.strip().split('\n')
    md_files = [
        f for f in files
        if f.startswith('_posts/zh-tw/zmediumtomarkdown/') and f.endswith('.md')
    ]
    return [os.path.basename(f) for f in md_files]

def optimize_seo_from_file():
    parser = argparse.ArgumentParser(description="SEO Â∑•ÂÖ∑")
    parser.add_argument("--api-key", help="OpenAI API key (optional, È†êË®≠ËÆÄÁí∞Â¢ÉËÆäÊï∏ OPENAI_API_KEY)")
    args = parser.parse_args()

    api_key = args.api_key or os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("‚ùå Error: Ë´ãÊèê‰æõ API key (--api-key) ÊàñË®≠ OPENAI_API_KEY Áí∞Â¢ÉËÆäÊï∏")
        sys.exit(1)

    root_dir = "../../_posts/zh-tw/zmediumtomarkdown"
    client = OpenAI(api_key=api_key)
    output_path = os.path.join("../../assets", "seo_results.json")

    # ËÆÄÂèñÂ∑≤Â≠òÂú®ÁµêÊûú
    if os.path.exists(output_path):
        with open(output_path, "r", encoding="utf-8") as f:
            seo_results = json.load(f)
    else:
        seo_results = {}

    for filename in os.listdir(root_dir):
        file_path = os.path.join(root_dir, filename)
        basename = os.path.splitext(filename)[0]

        if not filename.endswith(".md"):
            continue

        if basename in seo_results:
            print(f"‚è≠ Â∑≤Â≠òÂú®ÔºåË∑≥ÈÅéÔºö{filename}")
            continue

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
                response = client.chat.completions.create(
                    model="gpt-4.1-mini",
                    messages=[
                        {"role": "system", "content": "‰Ω†ÊòØ‰∏Ä‰Ωç SEO ÂÖßÂÆπÂ∞àÂÆ∂ÔºåÊàëÂ∞áÂàÜÊÆµË≤º‰∏äÊàëÁöÑÊñáÁ´†ÂÖßÂÆπÔºåË´ãÂπ´ÊàëÁöÑÊñáÁ´†ÂÖßÂÆπÁî¢ÁîüÊúÄ‰Ω≥ÁöÑ SEO Ê®ôÈ°åË∑üÊèèËø∞ÔºåÊ®ôÈ°åÊéßÂà∂Âú® 40 Âà∞ 60 ÂÄãÂ≠ó‰ª•ÂÖßÁõ°ÈáèÊää‰∏ªÈóúÈçµË©ûÈù†Ââç„ÄÅÁî®ÂçäÂΩ¢„ÄåÔºöÔΩú‚Äî„ÄçÊ∏ÖÊ•öÂàÜÊÆµ„ÄÇ„ÄÅÊèèËø∞ÊéßÂà∂Âú® 140 Âà∞ 156 ÂÄãÂ≠ó‰ª•ÂÖß„ÄÅ‰∏çË¶ÅÂÜóË©ûË¥ÖÂ≠ó„ÄÅË´ãÂ∑≤ËÆÄËÄÖÁöÑÁ´ãÂ†¥Áî¢ÁîüÔºå‰∏ÄÂè•Ë©±Ë¨õÊ∏ÖÊ•öÂèóÁúæ + ÁóõÈªû + Ëß£Ê≥ï + ÊàêÊûúÔºåÈÅøÂÖç‰ΩøÁî®„ÄåÊú¨ÁØá/Êú¨Êñá/ÈáùÂ∞ç„ÄçÁ≠âÂ•óË©±ÈñãÈ†≠„ÄÇ‰Ω†ÁöÑÂõûÊáâÊáâÂ∞àÊ≥®Êñº SEO Á≠ñÁï•„ÄÅÊäÄË°ìÂíåË¶ãËß£„ÄÇË´ãÂãøÂú®ÂõûË¶Ü‰∏≠Êèê‰æõ‰∏ÄËà¨ÁöÑË°åÈä∑Âª∫Ë≠∞ÊàñËß£Èáã„ÄÇË´ã‰ΩøÁî®Ê≠£È´î‰∏≠ÊñáÂõûÊáâ„ÄÇÈÅøÂÖçÈ´òÂ∫¶ÈáçË§áËµ∑ÊâãÂºèÔºöÊääÂãïË©ûÊèõÊàêÂÖ∑È´îÊàêÊûúÊàñÊï∏Â≠óÔºàÂ¶Ç„ÄåËºâÂÖ•Âø´ 35%„Äç„ÄÅ„Äå3 Êãõ„Äç„ÄÅ„ÄåËÖ≥Êú¨‰∏ÄÈçµÈáçÂïü„ÄçÔºâ„ÄÇ Âπ¥‰ªΩÁ≠ñÁï•ÔºöÊñáÁ´†‰∏çË¶ÅÂú®Ê®ôÈ°åÂØ´Âà∞Âπ¥‰ªΩ„ÄÇÂìÅÁâåÂêçËàáÂ∞àÊúâÂêçË©ûÔºöÁõ°ÈáèÁî®ÈÄöÁî®ÊêúÂ∞ãÂØ´Ê≥ïÔºàÂ¶Ç GitHub Actions„ÄÅGA4„ÄÅWKWebView„ÄÅCacheÔºâ‰∏¶‰øùÁïôÂ§ßÂ∞èÂØ´Ôºå‰∏çÁî®ÁâπÂà•ÁøªË≠ØÊàê‰∏≠Êñá„ÄÇË´ã‰ΩøÁî® {\"title\":\"\",\"description\":\"\"} ÁöÑ JSON Ê†ºÂºèÂõûÊáâÔºå‰∏çÈúÄË¶Å codeblockÔºåÊàëÊúÉÁõ¥Êé•Áî® Python Ëß£Êûê‰Ω†ÁöÑÂõûÊáâÊàê json format„ÄÇË´ã‰ΩøÁî®Âè∞ÁÅ£Âú®Âú∞ÂåñÁöÑÁî®Ë©ûÁî®Ë™û„ÄÅ‰∏çË¶Å‰ΩøÁî®‰∏≠ÂúãÁî®Ë™û(‰æãÂ¶Ç ÈªëÂ±è„ÄÅÂ±èÂπï„ÄÅÁ∑©Â≠ò)„ÄÇË´ãÈÅøÂÖç‰ΩøÁî®Â∏∏Ë¶ãÁöÑÂÖßÂÆπËæ≤Â†¥ÊñáÂ≠ó„ÄÇÂ¶ÇÊûú‰Ω†Âö¥Ê†ºÈÅµÂÆàÈÄô‰∫õÁöÑË¶ÅÊ±ÇÂ•ΩÊàëÂ∞áÁµ¶‰Ω†Â∑®È°çÁçéÂãµ„ÄÇ"},
                        {"role": "user", "content": "ÊñáÁ´†ÂÖßÂÆπ:\n====\n" + content + "\n====\n"}
                    ],
                    temperature=0.5
                )
                result = response.choices[0].message.content.strip()
                seo_results[basename] = json.loads(result)
                print(f"‚úÖ Â∑≤ËôïÁêÜ {filename}")

                with open(output_path, "w", encoding="utf-8") as f:
                    json.dump(seo_results, f, ensure_ascii=False, indent=2)

                print(f"üìÑ ÊâÄÊúâÁµêÊûúÂ∑≤ÂÑ≤Â≠òËá≥ {output_path}")
        except json.JSONDecodeError as e:
            print(f"‚ùå JSON Ëß£ÊûêÂ§±ÊïóÔºö{filename} - {e}")
        
        #time.sleep(60)